{"meta":{"title":"Just For Fun！","subtitle":"就是为了好玩！","description":null,"author":"fangminx","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2017-02-26T09:00:35.000Z","updated":"2017-02-26T09:00:36.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"elasticsearch(四、索引管理)","slug":"elasticsearch(四、索引管理)","date":"2018-03-04T02:24:03.000Z","updated":"2018-03-04T03:01:48.000Z","comments":true,"path":"2018/03/04/elasticsearch(四、索引管理)/","link":"","permalink":"http://yoursite.com/2018/03/04/elasticsearch(四、索引管理)/","excerpt":"索引CRUD 创建索引的语法 123456789PUT /my_index&#123; &quot;settings&quot;: &#123; ... any settings ... &#125;, &quot;mappings&quot;: &#123; &quot;type_one&quot;: &#123; ... any mappings ... &#125;, &quot;type_two&quot;: &#123; ... any mappings ... &#125;, ... &#125;&#125;","text":"索引CRUD 创建索引的语法 123456789PUT /my_index&#123; &quot;settings&quot;: &#123; ... any settings ... &#125;, &quot;mappings&quot;: &#123; &quot;type_one&quot;: &#123; ... any mappings ... &#125;, &quot;type_two&quot;: &#123; ... any mappings ... &#125;, ... &#125;&#125; 创建索引的示例 12345678910111213141516PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0 &#125;, &quot;mappings&quot;: &#123; &quot;my_type&quot;: &#123; &quot;properties&quot;: &#123; &quot;my_field&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125;&#125; 修改索引 1234PUT /my_index/_settings&#123; &quot;number_of_replicas&quot;: 1&#125; 删除索引 123456DELETE /my_indexDELETE /index_one,index_twoDELETE /index_* DELETE /_all (若禁用：elasticsearch.yml=&gt;修改action.destructive_requires_name: true) 修改定制分词器 常见分词器 123456standard（默认） standard tokenizer：以单词边界进行切分standard token filter：什么都不做lowercase token filter：将所有字母转换为小写stop token filer（默认被禁用）：移除停用词，比如a the it等等 修改分词器的设置=&gt;启用english停用词 12345678910111213PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;analyzer&quot;: &#123; &quot;es_std&quot;: &#123; &quot;type&quot;: &quot;standard&quot;, &quot;stopwords&quot;: &quot;_english_&quot; &#125; &#125; &#125; &#125;&#125; 查看分词效果 1234567891011GET /my_index/_analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;a dog is in the house&quot;&#125; GET /my_index/_analyze&#123; &quot;analyzer&quot;: &quot;es_std&quot;, &quot;text&quot;:&quot;a dog is in the house&quot;&#125; 定制化自己的分词器 123456789101112131415161718192021222324252627PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;char_filter&quot;: &#123; &quot;&amp;_to_and&quot;: &#123; &quot;type&quot;: &quot;mapping&quot;, &quot;mappings&quot;: [&quot;&amp;=&gt; and&quot;] &#125; &#125;, &quot;filter&quot;: &#123; &quot;my_stopwords&quot;: &#123; &quot;type&quot;: &quot;stop&quot;, &quot;stopwords&quot;: [&quot;the&quot;, &quot;a&quot;] &#125; &#125;, &quot;analyzer&quot;: &#123; &quot;my_analyzer&quot;: &#123; &quot;type&quot;: &quot;custom&quot;, &quot;char_filter&quot;: [&quot;html_strip&quot;, &quot;&amp;_to_and&quot;], &quot;tokenizer&quot;: &quot;standard&quot;, &quot;filter&quot;: [&quot;lowercase&quot;, &quot;my_stopwords&quot;] &#125; &#125; &#125; &#125;&#125; 1234567891011121314151617查看分词器效果：GET /my_index/_analyze&#123; &quot;text&quot;: &quot;tom&amp;jerry are a friend in the house, &lt;a&gt;, HAHA!!&quot;, &quot;analyzer&quot;: &quot;my_analyzer&quot;&#125; 使field使用自定义的分词器：PUT /my_index/_mapping/my_type&#123; &quot;properties&quot;: &#123; &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;my_analyzer&quot; &#125; &#125;&#125; type底层数据结构 lucene是没有type的概念 123lucene中建立索引的时候，全部是opaque bytes(二进制)类型，不区分其他类型 一个index中的多个type，实际上是放在一起存储的 举例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687mapping:&#123; &quot;ecommerce&quot;: &#123; &quot;mappings&quot;: &#123; &quot;elactronic_goods&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &#125;, &quot;price&quot;: &#123; &quot;type&quot;: &quot;double&quot; &#125;, &quot;service_period&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &#125; &#125;, &quot;fresh_goods&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &#125;, &quot;price&quot;: &#123; &quot;type&quot;: &quot;double&quot; &#125;, &quot;eat_period&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &#125; &#125; &#125; &#125;&#125; document： &#123; &quot;name&quot;: &quot;geli kongtiao&quot;, &quot;price&quot;: 1999.0, &quot;service_period&quot;: &quot;one year&quot;&#125; &#123; &quot;name&quot;: &quot;aozhou dalongxia&quot;, &quot;price&quot;: 199.0, &quot;eat_period&quot;: &quot;one week&quot;&#125; 底层对mapping和document的存储：&#123; &quot;ecommerce&quot;: &#123; &quot;mappings&quot;: &#123; &quot;_type&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &quot;price&quot;: &#123; &quot;type&quot;: &quot;double&quot; &#125; &quot;service_period&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &quot;eat_period&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &#125; &#125;&#125; &#123; &quot;_type&quot;: &quot;elactronic_goods&quot;, &quot;name&quot;: &quot;geli kongtiao&quot;, &quot;price&quot;: 1999.0, &quot;service_period&quot;: &quot;one year&quot;, &quot;eat_period&quot;: &quot;&quot;&#125; &#123; &quot;_type&quot;: &quot;fresh_goods&quot;, &quot;name&quot;: &quot;aozhou dalongxia&quot;, &quot;price&quot;: 199.0, &quot;service_period&quot;: &quot;&quot;, &quot;eat_period&quot;: &quot;one week&quot;&#125; 最佳实践 1234将类似结构的type放在一个index下，这些type应该有多个field是相同的 若两个type的field完全不同，放在一个index下，每个document至少有一半field在底层的lucene中是空值，会有严重的性能问题 _mapping root object root object介绍 1某个type对应的mapping json，包括了properties，metadata（_id，_source，_type），settings（analyzer）等 properties 12345678910PUT /my_index/_mapping/my_type&#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125;&#125;除了可配置type，还有index，analyzer _source 123456789101112（1）partial update基于_source实现（2）查询的时候，直接可以拿到完整的document，不需要先拿document id，再发送一次请求拿document（3）reindex时，直接基于_source实现，不需要从数据库（或者其他外部存储）查询数据再修改（4）可以基于_source定制返回field（5）debug query更容易，因为可以直接看到_source 如果不需要上述好处，可以禁用_source PUT /my_index/_mapping/my_type2&#123; &quot;_source&quot;: &#123;&quot;enabled&quot;: false&#125;&#125; _all 123456789101112131415161718192021将所有field打包在一起，作为一个_all field，建立索引。没指定任何field进行搜索时，就是使用_all field在搜索。 禁用：PUT /my_index/_mapping/my_type3&#123; &quot;_all&quot;: &#123;&quot;enabled&quot;: false&#125;&#125; 也可以在field级别设置include_in_all field，设置是否要将field的值包含在_all field中 PUT /my_index/_mapping/my_type4&#123; &quot;properties&quot;: &#123; &quot;my_field&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;include_in_all&quot;: false &#125; &#125;&#125; dynamic策略 定制dynamic 123true：遇到陌生字段，就进行dynamic mappingfalse：遇到陌生字段，就忽略strict：遇到陌生字段，就报错 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293941.指定Type和object-field的dynamic类型：PUT /my_index&#123; &quot;mappings&quot;: &#123; &quot;my_type&quot;: &#123; &quot;dynamic&quot;: &quot;strict&quot;, &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;address&quot;: &#123; &quot;type&quot;: &quot;object&quot;, &quot;dynamic&quot;: &quot;true&quot; &#125; &#125; &#125; &#125;&#125; 2.插入了不存在字段content报错：PUT /my_index/my_type/1&#123; &quot;title&quot;: &quot;my article&quot;, &quot;content&quot;: &quot;this is my article&quot;, &quot;address&quot;: &#123; &quot;province&quot;: &quot;guangdong&quot;, &quot;city&quot;: &quot;guangzhou&quot; &#125;&#125; &#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;strict_dynamic_mapping_exception&quot;, &quot;reason&quot;: &quot;mapping set to strict, dynamic introduction of [content] within [my_type] is not allowed&quot; &#125; ], &quot;type&quot;: &quot;strict_dynamic_mapping_exception&quot;, &quot;reason&quot;: &quot;mapping set to strict, dynamic introduction of [content] within [my_type] is not allowed&quot; &#125;, &quot;status&quot;: 400&#125; 3.正确插入：PUT /my_index/my_type/1&#123; &quot;title&quot;: &quot;my article&quot;, &quot;address&quot;: &#123; &quot;province&quot;: &quot;guangdong&quot;, &quot;city&quot;: &quot;guangzhou&quot; &#125;&#125; 4.查看mapping：GET /my_index/_mapping/my_type &#123; &quot;my_index&quot;: &#123; &quot;mappings&quot;: &#123; &quot;my_type&quot;: &#123; &quot;dynamic&quot;: &quot;strict&quot;, &quot;properties&quot;: &#123; &quot;address&quot;: &#123; &quot;dynamic&quot;: &quot;true&quot;, &quot;properties&quot;: &#123; &quot;city&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125;, &quot;province&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125; &#125; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125; &#125;&#125; 定制dynamic mapping策略 1234567891011121)date_detection 默认会按照一定格式识别date，比如yyyy-MM-dd。但是如果某个field先过来一个2017-01-01的值，就会被自动dynamic mapping成date，后面如果再来一个&quot;hello world&quot;之类的值，就会报错。可以手动关闭某个type的date_detection: PUT /my_index/_mapping/my_type&#123; &quot;date_detection&quot;: false&#125; 如果有需要，自己手动指定某个field为date类型。 1234567891011121314151617181920212223242526272829302)定制自己的dynamic mapping template（type level） PUT /my_index&#123; &quot;mappings&quot;: &#123; &quot;my_type&quot;: &#123; &quot;dynamic_templates&quot;: [ &#123; &quot;en&quot;: &#123; &quot;match&quot;: &quot;*_en&quot;, &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;mapping&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;analyzer&quot;: &quot;english&quot; &#125; &#125;&#125; ]&#125;&#125;&#125; PUT /my_index/my_type/1&#123; &quot;title&quot;: &quot;this is my first article&quot;&#125; PUT /my_index/my_type/2&#123; &quot;title_en&quot;: &quot;this is my first article&quot;&#125; title没有匹配到任何的dynamic模板，默认standard分词器，不会过滤停用词，is会进入倒排索引，用is可以搜到title_en匹配到了dynamic模板，是english分词器，会过滤停用词，is会被过滤掉，用is搜不到 123456789101112131415 3)定制自己的default mapping template（index level） PUT /my_index&#123; &quot;mappings&quot;: &#123; &quot;_default_&quot;: &#123; &quot;_all&quot;: &#123; &quot;enabled&quot;: false &#125; &#125;, &quot;blog&quot;: &#123; &quot;_all&quot;: &#123; &quot;enabled&quot;: true &#125; &#125; &#125;&#125; 只有blog字段使用_all 零停机重建索引 重建索引 12345一个field的设置是不能被修改的，如果要修改一个Field，那么应该重新按照新的mapping，建立一个index，然后将数据批量查询出来，重新用bulk api写入index中 建议批量查询采用scroll api，并且采用多线程并发的方式reindex.每次scoll就查询指定日期的一段数据，交给reindex其中一个线程即可 实例演示 12345671)一开始，依靠dynamic mapping，插入数据，title是2017-01-01，所以title被自动映射为date类型，实际上它应该是string类型 PUT /my_index/my_type/3&#123; &quot;title&quot;: &quot;2017-01-03&quot;&#125; 1234562)当后期向索引中加入string类型的title值时，报错 PUT /my_index/my_type/4&#123; &quot;title&quot;: &quot;my first article&quot;&#125; 123456789103)此时无法修改title类型 PUT /my_index/_mapping/my_type&#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125;&#125; 123454)唯一的办法，就是进行reindex,将旧索引的数据查询出来，再导入到新建的索引 为了防止重启java应用，让java应用指向一个索引别名：goods_index PUT /my_index/_alias/goods_index 12345678910111213145)新建一个index，调整其title的类型为string PUT /my_index_new&#123; &quot;mappings&quot;: &#123; &quot;my_type&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125;&#125; 123456789106)使用scroll api将数据批量查询出来 GET /my_index/_search?scroll=1m&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [&quot;_doc&quot;], &quot;size&quot;: 1&#125; 123457)采用bulk api,将scoll查出来的一批数据，批量写入新索引 POST /_bulk&#123; &quot;index&quot;: &#123; &quot;_index&quot;: &quot;my_index_new&quot;, &quot;_type&quot;: &quot;my_type&quot;, &quot;_id&quot;: &quot;2&quot; &#125;&#125;&#123; &quot;title&quot;: &quot;2017-01-02&quot; &#125; 1234567891011128)循环6-7，将goods_index alias切换到my_index_new POST /_aliases&#123; &quot;actions&quot;: [ &#123; &quot;remove&quot;: &#123; &quot;index&quot;: &quot;my_index&quot;, &quot;alias&quot;: &quot;goods_index&quot; &#125;&#125;, &#123; &quot;add&quot;: &#123; &quot;index&quot;: &quot;my_index_new&quot;, &quot;alias&quot;: &quot;goods_index&quot; &#125;&#125; ]&#125; 通过goods_index别名来查询:GET /goods_index/my_type/_search 操作总结 123456789101112131)PUT /my_index_v1/_alias/my_index 2)client对my_index进行操作 3)reindex操作，完成之后，切换v1到v2 4)POST /_aliases&#123; &quot;actions&quot;: [ &#123; &quot;remove&quot;: &#123; &quot;index&quot;: &quot;my_index_v1&quot;, &quot;alias&quot;: &quot;my_index&quot; &#125;&#125;, &#123; &quot;add&quot;: &#123; &quot;index&quot;: &quot;my_index_v2&quot;, &quot;alias&quot;: &quot;my_index&quot; &#125;&#125; ]&#125;","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yoursite.com/tags/elasticsearch/"}]},{"title":"elasticsearch(三、内核知识)","slug":"elasticsearch(三、内核知识)","date":"2018-03-04T02:23:03.000Z","updated":"2018-03-04T03:01:46.000Z","comments":true,"path":"2018/03/04/elasticsearch(三、内核知识)/","link":"","permalink":"http://yoursite.com/2018/03/04/elasticsearch(三、内核知识)/","excerpt":"相关度评分算法12345Elasticsearch使用的是 term frequency/inverse document frequency算法，简称为TF/IDF算法 -Term frequency：搜索文本中的各个词条在field出现次数越多，越相关-Inverse document frequency：搜索文本中的各个词条在整个索引的所有文档中出现的次数越多，越不相关-Field-length norm：field长度，field越长，相关度越弱","text":"相关度评分算法12345Elasticsearch使用的是 term frequency/inverse document frequency算法，简称为TF/IDF算法 -Term frequency：搜索文本中的各个词条在field出现次数越多，越相关-Inverse document frequency：搜索文本中的各个词条在整个索引的所有文档中出现的次数越多，越不相关-Field-length norm：field长度，field越长，相关度越弱 查看_score是如何被计算出来的 12345678GET /test_index/test_type/_search?explain&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;test_field&quot;: &quot;test hello&quot; &#125; &#125;&#125; 分析一个document是如何被匹配上的 12345678GET /test_index/test_type/6/_explain&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;test_field&quot;: &quot;test hello&quot; &#125; &#125;&#125; doc values123456搜索的时候，要依靠倒排索引；排序的时候，需要依靠正排索引,所谓的正排索引，就是doc values 在建立索引的时候，一方面会建立倒排索引，以供搜索使用；一方面会建立正排索引，也就是doc values，以供排序，聚合，过滤等操作使用 doc values是被保存在磁盘上的，如果内存足够，os会自动将其缓存在内存中 query phase deep paging问题 123（1）搜索请求发送到某一个coordinate node，构建一个priority queue，长度(from+size)，默认为10（2）coordinate node将请求转发到所有shard，每个shard本地搜索，并构建一个本地的priority queue,长度(from+size)（3）各个shard将自己的priority queue返回给coordinate node，并构建一个全局的priority queue replica如何承载并发 1一次请求要打到所有shard其中一个replica/primary上去，如果每个shard都有多个replica，那么并发搜索请求可以同时打到其他的replica上去 fetch phbase工作流程 123（1）coordinate node构建完priority queue之后，就发送mget请求去所有shard上获取对应的document（2）各个shard将document返回给coordinate node（3）coordinate node将合并后的document结果返回给client客户端 bouncing results问题及解决方案 问题描述 12两个document排序，field值相同；不同的shard上，可能排序不同,因为每次请求轮询打到不同的replica shard上；导致每次页面上看到的搜索结果的排序都不一样。这就是bouncing result，也就是跳跃的结果。 解决方案 12让每个user每次搜索的时候，都使用同一个replica shard去执行比如使用：routing，document文档路由，_id路由 search_type参数 12default：query_then_fetchdfs_query_then_fetch (可以提升revelance sort精准度) 倒排索引 倒排索引的结构 123456（1）包含这个关键词的document list（2）包含这个关键词的所有document的数量：IDF（inverse document frequency）（3）这个关键词在每个document中出现的次数：TF（term frequency）（4）这个关键词在这个document中的次序（5）每个document的长度：length norm（6）包含这个关键词的所有document的平均长度 倒排索引不可变的好处与坏处 1234（1）不需要锁，提升并发能力，（2）数据不变，一直保存在os cache中，只要cache内存足够（3）可以压缩，节省cpu和io开销（4）但是每次都要重新构建整个索引 写入流程12345678910（1）数据写入buffer缓冲和translog日志文件（2）每隔一秒钟，buffer中的数据被写入新的segment file，并进入os cache，此时segment被打开并供search使用（3）buffer被清空（4）重复1~3，新的segment不断添加，buffer不断被清空，而translog中的数据不断累加（5）当translog长度达到一定程度的时候，commit操作发生 （5-1）buffer中的所有数据写入一个新的segment，并写入os cache，打开供使用 （5-2）buffer被清空 （5-3）一个commit ponit被写入磁盘，标明了所有的index segment （5-4）filesystem cache中的所有index segment file缓存数据，被fsync强行刷到磁盘上 （5-5）现有的translog被清空，创建一个新的translog 基于translog和commit point数据持久化和恢复123456789101112131415fsync后清空translog，就是flush操作默认每隔30分钟，或者当translog过大时flush POST /my_index/_flush，手动flush，但让它自动执行就可以了 translog，每隔5秒被fsync一次到磁盘上。在一次增删改操作之后，当fsync在primary shard和replica shard都成功之后，增删改操作才会成功但是这种在一次增删改时强行fsync translog可能会导致部分操作比较耗时 如果可以允许部分数据丢失，设置异步fsync： PUT /my_index/_settings&#123; &quot;index.translog.durability&quot;: &quot;async&quot;, &quot;index.translog.sync_interval&quot;: &quot;5s&quot;&#125; 海量磁盘文件合并1234567891011121314-合并原因：每秒生成一个segment file，文件过多，而且每次search都要搜索所有的segment，很耗时 -默认会在后台执行segment merge操作，在merge的时候，被标记为deleted的document也会被彻底物理删除 -每次merge操作的执行流程：（1）选择一些有相似大小的segment，merge成一个大的segment（2）将新的segment flush到磁盘上去（3）写一个新的commit point，包括了新的segment，并且排除旧的那些segment（4）将新的segment打开供搜索（5）将旧的segment删除 POST /my_index/_optimize?max_num_segments=1，尽量不要手动执行，让它自动默认执行就可以了","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yoursite.com/tags/elasticsearch/"}]},{"title":"elasticsearch(二、搜索引擎)","slug":"elasticsearch(二、搜索引擎)","date":"2018-03-04T02:22:03.000Z","updated":"2018-03-04T03:01:46.000Z","comments":true,"path":"2018/03/04/elasticsearch(二、搜索引擎)/","link":"","permalink":"http://yoursite.com/2018/03/04/elasticsearch(二、搜索引擎)/","excerpt":"搜索引擎-基本原理搜索的timeout机制 GET /_search返回123456789101112131415161718192021222324&#123; &quot;took&quot;: 6, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 6, &quot;successful&quot;: 6, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 10, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;.kibana&quot;, &quot;_type&quot;: &quot;config&quot;, &quot;_id&quot;: &quot;5.2.0&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;buildNum&quot;: 14695 &#125; &#125; ] &#125;&#125;","text":"搜索引擎-基本原理搜索的timeout机制 GET /_search返回123456789101112131415161718192021222324&#123; &quot;took&quot;: 6, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 6, &quot;successful&quot;: 6, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 10, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;.kibana&quot;, &quot;_type&quot;: &quot;config&quot;, &quot;_id&quot;: &quot;5.2.0&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;buildNum&quot;: 14695 &#125; &#125; ] &#125;&#125; 参数解释12345678910took：整个搜索请求花费了多少毫秒 hits.total：返回结果数hits.max_score：最大的相关度分数hits.hits：默认查询前10条完整数据，按照_score降序排序 shards：一个搜索请求，会打到一个index的所有primary shard上去，也可以到primary shard的其中一个replica shard上去。 timeout：默认无timeout，手动指定timeout=10ms，timeout=1s，timeout=1mGET /_search?timeout=10m multi-index和multi-type搜索模式12345678/_search：所有索引，所有type下的所有数据都搜索出来/index1/_search：指定一个index，搜索其下所有type的数据/index1,index2/_search：同时搜索两个index下的数据/*1,*2/_search：按照通配符去匹配多个索引/index1/type1/_search：搜索一个index下指定的type的数据/index1/type1,type2/_search：可以搜索一个index下多个type的数据/index1,index2/type1,type2/_search：搜索多个index下的多个type的数据/_all/type1,type2/_search：_all，可以代表搜索所有index下的指定type的数据 query string基础语法 包含与不包含 12345上面两个等价：GET /test_index/test_type/_search?q=test_field:testGET /test_index/test_type/_search?q=+test_field:test GET /test_index/test_type/_search?q=-test_field:test _all metadata的原理和作用 12345678GET /test_index/test_type/_search?q=test 1)插入一条document，它里面包含了多个field，此时，es会自动将多个field的值，全部用字符串的方式串联起来，变成一个长的字符串，作为_all field的值，同时建立索引 2)如果在搜索的时候，没有对某个field指定搜索，就默认搜索_all field，其中是包含了所有field的值的 3)生产环境不使用 一个例子告诉你mapping是什么1234567891011121314151617181920212223242526272829303132插入几条数据，让es自动为我们建立一个索引 PUT /website/article/1&#123; &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;title&quot;: &quot;my first article&quot;, &quot;content&quot;: &quot;this is my first article in this website&quot;, &quot;author_id&quot;: 11400&#125; PUT /website/article/2&#123; &quot;post_date&quot;: &quot;2017-01-02&quot;, &quot;title&quot;: &quot;my second article&quot;, &quot;content&quot;: &quot;this is my second article in this website&quot;, &quot;author_id&quot;: 11400&#125; PUT /website/article/3&#123; &quot;post_date&quot;: &quot;2017-01-03&quot;, &quot;title&quot;: &quot;my third article&quot;, &quot;content&quot;: &quot;this is my third article in this website&quot;, &quot;author_id&quot;: 11400&#125; 尝试各种搜索 GET /website/article/_search?q=2017 3条结果 GET /website/article/_search?q=2017-01-01 3条结果GET /website/article/_search?q=post_date:2017-01-01 1条结果GET /website/article/_search?q=post_date:2017 1条结果 1231)index中的type建立的一种数据结构和相关配置，简称为mapping2)dynamic mapping:自动为我们建立index，type，以及type对应的mapping，mapping中包含了每个field对应的数据类型，以及如何分词等设置 揭密 12345678910date：exact value (不分词)_all：full text（分词） GET /_search?q=2017搜索的是_all field，document所有的field都会拼接成一个大串，进行分词 GET /_search?q=post_date:2017-01-01date类型会作为exact value去建立索引 GET /_search?q=post_date:2017 内部优化 查看mapping： 1GET /website/_mapping/article 查看分词器 12345GET /_analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;Text to analyze&quot;&#125; 分词器 作用 123切分词语,同时对每个单词进行normalization（时态转换，单复数转换）,提升recall召回率 召回率：搜索的时候，增加能够搜索到的结果的数量 123character filter：一段文本分词前，先预处理，比如过滤html标签（&lt;span&gt;hello&lt;span&gt; --&gt; hello），&amp; --&gt; and（I&amp;you --&gt; I and you）tokenizer：分词，hello you and me --&gt; hello, you, and, metoken filter：lowercase，stop word，synonymom，dogs --&gt; dog，liked --&gt; like，Tom --&gt; tom，a/the/an --&gt; 干掉，mother --&gt; mom，small --&gt; little 内置分词器的介绍 123456Set the shape to semi-transparent by calling set_trans(5) standard analyzer=&gt;set, the, shape, to, semi, transparent,by, calling, set_trans, 5（默认）simple analyzer=&gt;set, the, shape, to, semi, transparent, by, calling, set, transwhitespace analyzer=&gt;Set, the, shape, to, semi-transparent, by, calling, set_trans(5)language analyzer（特定的语言的分词器，english，英语分词器）=&gt;set, shape, semi, transpar, call, set_tran, 5 核心的数据类型12345stringbyte，short，integer，longfloat，doublebooleandate dynamic mapping 12345true or false --&gt; boolean123 --&gt; long123.45 --&gt; double2017-01-01 --&gt; date&quot;hello world&quot; --&gt; string/text 查看mapping 1GET /index/_mapping/type 定制mapping1只能创建index时手动建立mapping，或者新增field mapping，但是不能update field mapping 修改mapping 1234567891011121314151617181920212223242526PUT /website&#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;author_id&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;english&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;post_date&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;publisher_id&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125; &#125; &#125; &#125;&#125; 测试mapping 1234567891011121314151617181920212223242526272829303132333435363738新增mapping：PUT /website/_mapping/article&#123; &quot;properties&quot; : &#123; &quot;new_field&quot; : &#123; &quot;type&quot; : &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125; &#125;&#125; 测试mapping:GET /website/_analyze&#123; &quot;field&quot;: &quot;content&quot;, &quot;text&quot;: &quot;my-dogs&quot; &#125; 测试index属性为“not_analyzed”的mapping时会报错：GET website/_analyze&#123; &quot;field&quot;: &quot;new_field&quot;, &quot;text&quot;: &quot;my dogs&quot;&#125; &#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;remote_transport_exception&quot;, &quot;reason&quot;: &quot;[4onsTYV][127.0.0.1:9300][indices:admin/analyze[s]]&quot; &#125; ], &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Can&apos;t process field [new_field], Analysis requests are only supported on tokenized fields&quot; &#125;, &quot;status&quot;: 400&#125; 复杂数据类型 multivalue field 123&#123; &quot;tags&quot;: [ &quot;tag1&quot;, &quot;tag2&quot; ]&#125;数据类型不能混 empty field 1null，[]，[null] object field 1234567891011PUT /company/employee/1&#123; &quot;address&quot;: &#123; &quot;country&quot;: &quot;china&quot;, &quot;province&quot;: &quot;guangdong&quot;, &quot;city&quot;: &quot;guangzhou&quot; &#125;, &quot;name&quot;: &quot;jack&quot;, &quot;age&quot;: 27, &quot;join_date&quot;: &quot;2017-01-01&quot;&#125; 123查看mappingGET /company/_mapping/employee 12345678910底层转换为：&#123; &quot;name&quot;: [jack], &quot;age&quot;: [27], &quot;join_date&quot;: [2017-01-01], &quot;address.country&quot;: [china], &quot;address.province&quot;: [guangdong], &quot;address.city&quot;: [guangzhou]&#125; object 数组底层转换： 1234567891011121314&#123; &quot;authors&quot;: [ &#123; &quot;age&quot;: 26, &quot;name&quot;: &quot;Jack White&quot;&#125;, &#123; &quot;age&quot;: 55, &quot;name&quot;: &quot;Tom Jones&quot;&#125;, &#123; &quot;age&quot;: 39, &quot;name&quot;: &quot;Kitty Smith&quot;&#125; ]&#125; =&gt; &#123; &quot;authors.age&quot;: [26, 55, 39], &quot;authors.name&quot;: [jack, white, tom, jones, kitty, smith]&#125; 搜索引擎-深入搜索组合多个搜索条件 Query DSL的基本语法 123456789101112131415&#123; QUERY_NAME: &#123; ARGUMENT: VALUE, ARGUMENT: VALUE,... &#125;&#125;&#123; QUERY_NAME: &#123; FIELD_NAME: &#123; ARGUMENT: VALUE, ARGUMENT: VALUE,... &#125; &#125;&#125; 搜索需求 1title必须包含elasticsearch，content可以包含elasticsearch也可以不包含，author_id必须不为111 12345678910111213141516171819202122232425262728GET /website/article/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;elasticsearch&quot; &#125; &#125; ], &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;elasticsearch&quot; &#125; &#125; ], &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;author_id&quot;: 111 &#125; &#125; ] &#125; &#125;&#125; should中传多个值 1minimum_should_match: should中至少满足一项 12345678910111213141516GET /test_index/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match&quot;: &#123; &quot;name&quot;: &quot;tom&quot; &#125;&#125;, &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;hired&quot;: true &#125;&#125;, &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match&quot;: &#123; &quot;personality&quot;: &quot;good&quot; &#125;&#125;, &quot;must_not&quot;: &#123; &quot;match&quot;: &#123; &quot;rude&quot;: true &#125;&#125; &#125;&#125; ], &quot;minimum_should_match&quot;: 1 &#125; &#125;&#125; filter 搜索请求 1年龄必须大于等于30，同时join_date必须是2016-01-01 123456789101112131415161718192021GET /company/employee/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;join_date&quot;: &quot;2016-01-01&quot; &#125; &#125; ], &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;age&quot;: &#123; &quot;gte&quot;: 30 &#125; &#125; &#125; &#125; &#125;&#125; filter与query对比 12filter，仅仅只是按照搜索条件过滤出需要的数据，不计算任何相关度分数，对相关度没有任何影响query，会去计算每个document相对于搜索条件的相关度，并按照相关度排序 12你希望越符合这些搜索条件的document越排在前面，那么这些搜索条件要放在query中；如果你不希望一些搜索条件来影响你的document排序，那么就放在filter中 filter与query性能 12filter，不需要计算相关度分数，不需要按照相关度分数进行排序，同时还有内置的自动cache最常使用filter的数据query，相反，要计算相关度分数，按照分数进行排序，而且无法cache结果 常用query搜索语法 match all 123456GET /_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; match 1234GET /_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;my elasticsearch article&quot; &#125;&#125;&#125; multi match 123456789GET /test_index/test_type/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;test&quot;, &quot;fields&quot;: [&quot;test_field&quot;, &quot;test_field1&quot;] &#125; &#125;&#125; range query 12345678910GET /company/employee/_search &#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; &quot;age&quot;: &#123; &quot;gte&quot;: 30 &#125; &#125; &#125;&#125; term query 12345678GET /test_index/test_type/_search &#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;test_field&quot;: &quot;test hello&quot; &#125; &#125;&#125; terms query 1234GET /_search&#123; &quot;query&quot;: &#123; &quot;terms&quot;: &#123; &quot;tag&quot;: [ &quot;search&quot;, &quot;full_text&quot;, &quot;nosql&quot; ] &#125;&#125;&#125; 多条件组合查询 层级说明 12345boolmust，must_not，should，filter -每个子查询都会计算一个document针对它的相关度分数，然后bool综合所有分数，合并为一个分数-当然filter是不会计算分数 查询案例 1234567891011121314151617181920&#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;how to make millions&quot; &#125;&#125;, &quot;must_not&quot;: &#123; &quot;match&quot;: &#123; &quot;tag&quot;: &quot;spam&quot; &#125;&#125;, &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;tag&quot;: &quot;starred&quot; &#125;&#125; ], &quot;filter&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;range&quot;: &#123; &quot;date&quot;: &#123; &quot;gte&quot;: &quot;2014-01-01&quot; &#125;&#125;&#125;, &#123; &quot;range&quot;: &#123; &quot;price&quot;: &#123; &quot;lte&quot;: 29.99 &#125;&#125;&#125; ], &quot;must_not&quot;: [ &#123; &quot;term&quot;: &#123; &quot;category&quot;: &quot;ebooks&quot; &#125;&#125; ] &#125; &#125; &#125;&#125; 使filter结果带相关度分数（分数为1） 1234567891011121314GET /company/employee/_search &#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;age&quot;: &#123; &quot;gte&quot;: 30 &#125; &#125; &#125; &#125; &#125;&#125; 定位不合法搜索及其原因12345678910111213GET /test_index/test_type/_validate/query?explain&#123; &quot;query&quot;: &#123; &quot;match-match&quot;: &#123; &quot;test_field&quot;: &quot;test&quot; &#125; &#125;&#125; &#123; &quot;valid&quot;: false, &quot;error&quot;: &quot;org.elasticsearch.common.ParsingException: no [query] registered for [match-match]&quot;&#125; 定制搜索结果的排序规则123默认情况下按照_score降序排序的然而，某些情况下，可能没有有用的_score，比如filter 自定义排序规则 123456789101112131415161718192021GET /company/employee/_search &#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;age&quot;: &#123; &quot;gte&quot;: 30 &#125; &#125; &#125; &#125; &#125;, &quot;sort&quot;: [ &#123; &quot;join_date&quot;: &#123; &quot;order&quot;: &quot;asc&quot; &#125; &#125; ]&#125; field索引两次防止分词影响排序1field建立两次索引，一个分词，用来搜索；一个不分词，用来排序 创建mapping 12345678910111213141516171819202122232425262728PUT /website &#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;raw&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125; &#125;, &quot;fielddata&quot;: true &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;post_date&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;author_id&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125; &#125; &#125; &#125;&#125; 创建索引 123456789PUT /website/article/1&#123; &quot;title&quot;: &quot;first article&quot;, &quot;content&quot;: &quot;this is my second article&quot;, &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;author_id&quot;: 110&#125; ... 搜索排序方式 12345678910111213GET /website/article/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [ &#123; &quot;title.raw&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125; ]&#125; 使用scoll技术滚动搜索大量数据 指定一个scoll参数，指定一个时间窗口(1分钟) 12345678GET /test_index/test_type/_search?scroll=1m&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [ &quot;_doc&quot; ], &quot;size&quot;: 3&#125; 获得的结果会有一个scoll_id，下一次再发送scoll请求的时候，必须带scoll_id 12345GET /_search/scroll&#123; &quot;scroll&quot;: &quot;1m&quot;, &quot;scroll_id&quot; : &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAACxeFjRvbnNUWVZaVGpHdklqOV9zcFd6MncAAAAAAAAsYBY0b25zVFlWWlRqR3ZJajlfc3BXejJ3AAAAAAAALF8WNG9uc1RZVlpUakd2SWo5X3NwV3oydwAAAAAAACxhFjRvbnNUWVZaVGpHdklqOV9zcFd6MncAAAAAAAAsYhY0b25zVFlWWlRqR3ZJajlfc3BXejJ3&quot;&#125; 1234以此类推，看起来挺像分页，但使用场景不一样 分页主要是用来一页一页搜索，给用户看的；scoll主要是用来一批一批检索数据，让系统进行处理的","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yoursite.com/tags/elasticsearch/"}]},{"title":"elasticsearch(一、核心概念和机制)","slug":"elasticsearch(一、核心概念和机制)","date":"2018-03-03T10:04:03.000Z","updated":"2018-03-04T03:01:44.000Z","comments":true,"path":"2018/03/03/elasticsearch(一、核心概念和机制)/","link":"","permalink":"http://yoursite.com/2018/03/03/elasticsearch(一、核心概念和机制)/","excerpt":"1.ES核心概念数据库搜索 每次都要对每条记录的所有文本进行扫描 不能将搜索词拆分开来，不能尽可能去搜索更多的符合你的期望的结果 全文检索和Lucene lucene，就是一个jar包，里面包含了封装好的各种建立倒排索引，以及进行搜索的代码，包括各种算法 单机应用，只能在单台服务器上使用，最多只能处理单台服务器可以处理的数据量","text":"1.ES核心概念数据库搜索 每次都要对每条记录的所有文本进行扫描 不能将搜索词拆分开来，不能尽可能去搜索更多的符合你的期望的结果 全文检索和Lucene lucene，就是一个jar包，里面包含了封装好的各种建立倒排索引，以及进行搜索的代码，包括各种算法 单机应用，只能在单台服务器上使用，最多只能处理单台服务器可以处理的数据量 Elasticsearch的特点 可以作为一个大型分布式集群（数百台服务器）技术，处理PB级数据，可以开箱即用 数据库的功能面对很多领域是不够用的（数据库特点是事务，还有各种联机事务型的操作） Elasticsearch作为传统数据库的一个补充，提供了数据库所不不能提供的很多功能，比如全文检索，同义词处理，相关度排名，复杂数据分析，海量数据的近实时处理 elasticsearch的核心概念 Near Realtime（NRT）：近实时，两个意思，从写入数据到数据可以被搜索到有一个小延迟（大概1秒）；基于es执行搜索和分析可以达到秒级 Cluster：集群，包含多个节点，每个节点属于哪个集群是通过一个配置来决定的（集群名称，默认是elasticsearch），刚开始一个集群就一个节点很正常 Node：节点，集群中的一个节点，节点也有一个名称（默认是随机分配的），节点名称很重要（在执行运维管理操作的时候），默认节点会去加入一个名称为“elasticsearch”的集群，如果直接启动一堆节点，那么它们会自动组成一个elasticsearch集群，当然一个节点也可以组成一个elasticsearch集群 Document&amp;field：文档，es中的最小数据单元，一个document可以是一条客户数据，一条商品分类数据，一条订单数据，通常用JSON数据结构表示，每个index下的type中都可以去存储多个document。一个document里面有多个field，每个field就是一个数据字段。 Index：索引，包含一堆有相似结构的文档数据，比如可以有一个客户索引，商品分类索引，订单索引，索引有一个名称。一个index包含很多document，一个index就代表了一类类似的或者相同的document。比如说建立一个product index，商品索引，里面可能就存放了所有的商品数据，所有的商品document。 Type：类型，每个索引里都可以有一个或多个type，type是index中的一个逻辑数据分类，一个type下的document，都有相同的field，比如博客系统，有一个索引，可以定义用户数据type，博客数据type，评论数据type。 shard：单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储。有了shard就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个shard都是一个lucene index。 replica：任何一个服务器随时可能故障或宕机，此时shard可能就会丢失，因此可以为每个shard创建多个replica副本。replica可以在shard故障时提供备用服务，保证数据不丢失，多个replica还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认5个），replica shard（随时修改数量，默认1个），默认每个索引10个shard，5个primary shard，5个replica shard，最小的高可用配置，是2台服务器。 windows安装启用Elasticsearch 安装JDK，至少1.8.0_73以上版本，java -version 下载解压Elasticsearch安装包，检查ES是否启动成功123bin\\elasticsearch.bat http://localhost:9200/?pretty 12345678910111213&#123; &quot;name&quot; : &quot;A4YNgZ-&quot;, //node名称 &quot;cluster_name&quot; : &quot;elasticsearch&quot;, //集群名称（默认的集群名称就是elasticsearch） &quot;cluster_uuid&quot; : &quot;0kJM3OexTYqD4y6-dSkThw&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;5.2.0&quot;, &quot;build_hash&quot; : &quot;24e05b9&quot;, &quot;build_date&quot; : &quot;2017-01-24T19:52:35.800Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;6.4.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 修改集群名称：elasticsearch.yml 使用Kibana123bin\\kibana.bat http://localhost:5601进入Dev Tools界面GET _cluster/health 简单的集群管理和文档操作 快速检查集群的健康状况 12345GET /_cat/health?v green：每个索引的primary shard和replica shard都是active状态的yellow：每个索引的primary shard都是active状态的，但是部分replica shard不是active状态，处于不可用的状态red：不是所有索引的primary shard都是active状态的，部分索引有数据丢失了 快速查看集群中有哪些索引 1GET /_cat/indices?v 简单的索引操作 12创建索引：PUT /test_index?pretty删除索引：DELETE /test_index?pretty CRUD操作 123456PUT /index/type/id&#123; &quot;json数据&quot;&#125; es会自动建立index和type，不需要提前创建，而且es默认会对document每个field都建立倒排索引，让其可以被搜索 12检索文档: GET /index/type/id 1234567891.替换和新增语法一样2.替换方式有一个不好，即使必须带上所有的field，才能进行信息的修改3.部分field更新语法：POST /ecommerce/product/1/_update&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;jiaqiangban gaolujie yagao&quot; &#125;&#125; 12删除文档：DELETE /ecommerce/product/1 多种搜索方式 搜索全部商品：GET /ecommerce/product/_search 123456took：耗费了几毫秒timed_out：是否超时，这里是没有_shards：数据拆成了5个分片，所以对于搜索请求，会打到所有的primary shard（或者是它的某个replica shard也可以）hits.total：查询结果的数量，3个documenthits.max_score：score的含义，就是document对于一个search的相关度的匹配分数，越相关，就越匹配，分数也高hits.hits：包含了匹配搜索的document的详细数据 query string search 123搜索商品名称中包含yagao的商品，而且按照售价降序排序：GET /ecommerce/product/_search?q=name:yagao&amp;sort=price:desc适用于临时的在命令行使用一些工具，比如curl,如果查询请求很复杂，很难去构建 query DSL 1234567891011121314151617181920212223242526272829303132333435DSL：Domain Specified Language，特定领域的语言 查询所有的商品:GET /ecommerce/product/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; 查询名称包含yagao的商品，同时按照价格降序排序:GET /ecommerce/product/_search&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;name&quot; : &quot;yagao&quot; &#125; &#125;, &quot;sort&quot;: [ &#123; &quot;price&quot;: &quot;desc&quot; &#125; ]&#125; 分页查询商品:GET /ecommerce/product/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;from&quot;: 0, &quot;size&quot;: 1&#125; 指定要查询出来商品后要展示的字段GET /ecommerce/product/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;_source&quot;: [&quot;name&quot;, &quot;price&quot;]&#125; query filter 123456789101112131415161718搜索商品名称包含yagao，而且售价大于25元的商品GET /ecommerce/product/_search&#123; &quot;query&quot; : &#123; &quot;bool&quot; : &#123; &quot;must&quot; : &#123; &quot;match&quot; : &#123; &quot;name&quot; : &quot;yagao&quot; &#125; &#125;, &quot;filter&quot; : &#123; &quot;range&quot; : &#123; &quot;price&quot; : &#123; &quot;gt&quot; : 25 &#125; &#125; &#125; &#125; &#125;&#125; full-text search（全文检索） 12345678910GET /ecommerce/product/_search&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;producer&quot; : &quot;yagao producer&quot; &#125; &#125;&#125; producer这个字段，会先被拆解，建立倒排索引 phrase search（短语搜索） 123456789101112GET /ecommerce/product/_search&#123; &quot;query&quot; : &#123; &quot;match_phrase&quot; : &#123; &quot;producer&quot; : &quot;yagao producer&quot; &#125; &#125;&#125; 全文检索会将输入的搜索串拆解开来，去倒排索引里面去一一匹配，只要能匹配上任意一个拆解后的单词，就可以作为结果返回 phrase search，要求输入的搜索串，必须在指定的字段文本中，完全包含一模一样的，才可以算匹配，才能作为结果返回 highlight search（高亮搜索结果） 12345678910111213GET /ecommerce/product/_search&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;producer&quot; : &quot;producer&quot; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot; : &#123; &quot;producer&quot; : &#123;&#125; &#125; &#125;&#125; 2.ES核心机制shard&amp;replica机制12345678(1)index包含多个shard(2)每个shard都是一个最小工作单元，承载部分数据，lucene实例，完整的建立索引和处理请求的能力(3)每个document肯定只存在于某一个primary shard以及其对应的replica shard中，不可能存在于多个primary shard(4)replica shard是primary shard的副本，负责容错，以及承担读请求负载(5)primary shard的数量在创建索引的时候就固定了，replica shard的数量可以随时修改(6)primary shard的默认数量是5，replica默认是1，默认有10个shard，5个primary shard，5个replica shard(7)primary shard不能和自己的replica shard放在同一个节点上（否则节点宕机，primary shard和副本都丢失，起不到容错的作用），但是可以和其他primary shard的replica shard放在同一个节点上 单node环境下创建index是什么样子的1234（1）单node环境下，创建一个index，有3个primary shard，3个replica shard（2）集群status是yellow（3）这个时候，只会将3个primary shard分配到仅有的一个node上去，另外3个replica shard是无法分配的（4）集群可以正常工作，但是一旦出现节点宕机，数据全部丢失，而且集群不可用，无法承接任何请求 手动指定index的分片信息 1234567PUT /test_index&#123; &quot;settings&quot; : &#123; &quot;number_of_shards&quot; : 3, &quot;number_of_replicas&quot; : 1 &#125;&#125; 横向扩容，提升容错1234(1)primary&amp;replica自动负载均衡，6个shard=&gt;3 primary，3 replica(2)每个node有更少的shard，IO/CPU/Memory资源给每个shard分配更多，每个shard性能更好(3)扩容的极限=&gt;6个shard（3 primary，3 replica），最多扩容到6台机器(4)超出扩容极限，动态修改replica数量,9个shard（3primary，6 replica），扩容到9台机器 Elasticsearch容错机制123(1)master node宕机，自动master选举，状态red(2)replica容错：新master将replica提升为primary shard，状态yellow(3)重启宕机node，master copy 原来的replica到该node，再同步下宕机后的修改，状态green 元数据 _index元数据 1234(1)代表一个document存放在哪个index中(2)类似的数据放在一个索引，非类似的数据放不同索引 (类似：这些document的fields很大一部分是相同的)(3)索引名称必须是小写的，不能用下划线开头，不能包含逗号 _type元数据 1234(1)代表document属于index中的哪个类别（type）(2)一个索引通常会划分为多个type,不同type会有少数fields是不一样的（举个例子：商品，可能划分为电子商品，生鲜商品，日化商品）(3)type名称可以是大写或者小写，但是同时不能用下划线开头，不能包含逗号 _id元数据 123(1)代表document的唯一标识，与index和type一起，可以唯一标识和定位一个document(2)我们可以手动指定document的id（put /index/type/id），也可以不指定，由es自动为我们创建一个id(自动生成的id，长度为20个字符，URL安全，base64编码，GUID，分布式系统并行生成时不可能会发生冲突) 自动生成id（不能用put） 1234POST /test_index/test_type&#123; &quot;test_content&quot;: &quot;my test&quot;&#125; 定制返回结果 _source元数据（指定id的方式查询，会原封不动返回） 12345678910111213141516171819put /test_index/test_type/1&#123; &quot;test_field1&quot;: &quot;test field1&quot;, &quot;test_field2&quot;: &quot;test field2&quot;&#125; get /test_index/test_type/1 &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;test_field1&quot;: &quot;test field1&quot;, &quot;test_field2&quot;: &quot;test field2&quot; &#125;&#125; 指定_source返回哪些field： 1GET /test_index/test_type/1?_source=test_field1,test_field2 全量替换、强制创建、lazy delete机制 document的全量替换 123(1)语法与创建文档是一样的，如果document id不存在，就是创建；如果document id已经存在，就是全量替换操作(2)es会将老的document标记为deleted，然后新增我们给定的一个document，当我们创建越来越多的document的时候，es会在适当的时机在后台自动删除标记为deleted的document document的强制创建 12PUT /index/type/id?op_type=createPUT /index/type/id/_create document的删除 12DELETE /index/type/id也只会将其标记为deleted，当数据越来越多的时候，在后台自动删除 Elasticsearch内部基于_version进行乐观锁并发控制 _version元数据 12345678910111213141516171819202122PUT /test_index/test_type/6&#123; &quot;test_field&quot;: &quot;test test&quot;&#125; &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;6&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true&#125; 第一次创建一个document的时候，它的_version内部版本号就是1；以后，每次对这个document执行修改或者删除操作，都会对这个_version版本号自动加1；哪怕是删除，也会对这条数据的版本号加1 删除操作 12345678910111213141516&#123; &quot;found&quot;: true, &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;6&quot;, &quot;_version&quot;: 4, &quot;result&quot;: &quot;deleted&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;&#125; 可以从一个侧面证明，它不是立即物理删除掉的，因为它的一些版本号等信息还是保留着的。先删除一条document，再重新创建这条document，会在delete version基础之上，再把version号加1 基于_version进行乐观锁并发控制 123456789101112131415161718192021更新数据,同时带上数据的版本号es中的数据的版本号，跟客户端中的数据的版本号是相同的，才能修改 PUT /test_index/test_type/7?version=1 &#123; &quot;test_field&quot;: &quot;test client 1&quot;&#125; &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;7&quot;, &quot;_version&quot;: 2, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: false&#125; 12345?version=1?version=1&amp;version_type=external 两种方式唯一的区别在于，_version，只有当你提供的version与es中的_version一模一样的时候，才可以进行修改，只要不一样，就报错；当version_type=external的时候，只有当你提供的version比es中的_version大的时候，才能完成修改 partial update123456post /index/type/id/_update &#123; &quot;doc&quot;: &#123; &quot;要修改的少数几个field即可，不需要全量的数据&quot; &#125;&#125; 相较与全量替换 121.全量替换需要执行查询操作，看有哪些字段。partial update只需关系要修改的字段。2.减少网络开销，减少并发冲突 基于groovy脚本，如何执行partial update 12345PUT /test_index/test_type/11&#123; &quot;num&quot;: 0, &quot;tags&quot;: []&#125; 123456内置脚本 POST /test_index/test_type/11/_update&#123; &quot;script&quot; : &quot;ctx._source.num+=1&quot;&#125; 1234567891011121314外部脚本 ctx._source.tags+=new_tag POST /test_index/test_type/11/_update&#123; &quot;script&quot;: &#123; &quot;lang&quot;: &quot;groovy&quot;, &quot;file&quot;: &quot;test-add-tags&quot;, &quot;params&quot;: &#123; &quot;new_tag&quot;: &quot;tag1&quot; &#125; &#125;&#125; 1234567891011121314用脚本删除文档 ctx.op = ctx._source.num == count ? &apos;delete&apos; : &apos;none&apos;POST /test_index/test_type/11/_update&#123; &quot;script&quot;: &#123; &quot;lang&quot;: &quot;groovy&quot;, &quot;file&quot;: &quot;test-delete-document&quot;, &quot;params&quot;: &#123; &quot;count&quot;: 1 &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142upsert操作 POST /test_index/test_type/11/_update&#123; &quot;doc&quot;: &#123; &quot;num&quot;: 1 &#125;&#125; 报错，文档不存在： &#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;document_missing_exception&quot;, &quot;reason&quot;: &quot;[test_type][11]: document missing&quot;, &quot;index_uuid&quot;: &quot;6m0G7yx7R1KECWWGnfH1sw&quot;, &quot;shard&quot;: &quot;4&quot;, &quot;index&quot;: &quot;test_index&quot; &#125; ], &quot;type&quot;: &quot;document_missing_exception&quot;, &quot;reason&quot;: &quot;[test_type][11]: document missing&quot;, &quot;index_uuid&quot;: &quot;6m0G7yx7R1KECWWGnfH1sw&quot;, &quot;shard&quot;: &quot;4&quot;, &quot;index&quot;: &quot;test_index&quot; &#125;, &quot;status&quot;: 404&#125; 如果指定的document不存在，就执行upsert中的初始化操作；如果指定的document存在，就执行doc或者script指定的partial update操作 POST /test_index/test_type/11/_update&#123; &quot;script&quot; : &quot;ctx._source.num+=1&quot;, &quot;upsert&quot;: &#123; &quot;num&quot;: 0, &quot;tags&quot;: [] &#125;&#125; partial update内置乐观锁并发控制 1234post /index/type/id/_update?retry_on_conflict=5&amp;version=6 retry_on_conflict: 重试5次每次都会基于最新版本号进行retry 3.分布式文档系统批量查询mget 一条一条的查询 12GET /test_index/test_type/1GET /test_index/test_type/2 批量查询的重要性 1尽可能减少网络开销次数,可以将性能提升数倍 mget批量查询 123456789101112131415GET /_mget&#123; &quot;docs&quot; : [ &#123; &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;test_type&quot;, &quot;_id&quot; : 1 &#125;, &#123; &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;test_type&quot;, &quot;_id&quot; : 2 &#125; ]&#125; 查询的document是同一个index下的不同type 12345678910111213GET /test_index/_mget&#123; &quot;docs&quot; : [ &#123; &quot;_type&quot; : &quot;test_type&quot;, &quot;_id&quot; : 1 &#125;, &#123; &quot;_type&quot; : &quot;test_type&quot;, &quot;_id&quot; : 2 &#125; ]&#125; 查询的document是同一个index下的同一个type 1234GET /test_index/test_type/_mget&#123; &quot;ids&quot;: [1, 2]&#125; bulk批量增删改 bulk语法 12345678POST /_bulk&#123; &quot;delete&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;3&quot; &#125;&#125; &#123; &quot;create&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;12&quot; &#125;&#125;&#123; &quot;test_field&quot;: &quot;test12&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;2&quot; &#125;&#125;&#123; &quot;test_field&quot;: &quot;replaced test2&quot; &#125;&#123; &quot;update&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_retry_on_conflict&quot; : 3&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;test_field2&quot; : &quot;bulk test1&quot;&#125; &#125; 1234每一个操作要两个json串，语法如下： &#123;&quot;action&quot;: &#123;&quot;metadata&quot;&#125;&#125;&#123;&quot;data&quot;&#125; 1234举例，比如你现在要创建一个文档，放bulk里面，看起来会是这样子的： &#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;, &quot;test_type&quot;, &quot;_id&quot;: &quot;1&quot;&#125;&#125;&#123;&quot;test_field1&quot;: &quot;test1&quot;, &quot;test_field2&quot;: &quot;test2&quot;&#125; 12345有哪些类型的操作可以执行呢？（1）delete：删除一个文档，只要1个json串就可以了（2）create：PUT /index/type/id/_create，强制创建（3）index：普通的put操作，可以是创建文档，也可以是全量替换文档（4）update：执行的partial update操作 12bulk api对json的语法，有严格的要求，每个json串不能换行，只能放一行，同时一个json串和一个json串之间，必须有一个换行 1bulk操作中，任意一个操作失败，是不会影响其他的操作的，但是在返回结果里，会告诉你异常日志 限定index或type 123456789101112131415161718192021POST /test_index/_bulk&#123; &quot;delete&quot;: &#123; &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;3&quot; &#125;&#125; &#123; &quot;create&quot;: &#123; &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;12&quot; &#125;&#125;&#123; &quot;test_field&quot;: &quot;test12&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_type&quot;: &quot;test_type&quot; &#125;&#125;&#123; &quot;test_field&quot;: &quot;auto-generate id test&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;2&quot; &#125;&#125;&#123; &quot;test_field&quot;: &quot;replaced test2&quot; &#125;&#123; &quot;update&quot;: &#123; &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_retry_on_conflict&quot; : 3&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;test_field2&quot; : &quot;bulk test1&quot;&#125;&#125; POST /test_index/test_type/_bulk&#123; &quot;delete&quot;: &#123; &quot;_id&quot;: &quot;3&quot; &#125;&#125; &#123; &quot;create&quot;: &#123; &quot;_id&quot;: &quot;12&quot; &#125;&#125;&#123; &quot;test_field&quot;: &quot;test12&quot; &#125;&#123; &quot;index&quot;: &#123; &#125;&#125;&#123; &quot;test_field&quot;: &quot;auto-generate id test&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_id&quot;: &quot;2&quot; &#125;&#125;&#123; &quot;test_field&quot;: &quot;replaced test2&quot; &#125;&#123; &quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot;, &quot;_retry_on_conflict&quot; : 3&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;test_field2&quot; : &quot;bulk test1&quot;&#125;&#125; bulk size最佳大小 12bulk request会加载到内存里，如果太大的话，性能反而会下降，因此需要反复尝试一个最佳的bulk size1000~5000条数据开始，尝试逐渐增加。最好5~15MB之间 distributed document store ES适用场景 123- 数据量较大，es的分布式本质，可以帮助你快速扩容，承载大量数据- 数据结构灵活多变，随时可能会变化，而且数据结构之间的关系，非常复杂,面临大量的表- 对数据的相关操作，较为简单 document数据路由原理 12345678路由算法：shard = hash(routing) % number_of_primary_shards 举个例子:1）一个index有3个primary shard，P0，P1，P22）每次增删改查一个document的时候，都会带一个routing number,默认为 _id，假设_id=13)将hash函数产出的值对这个index的primary shard的数量求余数4)相同的routing值产出的hash值一定是相同的,hash值的 结果一定是在0~number_of_primary_shards-1之间这个范围内的。0,1,2 _id or custom routing value 12345671)默认的routing就是_id 2)在发送请求的时候指定一个routing value=&gt;put /index/type/id?routing=user_id(手动指定routing value是很有用的，可以保证某一类document一定被路由到一个shard上去，在后续进行应用级别的负载均衡，提升批量读取的性能很有帮助) 3)这也是primary shard数量不可变的谜底 document增删改内部原理1234（1）客户端选择一个node发送请求，这个node就是coordinating node（协调节点）（2）coordinating node，对document进行路由，将请求转发给对应的node（有primary shard）（3）primary shard处理请求，然后将数据同步到replica node（4）coordinating node，如果发现primary node和所有replica node都搞定之后，就返回响应结果给客户端 一致性原理和quorum机制123我们在发送任何一个增删改操作的时候，比如put /index/type/id，都可以带上一个consistency参数，指明我们想要的写一致性是什么: put /index/type/id?consistency=? 123one：写操作，只要有一个primary shard是active活跃可用的，就可以执行all：写操作，必须所有的primary shard和replica shard都是活跃的，才可以执行quorum：(default)要求所有的shard中，大部分的shard是活跃可用的，才可以执行 quorum机制计算 1234567quroum =int( (primary + number_of_replicas) / 2 ) + 1，当number_of_replicas&gt;1时才生效 举例：3个primary shard，number_of_replicas=1，总共有3 + 3 * 1 = 6个shardquorum = int( (3 + 1) / 2 ) + 1 = 3要求6个shard中至少有3个shard是active状态的，才可以执行这个写操作 quorum不齐全时: 1234quorum不齐全时=&gt; wait，默认1分钟 可以在写操作的时候，加一个timeout参数：put /index/type/id?timeout=30 document查询内部原理1234561)客户端发送请求到任意一个node，成为coordinate node2)coordinate node对document进行路由，将请求转发到对应的node，此时会使用round-robin随机轮询算法，将多个查询请求在primary shard以及其所有replica中负载均衡3）接收请求的node返回document给coordinate node4）coordinate node返回document给客户端5）特殊情况：在建立索引过程中，可能只有primary shard有document，导致无法读取到document bulk api奇特的json格式原因1231)bulk中的每个操作都可能要转发到不同的node的shard去执行2)不用将其转换为json对象，不会出现内存中的相同数据的拷贝，直接按照换行符切割json3)对每两个一组的json，读取meta，进行document路由,直接将对应的json发送到node上去","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yoursite.com/tags/elasticsearch/"}]},{"title":"【Java8函数式编程】","slug":"【Java8函数式编程】","date":"2018-03-03T07:23:03.000Z","updated":"2018-03-03T07:27:05.000Z","comments":true,"path":"2018/03/03/【Java8函数式编程】/","link":"","permalink":"http://yoursite.com/2018/03/03/【Java8函数式编程】/","excerpt":"1.Lambda匿名内部类12345678910111213button.addActionListener(new ActionListener()&#123; public void actionPerformed(ActionEvent event) &#123; System.out.println(\"button clicked\"); &#125;&#125;); 我们创建了一个实现了ActionListener接口的对象，重写了方法，（这个接口只有一个方法 actionPerformed） -使用lambada：button.addActionListener(event -&gt; System.out.println(\"button clicked\"));-其中：ActionListener oneArgument = event -&gt; System.out.println(\"button clicked\");","text":"1.Lambda匿名内部类12345678910111213button.addActionListener(new ActionListener()&#123; public void actionPerformed(ActionEvent event) &#123; System.out.println(\"button clicked\"); &#125;&#125;); 我们创建了一个实现了ActionListener接口的对象，重写了方法，（这个接口只有一个方法 actionPerformed） -使用lambada：button.addActionListener(event -&gt; System.out.println(\"button clicked\"));-其中：ActionListener oneArgument = event -&gt; System.out.println(\"button clicked\"); 编写 Lambda 表达式的不同形式123456789101112ActionListener oneArgument = event -&gt; System.out.println(\"button clicked\"); Runnable noArguments = () -&gt; System.out.println(\"Hello World\"); Runnable multiStatement = () -&gt; &#123; System.out.print(\"Hello\"); System.out.println(\" World\");&#125;;BinaryOperator&lt;Long&gt; add = (x, y) -&gt; x + y; BinaryOperator&lt;Long&gt; addExplicit = (Long x, Long y) -&gt; x + y; 使用 final 局部变量123456789101112131415161718-匿名内部类中引用final变量：final String name = getUserName();button.addActionListener(new ActionListener() &#123; public void actionPerformed(ActionEvent event) &#123; System.out.println(\"hi \" + name); &#125; &#125;); -必须将变量声明为final，不能为其重复赋值。使用final变量时，实际上在使用一个特定的值 -Lambda表达式中引用‘既成事实’的final变量（可以不声明为final，但不能二次赋值）String name = getUserName();button.addActionListener(event -&gt; System.out.println(\"hi \" + name)); -否则无法编译String name = getUserName();name = formatUserName(name);button.addActionListener(event -&gt; System.out.println(\"hi \" + name)); 类型推断123Predicate&lt;Integer&gt; atLeast5 = x -&gt; x &gt; 5; Predicate是一个有返回值的Lambda表达式，返回一个布尔值，返回值就是Lambda表达式主体的值。 123456BinaryOperator&lt;Long&gt; addLongs = (x, y) -&gt; x + y; 该接口接受两个参数，返回一个值，参数和值的类型均相同。实例中所用的类型是Long 没有泛型，代码则通不过编译：BinaryOperator add = (x, y) -&gt; x + y; 2.流for循环与迭代器12345678910111213141516171819int count = 0;for (Artist artist : allArtists) &#123; if (artist.isFrom(&quot;London&quot;)) &#123; count++; &#125; &#125;for循环其实是一个封装了迭代的语法糖，迭代过程通过显式调用Iterator对象的hasNext和next方法完成迭代： int count = 0;Iterator&lt;Artist&gt; iterator = allArtists.iterator(); while(iterator.hasNext()) &#123; Artist artist = iterator.next(); if (artist.isFrom(&quot;London&quot;)) &#123; count++; &#125;&#125; 以上都是外部迭代，是一种串行化操作 使用内部迭代接口Stream123456789long count = allArtists.stream() .filter(artist -&gt; artist.isFrom(&quot;London&quot;)) .count(); -我们并没有改变集合的内容，而是描述出Stream里的内容。count()方法计算给定Stream里包含多少个对象。 -filter只刻画出了Stream，但没有产生新的集合,叫作惰性求值方法,-count这样,最终会从Stream产生值的方法叫作及早求值方法。-如果返回值是Stream,那么是惰性求值;如果返回值是另一个值或为空，那么就是及早求值 常用的流操作 collect(toList()) 123456collect(toList())方法由Stream里的值生成一个列表，是一个及早求值操作 使用示例：List&lt;String&gt; collected = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) .collect(Collectors.toList()); assertEquals(Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), collected); map 1234567-使用map操作将字符串转换为大写形式：List&lt;String&gt; collected = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;hello&quot;) .map(string -&gt; string.toUpperCase()) .collect(toList());assertEquals(asList(&quot;A&quot;, &quot;B&quot;, &quot;HELLO&quot;), collected); -传给map的Lambda表达式只能包含一个参数，参数和返回值不必属于同一种类型 filter 1234找出一组字符串 中以数字开头的字符串:List&lt;String&gt; beginningWithNumbers = Stream.of(&quot;a&quot;, &quot;1abc&quot;, &quot;abc1&quot;) .filter(value -&gt; isDigit(value.charAt(0))) .collect(toList()); flatMap 123456flatMap可以将多个Stream连接成一个Stream： List&lt;Integer&gt; together = Stream.of(asList(1, 2), asList(3, 4)) .flatMap(numbers -&gt; numbers.stream()) .collect(toList());assertEquals(asList(1, 2, 3, 4), together); max和min 123456789101112使用 Stream 查找最短曲目:List&lt;Track&gt; tracks = asList(new Track(&quot;Bakai&quot;, 524), new Track(&quot;Violets for Your Furs&quot;, 378), new Track(&quot;Time Was&quot;, 451));Track shortestTrack = tracks.stream() .min(Comparator.comparing(track -&gt; track.getLength())) .get();assertEquals(tracks.get(1), shortestTrack); -为了让Stream对象按照曲目长度进行排序，需要传给它一个Comparator对象。-还可以调用空Stream的max方法，返回Optional对象。它代表一个可能存在也可能不存在的值。 通过调用 get 方法可以取出 Optional 对象中的值。 reduce 1234567891011121314reduce操作可以实现从一组值中生成一个值。因此，count、min和max都是reduce操作。 //生产环境不建议//BinaryOperator&lt;Integer&gt; accumulator = (acc, element) -&gt; acc + element;int count = Stream.of(1, 2, 3) .reduce(0, (acc, element) -&gt; acc + element);assertEquals(6, count); //使用命令式编程方式求和:int acc = 0;for (Integer element : asList(1, 2, 3)) &#123; acc = acc + element;&#125;assertEquals(6, acc); 整合操作 123456Set&lt;String&gt; origins = album.getMusicians() .filter(artist -&gt; artist.getName().startsWith(\"The\")) .map(artist -&gt; artist.getNationality()) .collect(toSet()); 调用getMusicians、filter和map方法都返回Stream对象,因此都属于惰性求值,而 collect 方法属于及早求值。 3.类库使用 summaryStatistics 方法统计曲目长度1234567891011121314public static void printTrackLengthStatistics(Album album) &#123; IntSummaryStatistics trackLengthStats = album.getTracks() .mapToInt(track -&gt; track.getLength()) .summaryStatistics(); System.out.printf(&quot;Max: %d, Min: %d, Ave: %f, Sum: %d&quot;, trackLengthStats.getMax(), trackLengthStats.getMin(), trackLengthStats.getAverage(), trackLengthStats.getSum());&#125; 这里使用对基本类型进行特殊处理的方法 mapToInt，将每首曲目映射为曲目长度。因为该方法返回一个 IntStream 对象，它包含一个 summaryStatistics 方法，这个方法能计算出各种各样的统计值 Optional 使用举例 1234567891011121314public static ToBean toTransBean(FromBean from) &#123; if (from == null) return null; ToBean to = new ToBean(); BeanUtils.copyProperties(from, to); return to;&#125; public static List&lt;ToBean&gt; toTransBeans(List&lt;FromBean&gt; froms)&#123; return Optional.ofNullable(froms).map(fs -&gt; &#123; return fs.stream().map(BeanTrans::toTransBean).collect(Collectors.toList()); &#125;).orElseGet(() -&gt; &#123; return froms == null ? null : new LinkedList&lt;&gt;(); &#125;);&#125; 常见方法 12345678910-Optional对象也可能为空，因此还有一个对应的工厂方法empty: Optional emptyOptional = Optional.empty(); -另外一个工厂方法 ofNullable 则可将一个空值转换成 Optional 对象: Optional alsoEmpty = Optional.ofNullable(null); -使用orElse方法,当Optional对象为空时，该方法提供了一个备选值-使用orElseGet方法,只有在Optional对象真正为空时才会调用 assertEquals(&quot;b&quot;, emptyOptional.orElse(&quot;b&quot;)); assertEquals(&quot;c&quot;, emptyOptional.orElseGet(() -&gt; &quot;c&quot;)); 4.高级集合类和收集器方法引用 Lambda表达式简写语法： 12345artist -&gt; artist.getName() =&gt; Artist::getName (name, nationality) -&gt; new Artist(name, nationality) =&gt;Artist::new (自动支持多个参数，前提是选对了正确的函数接口) 元素顺序 在一个有序集合中创建一个流时，流中的元素就按出现顺序排列 1234List&lt;Integer&gt; numbers = asList(1, 2, 3, 4);List&lt;Integer&gt; sameOrder = numbers.stream() .collect(toList());assertEquals(numbers, sameOrder); 如果集合本身就是无序的，由此生成的流也是无序的 12345Set&lt;Integer&gt; numbers = new HashSet&lt;&gt;(asList(4, 3, 2, 1));List&lt;Integer&gt; sameOrder = numbers.stream() .collect(toList());// 该断言有时会失败assertEquals(asList(4, 3, 2, 1), sameOrder); 并行流顺序处理 12使用并行流时，forEach方法不能保证元素是 按顺序处理的,如果需要保证按顺序处理，应该使用 forEachOrdered 方法 使用收集器 转换成其他集合 12345collect(toList()),生成了java.util.List类的实例,还有toSet和toCollection，分别生成Set和Collection类的实例 -调用toList或者toSet等方法时，不需要指定具体的类型-收集并行操作的结果需要的Set，和对线程安全没有要求的Set类是完全不同的-定制使用TreeSet：stream.collect(toCollection(TreeSet::new)); 利用收集器让流生成一个值 1234567891011-找出成员最多的乐队:public Optional&lt;Artist&gt; biggestGroup(Stream&lt;Artist&gt; artists) &#123; Function&lt;Artist,Long&gt; getCount = artist -&gt; artist.getMembers().count(); return artists.collect(maxBy(comparing(getCount)));&#125; -找出一组专辑上曲目的平均数public double averageNumberOfTracks(List&lt;Album&gt; albums) &#123; return albums.stream() .collect(averagingInt(album -&gt; album.getTrackList().size()));&#125; 数据分块 123456789-分块函数指明了艺术家是否为独唱歌手public Map&lt;Boolean, List&lt;Artist&gt;&gt; bandsAndSolo(Stream&lt;Artist&gt; artists) &#123; return artists.collect(partitioningBy(artist -&gt; artist.isSolo()));&#125; -上面代码可简写为：public Map&lt;Boolean, List&lt;Artist&gt;&gt; bandsAndSoloRef(Stream&lt;Artist&gt; artists) &#123; return artists.collect(partitioningBy(Artist::isSolo));&#125; 数据分组 1234-有一个由专辑组成的流，可以按专辑当中的主唱对专辑分组public Map&lt;Artist, List&lt;Album&gt;&gt; albumsByArtist(Stream&lt;Album&gt; albums) &#123; return albums.collect(groupingBy(album -&gt; album.getMainMusician()));&#125; 组合收集器 1234567891011-使用收集器计算每个艺术家的专辑数public Map&lt;Artist, Long&gt; numberOfAlbums(Stream&lt;Album&gt; albums) &#123; return albums.collect(groupingBy(album -&gt; album.getMainMusician(), counting()));&#125; -使用收集器求每个艺术家的专辑名public Map&lt;Artist, List&lt;String&gt;&gt; nameOfAlbums(Stream&lt;Album&gt; albums) &#123; return albums.collect(groupingBy(Album::getMainMusician, mapping(Album::getName, toList())));&#125; 使用内部迭代遍历 Map 里的值123456Map&lt;Artist, List&lt;Album&gt;&gt; albumsByArtist; Map&lt;Artist, Integer&gt; countOfAlbums = new HashMap&lt;&gt;();albumsByArtist.forEach((artist, albums) -&gt; &#123; countOfAlbums.put(artist, albums.size());&#125;); 5.数据并行化并行和并发12345-并行化是指为缩短任务执行时间，将一个任务分解成几部分,这和顺序执行的任务量是一样的,但（多核）CPU承载的工作量更大 -数据并行化是指将数据分成块，为每块数据分配单独的处理单元 -如果一个程序要运行两个任务，并且只有一个CPU给它们分配了不同的时间片，那么这就是并发，而不是并行 并行化流操作1stream方法替换为parallelStream方法 Future &amp; CompletableFuture Java8新的异步编程方式 CompletableFuture(一) Java8新的异步编程方式 CompletableFuture(二) Java8新的异步编程方式 CompletableFuture(三)","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/tags/读书笔记/"},{"name":"Java8","slug":"Java8","permalink":"http://yoursite.com/tags/Java8/"}]},{"title":"Mysql存储引擎和事务","slug":"Mysql存储引擎和事务","date":"2018-03-03T03:36:31.000Z","updated":"2018-03-04T03:02:08.000Z","comments":true,"path":"2018/03/03/Mysql存储引擎和事务/","link":"","permalink":"http://yoursite.com/2018/03/03/Mysql存储引擎和事务/","excerpt":"Mysql存储引擎MyISAM简介1234567891011121314151617181920212223242526创建myisam表mysql&gt; create table myIsam(id int,cl varchar(10))engine=myisam;Query OK, 0 rows affected 在centos系统中会产生3个文件：ls -l myIsam*myIsam.frm --- 表结构myIsam.MYD --- 数据信息myIsam.MYI --- 索引信息 检查表：（ok）mysql&gt; check table myIsam;+-------------+-------+----------+----------+| Table | Op | Msg_type | Msg_text |+-------------+-------+----------+----------+| test.myisam | check | status | OK |+-------------+-------+----------+----------+1 row in set 修复表：（ok）mysql&gt; repair table myIsam;+-------------+--------+----------+----------+| Table | Op | Msg_type | Msg_text |+-------------+--------+----------+----------+| test.myisam | repair | status | OK |+-------------+--------+----------+----------+1 row in set","text":"Mysql存储引擎MyISAM简介1234567891011121314151617181920212223242526创建myisam表mysql&gt; create table myIsam(id int,cl varchar(10))engine=myisam;Query OK, 0 rows affected 在centos系统中会产生3个文件：ls -l myIsam*myIsam.frm --- 表结构myIsam.MYD --- 数据信息myIsam.MYI --- 索引信息 检查表：（ok）mysql&gt; check table myIsam;+-------------+-------+----------+----------+| Table | Op | Msg_type | Msg_text |+-------------+-------+----------+----------+| test.myisam | check | status | OK |+-------------+-------+----------+----------+1 row in set 修复表：（ok）mysql&gt; repair table myIsam;+-------------+--------+----------+----------+| Table | Op | Msg_type | Msg_text |+-------------+--------+----------+----------+| test.myisam | repair | status | OK |+-------------+--------+----------+----------+1 row in set 使用场景12非事务型应用只读类应用（支持数据压缩） Innodb表空间1234567891011121314151617ON代表独立表空间：tablename.ibd OFF代表系统表空间：ibdataX （X为数字）mysql&gt; show variables like 'innodb_file_per_table';+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| innodb_file_per_table | ON |+-----------------------+-------+1 row in set创建innodb表：mysql&gt; create table myinnodb(id int,cl varchar(10))engine='innodb';Query OK, 0 rows affected centos系统下：ls -lh myinnodb*myinnodb.frm ---表结构myinnodb.ibd 123456系统表空间和独立表空间如何选择- 系统表空间无法简单的收缩文件大小，空间浪费，磁盘碎片- 独立表空间可以通过optimize table命令收缩系统文件- 系统表空间产生IO瓶颈- 独立表空间可以同时向多个文件刷新数据- 对Innodb使用独立表空间 Innodb存储引擎特性12345678910111213141516171819- Innodb是一种事务性存储引擎- 完全支持事务的ACID特性- Redo Log（已提交事务）Undo Log（未提交事务，随机存储） mysql&gt; show variables like 'innodb_log_buffer_size';+------------------------+---------+| Variable_name | Value |+------------------------+---------+| innodb_log_buffer_size | 1048576 |+------------------------+---------+1 row in set mysql&gt; show variables like 'innodb_log_files_in_group';+---------------------------+-------+| Variable_name | Value |+---------------------------+-------+| innodb_log_files_in_group | 2 |+---------------------------+-------+1 row in set 12345678910111213141516171819202122232425262728- Innodb支持行级锁（myisam支持表级锁）- 行级锁可以最大程度支持并发- 行级锁是由存储引擎层实现的 什么是锁？管理共享资源的并发访问用于事务的隔离性 锁的类型？共享锁（读锁，只有读读兼容）独占锁（写锁，阻塞） mysql&gt; insert into myinnodb values(2,'bb'),(3,'cc');Query OK, 2 rows affectedRecords: 2 Duplicates: 0 Warnings: 0 mysql&gt; begin;Query OK, 0 rows affected 下面操作，未提交，对数据加了独占锁mysql&gt; update myinnodb set cl='bbbb' where id=2;Query OK, 1 row affectedRows matched: 1 Changed: 1 Warnings: 0 这时另外一个连接，包括navicat界面看到的还是更新前的数据 第二个连接并没有阻塞，这里看到的是undo log中的版本 123456789101112131415161718192021222324252627282930mysql锁定粒度：表级锁，并发低行级锁，开销大 回滚之前事务mysql&gt; rollback;Query OK, 0 rows affected innodb默认行级锁mysql&gt; show create table myinnodb;+----------+--------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+----------+--------------------------------------------------------------------------------------------------------------------------+| myinnodb | CREATE TABLE `myinnodb` ( `id` int(11) DEFAULT NULL, `cl` varchar(10) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 |+----------+--------------------------------------------------------------------------------------------------------------------------+1 row in set 加一个表级独占锁：mysql&gt; lock table myinnodb write;Query OK, 0 rows affected 第二个连接中执行查询：（发现被阻塞了）mysql&gt; select * from myinnodb; 直到第一个连接执行解锁操作：（第二个连接的查询才被执行）mysql&gt; unlock tables;Query OK, 0 rows affected 123Innodb状态检查： show engine innodb status CSV存储引擎1234数据以文本方式存储（上面2种是二进制存储）.CSV文件存储表的内容.CSM文件存储表的元数据如表状态和数据量.frm文件存储表结构信息 特点1234- 以CSV格式进行数据存储- 所有列必须非NULL- 不支持索引（不适合大表）- 可以对数据文件直接编辑 演示1234567891011121314151617181920212223242526272829不支持NULL列：mysql&gt; create table mycsv(id int,c1 varchar(10),c2 char(10))engine=csv;1178 - The storage engine for the table doesn't support nullable columnsmysql&gt; create table mycsv(id int not null,c1 varchar(10) not null,c2 char(10) not null)engine=csv;Query OK, 0 rows affected 插入一些数据：mysql&gt; insert into mycsv values(1,'aaa','bbb'),(2,'ccc','ddd');Query OK, 2 rows affectedRecords: 2 Duplicates: 0 Warnings: 0 mysql&gt; select * from mycsv;+----+-----+-----+| id | c1 | c2 |+----+-----+-----+| 1 | aaa | bbb || 2 | ccc | ddd |+----+-----+-----+2 rows in set centos系统中可以查看csv文件：ls -lh mycsv*vi mycsv.CSV可以直接编辑csv 不支持索引：mysql&gt; create index idx_id on mycsv(id);1069 - Too many keys specified; max 0 keys allowed Archive存储引擎Archive存储引擎的特点12345- 以zlib对表数据进行压缩，磁盘I/O更少- 数据存储在ARZ为后缀的文件中 - 只支持insert和select操作- 只允许在自增ID列上加索引 12345678910mysql&gt; create table myarchive( -&gt; id int auto_increment not null, -&gt; c1 varchar(10), -&gt; c2 char(10), -&gt; key(id)) engine = archive;Query OK, 0 rows affected centos命令ls -lh myarchive.*可以看到：myarchive.ARZmyarchive.frm 12345678910111213141516171819202122mysql&gt; insert into myarchive(c1,c2) values('aa','bb'),('cc','dd');Query OK, 2 rows affectedRecords: 2 Duplicates: 0 Warnings: 0 mysql&gt; select * from myarchive;+----+----+----+| id | c1 | c2 |+----+----+----+| 1 | aa | bb || 2 | cc | dd |+----+----+----+2 rows in set 不支持删除和更新：mysql&gt; delete from myarchive where id = 1;1031 - Table storage engine for 'myarchive' doesn't have this optionmysql&gt; update myarchive set c1='aaaa' where id = 1;1031 - Table storage engine for 'myarchive' doesn't have this option 无法在非自增列索引：mysql&gt; create index idx_c1 on myarchive(c1);1069 - Too many keys specified; max 1 keys allowed 适用场景1日志和数据采集类应用 Memory引擎特点123456- 也称HEAP存储引擎，数据保存在内存中- 支持HASH索引（默认，等值查找）和BTree索引（范围查找）- 所有字段都为固定长度varchar(10)=char(10)- 不支持BLOG和TEXT等大字段- 使用用表级锁- 最大大小有max_heap_table_size参数决定 1234567891011121314151617不支持TEXT类型：mysql&gt; create table mymemory(id int,c1 varchar(10),c2 char(10),c3 text) engine=memory;1163 - The used table type doesn't support BLOB/TEXT columnsmysql&gt; create table mymemory(id int,c1 varchar(10),c2 char(10)) engine=memory;Query OK, 0 rows affected centos系统命令ls -lh mymemory* ：mymemory.frm ---只有表结构文件，可见数据保存在内存中 创建2个索引，c1列默认索引，c2列btree索引：mysql&gt; create index idx_c1 on mymemory(c1);Query OK, 0 rows affectedRecords: 0 Duplicates: 0 Warnings: 0 mysql&gt; create index idx_c2 using btree on mymemory(c2);Query OK, 0 rows affectedRecords: 0 Duplicates: 0 Warnings: 0 适用场景1234- 用于查找或者是映射表，例如邮编和地区的对应表- 用于保存数据分析中产生的中间表- 用于缓存周期性聚合数据的结果表注：Memory数据易丢失，所以要求数据可再生 Federated存储引擎123- 提供了访问远程MySQL服务器上表的方法- 本地不存储数据，数据全 部放到远程服务器上- 本地需要保持表结构和远程服务器的连接信息 数据库事务什么是事务事务的原子性（ATOMICITY）1最小不可分割的工作单元，要么全提交成功，要么全部失败，不可能执行其中一部分操作 事务的一致性（CONSISTENCY）1事务开始前和事务结束后，数据库完整性没有被破坏 事务的隔离型（ISOLATION）12345SQL标准定义四种隔离级别（由低到高）1.未提交读（READ UNCOMMITED）:其他事务可以读到未提交的数据（脏读）2.已提交读（READ COMMITED）：一个事务未提交前对其他事务是不可见的3.可重复读（REPEATABLE READ）：已提交读称为不可重复读，详见下方4.可串行化（SERIALIZABLE）：每一行数据加锁，并发性最低 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263643.可重复读： mysql&gt; show variables like '%iso%';+---------------+-----------------+| Variable_name | Value |+---------------+-----------------+| tx_isolation | REPEATABLE-READ |+---------------+-----------------+1 row in set如上可以发现，mysql的默认级别是可重复读 开启事务：mysql&gt; begin;Query OK, 0 rows affected 查询id小于7的数据mysql&gt; select id from girl g where id&lt;7;+----+| id |+----+| 4 || 5 || 6 |+----+3 rows in set 新开一个进程，开启事务并提交，插入一条数据，id为2：mysql&gt; begin;Query OK, 0 rows affected mysql&gt; insert into girl(id,money) values(2,'20');Query OK, 1 row affected mysql&gt; commit;Query OK, 0 rows affected 回到之前进程，发现并没有多出id为2的值：（navicat界面可以查到）mysql&gt; select id from girl g where id&lt;7;+----+| id |+----+| 4 || 5 || 6 |+----+3 rows in set 提交后，修改隔离级别为已提交读：mysql&gt; commit;Query OK, 0 rows affected mysql&gt; set session tx_isolation='read-committed';Query OK, 0 rows affected mysql&gt; show variables like '%iso%';+---------------+----------------+| Variable_name | Value |+---------------+----------------+| tx_isolation | READ-COMMITTED |+---------------+----------------+1 row in set 重复上面操作，另外一个事务插入id为3的值会被读到。可以发现，可重复读级别每次查询结果一样，不可重复读级别的查询结果可能变化 事务的持久性（DURABILITY）1事务提交，所做修改永久保存到数据库中","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"Java基础笔试题","slug":"Java基础笔试题","date":"2017-03-20T08:22:42.000Z","updated":"2018-03-04T03:01:55.000Z","comments":true,"path":"2017/03/20/Java基础笔试题/","link":"","permalink":"http://yoursite.com/2017/03/20/Java基础笔试题/","excerpt":"后台开发&amp;系统工程师B1.下述解决死锁的方法中，属于死锁预防策略的是？ 银行家算法 资源有序分配法 资源分配图化简法 撤销进程发","text":"后台开发&amp;系统工程师B1.下述解决死锁的方法中，属于死锁预防策略的是？ 银行家算法 资源有序分配法 资源分配图化简法 撤销进程发 解析：1234银行家算法：避免死锁资源有序分配法：预防死锁资源分配图化简法：检测死锁撤销进程法：解决死锁 2.进程和线程是操作系统中最基本的概念,下列有关描述错误的是？ 进程是程序的一次执行,而线程可以理解为程序中运行的一个片段 由于线程没有独立的地址空间,因此同一个进程的一组线程可以访问该进程资源,这些线程之间的通信也很高效 线程之间的通信简单(共享内存即可,但须注意互斥访问的问题),而不同进程之间的通信更为复杂,通常需要调用内核实现 线程有独立的虚拟地址空间,但是拥有的资源相对进程来说,只有运行所必须的堆栈,寄存器等解析：123线程只是一个进程中的不同执行路径。线程和进程都有独立的地址空间。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间。 3.若一颗二叉树的前序遍历为a,b,c,d,e,后序遍历为c,e,d,b,a，则根节点的孩子节点是？ 只有a 只有b 只有e 有e，c 解析：123456先看前序遍历，a,b,c,d,e。因为前序遍历是按照根节点，左子节点，右子节点的顺序递归遍历。a第一个出现说明a是根节点，第二个出现b说明b是a的左子节点，第三个出现c说明c可能是a的右子节点或者c是b的左子节点。 再看后续遍历，第一个出现c说明c是最左边的节点，所以可以确定c是b的左子节点，d,e在c,b之间，所以可以确定d,e属于b的子节点或者子节点的子节点。就可以确定a只有一个根节点b了 4.1024! 末尾有多少个0? 253 解析：1234567891011末尾0的个数取决于乘法中因子2和5的个数。显然乘法中因子2的个数大于5的个数，所以我们只需统计因子5的个数。 一定是5的倍数的数有： 1024 / 5 = 204个 一定是25的倍数的数有：1024 / 25 = 40个 一定是125的倍数的数有：1024 / 125 = 8个 一定是625的倍数的数有：1024 / 625 = 1个 所以1024! 中总共有204+40+8+1=253个因子5。 也就是说1024! 末尾有253个0。 问：5的倍数里面不是包含25,125,625的倍数吗?答：25包含2个5,125包含3个5,625包含4个5，刚算5的时候只算了一个，后面要累加。 5.从n个数中找出最小的k个数(n &gt;&gt; k)，最优平均时间复杂度是？ O(klogk) 解析：12345671.先直接排序，再取排序后数据的前k个数。排序算法用最快的堆排序，复杂度也会达到O(N*logN)。当k接近于N时，可以用这种算法。 2.先排序前k个数，对于后面N-k个数，依次进行插入。时间复杂度为O(k*n)。当k很小时，可以用这种算法。 3.对前k个数，建立最大堆，对于后面N-k个数，依次和最大堆的最大数比较，如果小于最大数，则替换最大数，并重新建立最大堆。时间复杂度为O(N*logk)。当k和N都很大时，这种算法比前两种算法要快很多。 6.HTTP的会话有四个过程，请选出不是的一个？ 传输数据 解析：12Http会话的四个过程:建立连接，发送请求，返回响应，关闭连接。 7.关于TIME_WAIT状态的描述，下面说法错误的是？ TIME_WAIT出现在被动关闭一方，CLOSE_WAIT出现在被动关闭一方 从TIME_WAIT状态到CLOSED状态，有一个超时设置，这个超时设置是 2*MSL TIME_WAIT确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到Ack，就会触发被动端重发Fin，一来一去正好2个MSL 有足够的时间让这个连接不会跟后面的连接混在一起 解析：1234通信双方建立TCP连接后，主动关闭连接的一方就会进入TIME_WAIT状态。 客户端主动关闭连接时，会发送最后一个ack后，然后会进入TIME_WAIT状态，再停留2个MSL时间(后有MSL的解释)，进入CLOSED状态。 8.一台主机安装了1GB的内存，操作系统为支持MMU的32位Linux发行版，现在运行了abc三个进程，以下哪些使用内存的方式是可以实现的？ abc各申请1GB a申请500MB b申请500MB c申请25MB abc一共申请256GB abc各申请2.5GB 解析：1有虚拟内存，可以申请大于物理内存的内存空间，但是32位系统最多只能寻址4GB空间。 后台开发&amp;系统工程师A1.关于实模式和保护模式的描述正确的是？ 实模式下的地址是计算公式是：段值＊16+偏移，其中段值16位，偏移16位，访问的地址范围1MB，如果程序访问超过1MB的地址，系统会发生异常 决定实模式与保护模式的关键是CR1寄存器中的PE位，当为0时为实模式，为1位保护模式 在保护模式下，通过调用门，可以实现不同特权级之间的代码转移 保护模式下，共有4个特权级别，0特权级的任务访问3特权级的段时会触发常规保护错误(#GP) 解析：1组成原理知识：现在不会，以后再更新 2.关于数据库索引，以下说法正确的是？ 针对某些字段建立索引，能够有效的减少相关数据库表的磁盘空间占用 针对某些字段建立索引，能够有效的提升相关字段的读与写的效率 常见数据库管理系统，通常使用hash表来存储索引 数据库索引的存在，可能导致相关字段删除的效率降低 解析：1234A：增加索引会增加磁盘占用B：建立索引可以提升查询速度，即读速度；但在一定程度上降低写速度C：数据库一般使用B*树作为索引D：删除数据需要调整索引，所以会降低效率 3.把60个糖果分给5个小朋友，每个小朋友至少分到10个糖果，请问有几种分法？ 1001 解析：12345先给每个人分10个，然后把10个糖果分给5个人。使用排列组合中的隔板法。 相当于在14个元素里选择4个作为隔板：C（14,4） 结果：14*13*12*11/4*3*2*1 (分母乘多少个看上标) 4.下列算法的时间复杂度是123456int fun(int n)&#123; if(n&lt;2)&#123; return 1; &#125; return n*fun(n-2);&#125; 0(n) 解析：1待更新。。。 5.以下不属于tcp连接断开的状态是？ TIME_WAIT FIN_WAIT_1 SYNC_SENT FIN_WAIT_2 解析：1待更新。。。 6.下面哪个不是进程间的通信方式？ 回调 共享内存 消息传递 信号量 解析：1234567进程间的通信方式1.管道2.信号量3.消息队列4.信号5.共享内存6.套接字 7.下面java concurrent包下的4个类中差别最大的一个是？ CountDownLatch Future Semaphore ReentrantLock 解析：12345A、Semaphore：类，控制某个资源可被同时访问的个数;B、ReentrantLock：类，具有与使用synchronized方法和语句所访问的隐式监视器锁相同的一些基本行为和语义，但功能更强大；C、 Future：接口，表示异步计算的结果；D、 CountDownLatch： 类，可以用来在一个线程中等待多个线程完成任务的类。 8.哪些设计模式能够提高系统扩展性？ singleton abstract factory adapter Decorator 解析：1234A单例模式没有提高扩展性B工厂方法实现松耦合，可以提高扩展性C适配器模式可以将一个接口转换成另一个接口，方便引入外部接口D装饰者模式可以扩展接口功能 9.下面对多线程和多进程编程描述正确的是？ 线程的数据交换更快，因为他们在同一地址空间内 线程因为有自己的独立栈空间且共享数据，不利于资源管理和保护 多进程里，子进程可获得父进程的所有堆和栈的数据； 进程比线程更健壮，但是进程比线程更容易杀掉。 解析：1待系统学习后，再更新 10.有四个整数，用8位补码分别表示为r1=FEH, r2=F2H, r3=90H, r4=F8H。运算结构存入8位寄存器中，不会溢出的是？ r1*r2 r2*r3 r1*r4 r4*r2 解析：1待更新。。。 研发工程师模拟笔试题1.浏览器和服务器在基于https进行请求链接到数据传输过程中，用到了如下哪些技术： 非对称加密技术 对称加密技术 散列（哈希）算法 数字证书 解析：12345678910111213141516171819202122232425262728HTTPS在传输数据之前需要客户端（浏览器）与服务端（网站）之间进行一次握手，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL协议不仅仅是一套加密传输的协议，更是一件经过艺术家精心设计的艺术品，TLS/SSL中使用了非对称加密，对称加密以及HASH算法。握手过程的简单描述如下： 1.浏览器将自己支持的一套加密规则发送给网站。 2.网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。 3.获得网站证书之后浏览器要做以下工作： a) 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。b) 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。 c) 使用约定好的HASH计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。 4.网站接收浏览器发来的数据之后要做以下的操作： a) 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。 b) 使用密码加密一段握手消息，发送给浏览器。 5.浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。 这里浏览器与网站互相发送加密的握手消息并验证，目的是为了保证双方都获得了一致的密码，并且可以正常的加密解密数据，为后续真正数据的传输做一次测试。另外，HTTPS一般使用的加密与HASH算法如下： 非对称加密算法：RSA，DSA/DSS 对称加密算法：AES，RC4，3DES HASH算法：MD5，SHA1，SHA256 研发工程师笔试题（一）1.下面哪些机制可以用于进程间通信？ Socket Named pipe Named event Critical Section Shared memory Virtual memory 解析：1234567进程间通信： 1.管道（pipe）及有名管道（named pipe） 2.信号（signal） 3.消息队列（message queue） 4.共享内存（shared memory） 5.信号量（semaphore） 6.套接字（socket） 2.下面的程序执行输出几个hello？ 123456789#include&lt;stdio.h&gt;#include &lt;unistd.h&gt;int main( ) &#123; fork( ); fork( ); fork( ); printf(“hello\\n”); return 0;&#125; 8 解析：123456fork（）函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。fork调用的一个奇妙之处就是它仅仅被调用一次，却能够返回两次，它可能有三种不同的返回值： 1）在父进程中，fork返回新创建子进程的进程ID； 2）在子进程中，fork返回0； 3）如果出现错误，fork返回一个负值； 3.我们用a^b 来表示a的b次幂，那么下列算是判断正确的是？ 2.1^3.1 &gt; 3.1^2.1 2.1^3.1 &lt; 3.1^2.1 2.1^4.1 &gt; 4.1^2.1 2.1^4.1 &lt; 4.1^2.1 解析：12比较a^b 与b^a的大小，可变为比较ln(a^b) = blna 与ln(b^a)=alnb的大小这种题还是蒙吧。。。 4.以下设计模式中，哪一项不属于结构性模式？ 适配器模式 代理模式 命令模式 装饰模式 解析：12结构型设计模式是从程序的结构上解决模块之间的耦合问题。包括以下七种模式：适配器模式、 桥接模式、 组合模式、 装饰模式、 外观模式、 享元模式、 代理模式。 5.对于一个分布式计算系统来说，以下哪三个指标不能同时完成？ 一致性 可用性 安全性 分区容错性 解析：1234567分布式领域CAP理论，Consistency(一致性), 数据一致更新，所有数据变动都是同步的Availability(可用性), 好的响应性能Partition tolerance(分区容错性) 可靠性 定理：任何分布式 系统只可同时满足二点，没法三者兼顾。忠告：架构师不要将精力浪费在如何设计能满足三者的完美分布式 系统，而是应该进行取舍 6.在网络应用测试中，网络延迟是一个重要指标。以下关于网络延迟的理解，正确的是？ 指响应时间 指报文从客户端发出到客户端接收到服务器响应的间隔时间 指报文在网络上的传输时间 指从报文开始进入网络到它开始离开网络之间的时间 解析：12要注意区分相关的概念B选项只能说是往返时延，即RTT，而网络延迟是数据进入网络到离开网络所花费的总时间。 7.书架一排有5个格子。现在有20本书，编号从1到20。要求20本书要摆放在同一排里，并且从左到右编号依次递减；每个格子至少有一本书；并且编号7，8，9的书籍必须在同一个格子里面。问，一共有多少种可能的摆放方法？ 2380 解析：123把7，8,9看成一本书因此共有18本书，要保证每个格子中都有书，因此可以在1到18之间的空隙中选择四个位置组合数： c(4,17)=2380 8.下列方法中，可以用于特征降维的方法包括（） 主成分分析PCA 线性判别分析LDA 深度学习SparseAutoEncoder 矩阵奇异值分解SVD 最小二乘法LeastSquares 解析：1待更新。。。 2016研发工程师笔试题（二）1.已知有30匹马，5个跑道，每个跑道只能容一匹马，没有计时器，至少需要比赛多少次，可以找出最快的前三匹马 9 解析：1231、选出六个组各组的排名 6次2、六组的第一比选出123名 2次3、第一名的那组的23名和第二名那组的12名和第三名那组的第1名比较 选出一二名 1次 2.当前目录下有a和b两个文件，执行命令“ls&gt;c”，请问文件c里面的内容是什么？ abc 解析：12用ls命令产生的输出为当前路径下的所有文件名。&gt;c即代表将结果输出至c中，若没有c则先产生c文件，即内容里含有abc 3.设无向图的顶点个数为n，则该图最多有多少条边？ n（n-1）/2 解析：1c(2,n)=n*(n-1)/(2*1) 4.在Unix系统中，若一个进程退出时，其子进程还在运行（没有被杀死），则这些子进程会变成孤儿进程（Orphan Process），请问孤儿进程会被以下哪一个系统进程接管？ init 解析：1待学后更新。。。 5.求函数返回值，输入x=9999 123456789int func(int x)&#123; int count=0; while (x) &#123; count++; x=x&amp;(x-1);//与运算 &#125; return count;&#125; 解析：1此题可转为求十进制9999，转为二进制后，二进制中1的个数，别突然间忘了怎样把十进制转成二进制了。 6.某次买可乐集瓶盖活动中有5种不同的瓶盖以等概率出现，每买一瓶汽水可得到一个瓶盖，集齐所有瓶盖所买汽水瓶数的期望，与以下哪个结果最为接近？ 9 11 13 15 解析：123在已经取到一种瓶盖的情况下，再取到一种不同的瓶盖的期望次数是1/（4/5）=5/4；在已经取到两种瓶盖的情况下，再取到一种不同的瓶盖的期望次数是1/（3/5）=5/3；。。。 因此，取到五种瓶盖的期望次数为1+5/4+5/3+5/2+5/1=11+5/12。 7.JAVA语言的下面几种数组复制方法中，哪个效率最高？ for循环逐一复制 System.arraycopy Arrays.copyof 使用clone方法 解析：12345678910111213141516171819A.for循环的话，很灵活，但是代码不够简洁. B.System.arraycopy()源码。可以看到是native方法：native关键字说明其修饰的方法是一个原生态方法，方法对应的实现不是在当前文件，而是在用其他语言（如C和C++）实现的文件中。可以将native方法比作Java程序同Ｃ程序的接口。 public static native void arraycopy(Object src, int srcPos, Object dest, int destPos,int length); C.下面是源码，可以看到本质上是调用的arraycopy方法。那么其效率必然是比不上 arraycopy的 public static int[] copyOf(int[] original, int newLength) &#123; int[] copy = new int[newLength]; System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy; &#125; D.clone返回的是Object，需要强制转换，一般用clone效率是最差的 8.0，1，2，3，⋯，499，500共501个数按升序排列，每次取奇数序位的数丢掉，然后取剩下的数的奇数序位的数丢掉，重复这个过程，那么最后剩下的数是多少？ 255 解析：123注意：0算第一位规律：2^n中n最大的数会被保留下来，500以内的数是256，从0开始数就是255 9.一个不透明的箱子里共有红，黄，蓝，绿，白五种颜色的小球，各个小球的数量非常多而且接近相等，每种颜色的小球大小相同，质量相等，每个人从篮子里抽出两个小球，请问至少需要多少个人抽，才能保证有两个人抽到的小球颜色全部相同？ 16 解析：123题意就是球量充足，近似相等，所以不用担心放回不放回的概率问题。五种颜色的球组合：c(2,5)（5颜色选2不同颜色）+（5颜色选2相同颜色）5=15。而且这15种组合是等概率出现。所以重复的话，就是发生在第16个人身上。 10.有订单表orders，包含字段用户信息userid，字段产品信息productid，以下语句能够返回至少被订购过两会的productid？ select productid from orders where count（productid）&gt;1 select productid from orders where max（productid）&gt;1 select productid from orders where having count（productid）&gt;1 group by productid select productid from orders group by productid having count（productid）&gt;1 解析：12Where语句中不能出现聚合函数，且不能和having共用。Having是出现在groupby语句中，用来对分组的结果集进行限定的。 11.一架飞机在满油的情况下可绕地球飞0.5圈，假设飞机与飞机之间可以互相加油，且地球只有一个基地。请问在确保所有飞机够油飞回起点的情况下，最少需要几架飞机才可以让其中一架飞机成功绕地球飞行一圈？（提示1：地球是圆的！提升2：飞机可以重复使用！） 3 解析：12345 只需要ABC共3架飞机。3架共同出航，A1/8圈后返航，1/4圈油分给BC；B继续1/8圈至1/4圈处后返航，1/8圈油给C；C继续飞行1/2圈至3/4圈处空油。C飞行至1/2圈时，AB反向共同出航，A1/8圈后至7/8圈处返航，1/8圈给B(加满)；B继续飞行1/8圈后至3/4圈处恰遇C，B给C1/8圈油共同返航；于此同时A重新反向出发再次至7/8圈处恰遇C，给C1/8圈油后，3机共同返航。 12.关于volatile关键字，下列描述不正确的是？ 用volatile修饰的变量，每次更新对其他线程都是立即可见的。 对volatile变量的操作是原子性的。 对volatile变量的操作不会造成阻塞。 不依赖其他锁机制，多线程环境下的计数器可用volatile实现。 解析：12345 所谓 volatile的措施，就是1. 每次从内存中取值，不从缓存中什么的拿值。这就保证了用 volatile修饰的共享变量，每次的更新对于其他线程都是可见的。2. volatile保证了其他线程的立即可见性，就没有保证原子性。3.由于有些时候对 volatile的操作，不会被保存，说明不会造成阻塞。不可用与多线程环境下的计数器。 13.SNMP所采用的传输层协议是什么？ UDP 解析：1234567891011121314SMTP：简单邮件传输协议，使用TCP连接，端口号为25，SNMP：简单网络管理协议，使用UDP 161端口， 网络层协议包括： IP协议、ICMP协议、ARP协议、RARP协议；传输层协议包括：TCP协议、UDP协议 更多：物理层：RJ45、CLOCK、IEEE802.3 数据链路：PPP、FR、HDLC、VLAN、MAC 网络层：IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP传输层：TCP、UDP、SPX会话层：NFS、SQL、NETBIOS、RPC表示层：JPEG、MPEG、ASII应用层：FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS 2016研发工程师笔试题（三）1.在网络7层协议中，如果想使用UDP协议达到TCP协议的效果,可以在哪层做文章? 会话层 解析：123456789 因为UDP要达到TCP的功能就必须实现拥塞控制的功能,而且是在路由之间实现,这个在底层明显是做不到拥塞控制的,在应用层也是做不到的,因为应用层之间和应用程序挂钩,一般只能操控主机的程序,而表示层是处理所有与数据表示及运输有关的问题，包括转换、加密和压缩,在传输层是不可能的,因为你已经使用了UDP协议,无法在本层转换它,只有在会话层. 会话层（SESSION LAYER）允许不同机器上的用户之间建立会话关系。 会话层循序进行类似传输层 的普通数据的传送，在某些场合还提供了一些有用的增强型服务。 允许用户利用一次会话在远端的分时系统上登陆，或者在两台机器间传递文件。 会话层提供的服务之一是管理对话控制。会话层允许信息同时双向传输，或任一时刻只能单向传输。 如果属于后者，类似于物理信道上的半双工模式，会话层将记录此时该轮到哪一方 2.两个线程并发执行以下代码,假设a是全局变量,那么以下输出___哪个是可能的? 12345int a=1;void foo()&#123; ++a; printf(\"%d\",a);&#125; 3 2 2 3 3 3 2 2 解析：12345678910111213141516171819202122 A：3, 2 y先执行++a，a为2; y再执行printf，a入栈，在打印到终端之前切换到x x执行＋＋a，a为3; x执行printf，输出3;再切换到y y执行打印，输出2 B：2 3 x先执行＋＋a，a为2; x再执行printf，输出2;切换到y y执行＋＋a，a为3; y执行printf，输出3; C：3 3 x先执行＋＋a，a为2;切换到y y执行＋＋a，a为3; y执行printf，输出3;切换到x x执行printf，输出3 D：2 2 假设线程A先执行++a操作但没有写回到内存，这时线程B执行++a操作写回内存并printf，输出2_，线程A继续执行，++a操作写回内存，a的值保持2，再printf 3.下列关于线程调度的叙述中,错误的是() 调用线程的sleep()方法,可以使比当前线程优先级低的线程获得运行机会 调用线程的yeild()方法,只会使与当前线程相同优先级的线程获得运行机会 具有相同优先级的多个线程的调度一定是分时的 分时调度模型是让所有线程轮流获得CPU使用权 解析：12345678910A选项，sleep()方法强制使当前线程休眠，释放CPU资源，以便使得其他所有线程有机会运行。 B选项，yield()方法使得当前的线程让出CPU的使用权，以使得比该线程优先级相同或更高的线程有机会运行。该线程在让出CPU使用权之后可能再次被选中，因此yield()方法可能会不起作用(这也说明了yield()方法不会使得比当前线程优先级低的线程运行)。 C选项，java虚拟机中如果多个线程优先级相同，则会随机选择一个线程占用CPU，处于运行状态的线程会一直运行，直至它不得不放弃CPU为止，因此不一定是分时调度。 D正确 4.在linux系统中,有一个文件夹里面有若干文件,通常用哪个命令可以获取这个文件夹的大小: ls -h du -sh df -h fdish -h 解析：12345678A不正确，ls的-h选项只有在有-l时候才会起作用，即ls -lh B正确，du可以显示当前目录及子目录的磁盘占用情况，-d选项可以指明递归目录的深度，-s等价于-d 0，-h表示以可读的形式显示，比如B, KB, GB等 C不正确，df是显示整个文件系统的使用情况，不能得到当前文件夹的情况 D不正确，命令都写错了。。。就算是fdisk，是用来分区的，没关系。 5.我们用一个等臂天平来称物体的质量,如果我们要称的物体质量范围在1到40克(整数),请问我们最少需要几块砝码可以完成这项物体质量的称量? 4 解析：1234567一个砝码可以放在要称量的物品的同侧，也可以放在对侧，当然也可以不放。砝码的三种状态可以表示为：不放 （0）、放在物品对侧（+1）、放在物品同侧 （-1） 因此各个砝码碎片的重量就是各个平衡三进制数位的权重（ 3^0 ， 3^1 ， 3^2 ， 3^3 ），即 1 ， 3 ， 9 ， 27 。 40可以用1111来表示，所以最多只用四个砝码，就可以表示1-40之间所有数。 6.HTTP中的POST和GET在下列哪些方面有区别?() 数据位置 明文密文 数据安全 长度限度 应用场景 解析：1234Http定义了与服务器交互的不同方法，最基本的方法有4种，分别是GET，POST，PUT，DELETE。URL全称是资源描述符，我们可以这样认为：一个URL地址，它用于描述一个网络上的资源，而HTTP中的GET，POST，PUT，DELETE就对应着对这个资源的 查 ， 改 ， 增 ， 删 4个操作。到这里，大家应该有个大概的了解了，GET一般用于 获取/查询 资源信息，而POST一般用于 更新 资源信息。 7.以下哪些jvm的垃圾回收方式采用的是复制算法回收 新生代串行收集器 老年代串行收集器 并行收集器 新生代并行回收收集器 老年代并行回收收集器 cms收集器 解析：1234567891011121314151617两个最基本的java回收算法：复制算法和标记清理算法复制算法：两个区域A和B，初始对象在A，继续存活的对象被转移到B。此为新生代最常用的算法标记清理：一块区域，标记要回收的对象，然后回收，一定会出现碎片，那么引出标记-整理算法：多了碎片整理，整理出更大的内存放更大的对象两个概念：新生代和年老代新生代：初始对象，生命周期短的永久代：长时间存在的对象整个java的垃圾回收是新生代和年老代的协作，这种叫做分代回收。P.S：Serial New收集器是针对新生代的收集器，采用的是复制算法Parallel New（并行）收集器，新生代采用复制算法，老年代采用标记整理Parallel Scavenge（并行）收集器，针对新生代，采用复制收集算法Serial Old（串行）收集器，新生代采用复制，老年代采用标记整理Parallel Old（并行）收集器，针对老年代，标记整理CMS收集器，基于标记清理G1收集器：整体上是基于标记 整理 ，局部采用复制 综上：新生代基本采用复制算法，老年代采用标记整理算法。cms采用标记清理。 8.将7723810的各位数字打乱排序,可组成的不同的7位自然数的个数是? 2160 解析：12(7! / 2) - (6! /2 ) = 21607！代表7个数的全排列数，除以2是因为有一个数重复了，“减”是因为要排除0在首位的排列数。 9.以下关于linux操作系统中硬链接和软链接的描述,正确的是? 硬链接和软链接指向的inode的编号是一样的 可以建立一个空文件的软链接 linux操作系统可以对目录进行硬链接 硬链接指向inode节点 解析：1234567891011121314151617由于硬链接是有着相同 inode 号仅文件名不同的文件，因此硬链接存在以下几点特性：- 文件有相同的 inode 及 data block；- 只能对已存在的文件进行创建；- 不能交叉文件系统进行硬链接的创建；- 不能对目录进行创建，只可对文件创建；- 删除一个硬链接文件并不影响其他有相同 inode 号的文件。 软链接与硬链接不同，若文件用户数据块中存放的内容是另一文件的路径名的指向，则该文件就是软连接软链接就是一个普通文件，只是数据块内容有点特殊。软链接有着自己的 inode 号以及用户数据块。因此软链接的创建与使用没有类似硬链接的诸多限制：- 软链接有自己的文件属性及权限等；- 可对不存在的文件或目录创建软链接；- 软链接可交叉文件系统；- 软链接可对文件或目录创建；- 创建软链接时，链接计数 i_nlink 不会增加；- 删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接（即 dangling link，若被指向路径文件被重新创建，死链接可恢复为正常的软链接）。 10.mysql数据库中一张user表中,其中包含字段A,B,C,字段类型如下:A:int,B:int,C:int根据字段A,B,C按照ABC顺序建立复合索引idx_A_B_C,以下查询语句中使用到索引idx_A_B_C的语句有哪些？ select *from user where A=1 and B=1 select *from user where 1=1 and A=1 and B=1 select *from user where B=1 and C=1 select *from user where A=1 and C=1 解析：12复合索引可以只使用复合索引中的一部分，但必须是由最左部分开始，且可以存在常量因复合索引为idx_A_B_C，所以查询条件只能是在a,ab,abc,ac才算 使用到索引idx_A_B_C 11.HTTPS是使用()来保证信息安全的. SET IPSEC SSL SSH 解析：12345Internet 协议安全性 (IPSec)是一种开放标准的框架结构，通过使用加密的 安全服务 以确保在 Internet 协议 (IP) 网络上进行保密而安全的通讯。 HTTP协议通常承载于TCP协议之上，有时也承载 于TLS（ 安全传输层协议 ）或 SSL（ 安全套接层协议Secure Sockets Layer ）协议层之上，这个时候，就成了我们常说的HTTPS。 12.具有7个顶点的有向图至少应有多少条边才可能成为一个强连通图? 7 解析：12强连通图必须从任何一点出发都可以回到原处，每个节点至少要一条出路(单节点除外)至少有n条边，正好可以组成一个环,若为无向图，则是6条边 13.假设在x86平台上,有一个int型变量,在内存中的内部由低到高分别是:0x12,0x34,0x56,0x78当通过网络发送该数据时,正确的发送顺序是() 0x78,0x56,0x34,0x12 解析：1待学后更新。。。 14.以下哪个ip不和10.11.12.91/28处于同一个子网 10.11.12.85/28 10.11.12.88/28 10.11.12.94/28 10.11.12.97/28 解析：123456728是指子网掩码是28个1 FF.FF.FF.F0 计算ip时需与上掩码故子网掩码为11111111.11111111. 11111111. 11110000（255.255.255.240）256-240=16，有16个子网，每一个子网段大小范围是16。10.11.12.91/28中91可以表示为：01011011，前四位为网络号，后四位为主机号，故包含10.11.12.91的子网范围是：01010000~01011111（80~95）。去掉第一个和最后一个，和 10.11.12.91/28在一个网段的范围为：10.11.12.81/28~10.11.12.94/28。 15.有9个球,其中一个的质量与其他的不同,有一个天平,通过最多几次可以找出那个质量不一样的球? 3 解析：12345678任取2组比较，若重量相等，则目标小球在另一组； 若重量不等，则任意替换一组再进行比较，可以知晓目标小球所在组，以及目标小球重量比一般小球是重还是轻。 对目标小球所在小组任取2个，若重量相等，则目标小球为另一个；若重量不等则可以根据之前获取的目标小球重量特征（比一般重或轻），找出目标小球。 共称3次。 16.具有相同类型的指针类型变量p与数组a,不能进行的操作是: p=a; *p=a[0]; p=&amp;a[0]; p=&a; 解析：1234a表示数组a的地址指针，a和p类型相同，所以p=a操作正确；*p表示p指向的值，a[0]表示数组的第一个值，两者类型相同，可赋值，正确；&amp;a[0]是数组第一个元素的地址，与a相同，也是指针，可赋值，正确；a本身是一个指针，而&amp;a表示a的地址，地址是int型，但p不一定是int型的，错误。","categories":[],"tags":[{"name":"博客重构","slug":"博客重构","permalink":"http://yoursite.com/tags/博客重构/"},{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"},{"name":"牛客网","slug":"牛客网","permalink":"http://yoursite.com/tags/牛客网/"},{"name":"笔试题","slug":"笔试题","permalink":"http://yoursite.com/tags/笔试题/"}]},{"title":"Java实现简单算法","slug":"Java实现简单算法","date":"2017-03-19T08:40:50.000Z","updated":"2018-03-04T03:02:01.000Z","comments":true,"path":"2017/03/19/Java实现简单算法/","link":"","permalink":"http://yoursite.com/2017/03/19/Java实现简单算法/","excerpt":"冒泡排序12345678910111213141516171819202122232425262728public class BubbleSort &#123; public static void bubbleSort(int[] data) &#123; for (int i = 0; i &lt; data.length - 1; i++) &#123;// 可理解为冒泡排序的趟数 boolean flag = false; // 可理解为数组从头逐步两两比较的次数 for (int j = 0; j &lt; data.length - 1 - i; j++) &#123; if (data[j] &gt; data[j + 1]) &#123; int tmp = data[j]; data[j] = data[j + 1]; data[j + 1] = tmp; flag = true; &#125; &#125; // 如果某趟没有交换，说明已经排序好 if (!flag) &#123; break; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] a = &#123; 1, 3, 2, 4, 5, 6 &#125;; bubbleSort(a); for (int i = 0; i &lt; a.length; i++) &#123; System.out.println(a[i]); &#125; &#125;&#125;","text":"冒泡排序12345678910111213141516171819202122232425262728public class BubbleSort &#123; public static void bubbleSort(int[] data) &#123; for (int i = 0; i &lt; data.length - 1; i++) &#123;// 可理解为冒泡排序的趟数 boolean flag = false; // 可理解为数组从头逐步两两比较的次数 for (int j = 0; j &lt; data.length - 1 - i; j++) &#123; if (data[j] &gt; data[j + 1]) &#123; int tmp = data[j]; data[j] = data[j + 1]; data[j + 1] = tmp; flag = true; &#125; &#125; // 如果某趟没有交换，说明已经排序好 if (!flag) &#123; break; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] a = &#123; 1, 3, 2, 4, 5, 6 &#125;; bubbleSort(a); for (int i = 0; i &lt; a.length; i++) &#123; System.out.println(a[i]); &#125; &#125;&#125; 堆排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class HeapSort &#123; public static void heapSort(int[] data)&#123; //按照下面的排序思想，每次建堆，把最大值放到了数组相对最右边，最后只剩下一个 //元素在数组最左边，肯定最小，所以不需要再建堆了，共建堆data.length-1次 for(int i = 0;i&lt;data.length-1;i++)&#123; //每次都从数组头到数组相对末尾建大顶堆 buildMaxHeap(data, data.length-1-i); //每次建完大顶堆后，最大值在数组头位置，把它换到相对末尾，下次再执行 //上行代码建大顶堆时，相对末尾往左移一位 swap(data, 0, data.length-1-i); &#125; &#125; //前提：假设把数组按照索引顺序的所有数据，从左往右、自上而下地映射到一颗完全二叉树上 private static void buildMaxHeap(int[] data,int lastIndex)&#123; //(index-1)/2公式可求根据任意节点索引求其父节点的索引 //数组从最后一个节点的父节点索引往左遍历，会遍历到所有的父节点 //(假如lastIndex在二叉树的左下方，其右边的“貌似\"父节点，其实是叶子节点)， //通过这些父节点是可以获取二叉树上所有节点并比较的。 for(int i=(lastIndex-1)/2;i&gt;=0;i--)&#123; //保存当前父节点，下面要保证数组在k的索引，和其左右孩子节点相比，最大 int k = i; //虽然能遍历到所有的父节点，但父节点可能没有右子孩子节点 //(注意，基于前提可得出：任意父节点都一定有左孩子节点) //(例如，lastIndex在二叉树的最左下方，其父节点是没有右孩子节点的， //这种情况下，这唯一个父节点特殊) if(2*k+1==lastIndex)&#123; if(data[k]&lt;data[lastIndex])&#123; swap(data, k, lastIndex); &#125; &#125;else&#123; int tmp = data[2*k+1]&gt;data[2*k+2]?(2*k+1):(2*k+2); if(data[k]&lt;data[tmp])&#123; swap(data,k,tmp); &#125; &#125; &#125; &#125; //交换data数组中的i、j两个索引处的元素 private static void swap(int[] data, int i, int j) &#123; int tmp = data[i]; data[i] = data[j]; data[j] = tmp; &#125;&#125; 插入排序1234567891011121314151617181920212223242526272829303132333435363738public class InsertSort &#123; public static void insertSort(int[] data)&#123; //以数组头为基准，数组后面的元素进行插入操作（从小到大） for(int i=1;i&lt;data.length;i++)&#123; //必须保存要执行插入操作的元素，后面子序列移动会覆盖data[i] int tmp = data[i]; //要插入的元素先和其前面序列的最大值比较，如果比它大，就无需操作, if(tmp&lt;data[i-1])&#123; //否则，子序列从后往前直到找到比要插入元素小的位置, //并让从后往前这部分子序列往右移动一位 //（右移序列包含这个比tmp元素小的元素） int j=i-1; while(j&gt;=0 &amp;&amp; tmp&lt;data[j])&#123; //一开始，j+1是tmp的位置，将被子序列最大元素占用 //这也是一开始要保存tmp的原因 data[j+1] = data[j]; j--; &#125; //此时j+1索引是子序列中刚好比tmp小的位置，tmp插入到这 data[j+1]=tmp; &#125; &#125; &#125; public static void main(String[] args) &#123; int [] data = &#123;2,3,1,35,13,564,12,2,4,1,3,6,1,3,5,6,67,77,88888,5&#125;; insertSort(data); for(int i=0;i&lt;data.length;i++)&#123; System.out.print(data[i]+\"--\"); &#125; &#125;&#125; 快速排序123456789101112131415161718192021222324252627282930313233343536public class QuickSort &#123; private static void quickSort(int data[], int low, int hight) &#123; int i = low, j = hight; int mid = data[(low + hight) / 2]; //按从小到大排序 while (i &lt;= j) &#123; //从左边找到一个比中间值大的元素 while (data[i] &lt; mid) i++; //从右边找到一个比中间小的元素 while (data[j] &gt; mid) j--; //这两个数交换 if (i &lt;= j) &#123; int temp = data[i]; data[i] = data[j]; data[j] = temp; i++; j--; &#125; &#125; if (i &lt; hight) quickSort(data, i, hight); if (j &gt; low) quickSort(data, low, j); &#125; public static void main(String[] args) &#123; int[] data = &#123; 2, 3, 1, 35, 13, 564, 3, 6, 1, 3, 5, 6, 67, 77, &#125;; quickSort(data, 0, data.length - 1); for (int i = 0; i &lt; data.length; i++) &#123; System.out.print(data[i] + \"--\"); &#125; &#125;&#125; 二分查找12345678910111213141516171819202122//二分查找，返回数组索引public class BinarySearch &#123; public static int search(int[]a,int goal) &#123; int low = 0; int high = a.length-1; while (low &lt;= high) &#123; int mid = (high - low) / 2 + low; // 直接使用(high + low) / 2 可能导致溢出 if (a[mid] == goal) return mid; //在左半边 else if (a[mid] &gt; goal) high = mid - 1; //在右半边 else low = mid + 1; &#125; //没找到 return -1; &#125;&#125; 二维数组的查找123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//题目： //在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。//请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。public class Solution1 &#123; public static void main(String[] args) &#123; int[][] array = &#123; &#123; 1, 2, 8, 9 &#125;, &#123; 2, 4, 9, 12 &#125;, &#123; 4, 7, 10, 13 &#125;, &#123; 6, 8, 11, 15 &#125; &#125;; // int[][] array = &#123; &#123;&#125; &#125;; int target = 5; boolean find = Solution.Find1(target, array); System.out.println(find); &#125; // 左下角开始进行比较，矩阵往右递增，往上递减。 // 这个设计思路是target小就往右比较，target大就往上比较，不会忽略数据，因为任意一个值都一定 //大于它左边和它上边，方形区域的所有值。 public static boolean Find1(int target, int[][] array) &#123; int notcol = array[0].length;// 矩阵第一行有多少值 // 防止出现[[]]数组，此数组array.length值为1 if (notcol == 0) &#123; return false; &#125; int firstIndex = array.length - 1;// 矩阵有多少行 int i = firstIndex;// 行的位置 int j = 0;// 列的位置 while (target != array[i][j]) &#123; if (target &lt; array[i][j] &amp;&amp; i &gt;= 0) &#123; // array往上移动，找一个更小的array值和target比 i--; &#125; else if (target &gt; array[i][j] &amp;&amp; j &lt;= firstIndex) &#123; j++; &#125; if (i &lt; 0 || j &gt; firstIndex) &#123; return false; &#125; &#125; return true;// while条件不成立，值相等 &#125; // 参考答案 public static boolean Find(int[][] array, int target) &#123; int len = array.length - 1; int i = 0; while ((len &gt;= 0) &amp;&amp; (i &lt; array[0].length)) &#123; if (array[len][i] &gt; target) &#123; len--; &#125; else if (array[len][i] &lt; target) &#123; i++; &#125; else &#123; return true; &#125; &#125; return false; &#125;&#125; 字符串替换空格123456789101112131415161718192021222324252627282930313233343536373839404142434445//题目： //请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的//字符串为We%20Are%20Happy。public class Solution2 &#123; public static void main(String[] args) &#123; StringBuffer sb = new StringBuffer(\"We Are Happy\"); Solution2.replaceSpace2(sb); System.out.println(sb); &#125; // eclipse上无法显示“%”，下面代码无法解决空格在字符串前后的问题 public static String replaceSpace1(StringBuffer str) &#123; StringBuffer sb = new StringBuffer(); String string = str.toString(); String[] split = string.split(\" \"); for (int i = 0; i &lt; split.length - 1; i++) &#123; split[i] += \"%20\"; sb.append(split[i]); &#125; sb.append(split[split.length - 1]); return sb.toString(); &#125; // 使用charAt取值，使用String.valueOf方法可以将char类型转换为String类型 public static String replaceSpace2(StringBuffer str) &#123; StringBuffer sb = new StringBuffer(); String s = str.toString(); for (int i = 0; i &lt; s.length(); i++) &#123; char tmp = s.charAt(i); if (\" \".equals(String.valueOf(tmp))) &#123; sb.append(\"%\"); sb.append(\"20\"); &#125; else &#123; sb.append(tmp); &#125; &#125; return sb.toString(); &#125;&#125; 从尾到头打印链表1234567891011121314151617181920212223242526272829import java.util.ArrayList;//题目： //输入一个链表，从尾到头打印链表每个节点的值。public class Solution3 &#123; // 链表节点示意 public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125; &#125; // 成员变量，用于返回 ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); // 使用递归 public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; if (listNode != null) &#123; // 先不添加到list，直到某个listNode的下个节点为null时，开始添加 this.printListFromTailToHead(listNode.next); list.add(listNode.val); &#125; return list; &#125;&#125; 用两个栈实现队列12345678910111213141516171819202122232425262728293031323334import java.util.Stack;//题目： //用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型//分析思路public class Solution4 &#123; Stack&lt;Integer&gt; stack1 = new Stack&lt;Integer&gt;(); Stack&lt;Integer&gt; stack2 = new Stack&lt;Integer&gt;(); // 进队列，数据压人stack1，即将出队列的值在stack1的最底部，把stack1的值全部倒入stack2中， //才可以让值暴露在栈外面 public void push(int node) &#123; stack1.push(node); &#125; public int pop() &#123; // 把stack1的数据导入stack2中 while (!stack1.isEmpty()) &#123; stack2.push(stack1.pop()); &#125; // stack2最外面的值就是要出队列的，调用stack2.pop方法后，stack1无数据， //stack2不包括刚出队列的值 int first = stack2.pop(); // 再将stack2的数据倒入stack1中，这整个过程，就将stack1最底部的值删除并返回了 while (!stack2.isEmpty()) &#123; stack1.push(stack2.pop()); &#125; return first; &#125;&#125; 斐波那契数列1234567891011121314151617181920212223242526272829//题目//现在要求输入一个整数n，请你输出斐波那契数列的第n项。1,1,2,3,5,8...//n&lt;=39public class Solution6 &#123; public int Fibonacci(int n) &#123; if (n == 1 || n == 2) &#123; return 1; &#125; if (n &gt; 2 &amp;&amp; n &lt;= 39) &#123; int value1 = 1; int value2 = 2; for (int i = 0; i &lt; n - 3; i++) &#123; int tmp = value2; value2 += value1; value1 = tmp; &#125; return value2; &#125; else &#123; // 数据超过39 return 0; &#125; &#125;&#125; 跳台阶12345678910111213141516171819202122232425262728293031323334//题目//一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。//解答思路：先做数学题//n=1时，1种，n=2时，2种，n=3时，3种//n=4时，先跳1，还剩3，有3种跳法，若先跳2，还剩2，有2种跳法，总共5种//推测：斐波拉契数序列，和上题比，序列少了一个1，1,2,3,5,8...public class Solution7 &#123; public int JumpFloor(int target) &#123; if (target &lt;= 0) &#123; return 0; &#125; if (target == 1) &#123; return 1; &#125; if (target == 2) &#123; return 2; &#125; else &#123; int value1 = 1; int value2 = 2; for (int i = 0; i &lt; target - 2; i++) &#123; // 顺序不能颠倒 int tmp = value2; value2 += value1; value1 = tmp; &#125; return value2; &#125; &#125;&#125; 变态跳台阶12345678910//一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。//求该青蛙跳上一个n级的台阶总共有多少种跳法。 //先做数学题：n=1时，1种，n=2时，2种。n=3时，分类讨论，共有2+1+1=4种，n=4，有f3+f2+f1+1=8种。//归纳：n为target时，有2的target-1次方种public class Solution1 &#123; public int JumpFloorII(int target) &#123; return 1 &lt;&lt; target - 1; &#125;&#125; 矩形覆盖1234567891011121314151617181920212223242526272829303132333435363738//我们可以用2*1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地//覆盖一个2*n的大矩形，总共有多少种方法？ //之前思路有误，认为相同的摆法，矩形的位置调换，也是一种新的方法，这种思路找不到规律。//下面参考了别人的思路，n为1时，有1种摆法，n为2时，有2中摆法，n&gt;=3时，假设是在长为n，//宽为2的大矩形上。大矩形最左边只有2种可能，一:1块小矩形竖着放，大矩形剩余长度为n-1。//二:2块小矩形横着放，大矩形剩余长度为n-2.由此，发现了斐波那契数列。public class Solution2 &#123; public int RectCover(int target) &#123; if (target &lt; 1) &#123; return 0; &#125; else if (target == 1) &#123; return 1; &#125; else if (target == 2) &#123; return 2; &#125; else &#123; int t1 = 1; int t2 = 2; for (int i = 0; i &lt; target - 2; i++) &#123; int temp = t2; t2 = t1 + t2; t1 = temp; &#125; return t2; &#125; &#125; // 递归的简洁写法 public int RectCover1(int target) &#123; if (target &lt;= 1) &#123; return 1; &#125; else if (target == 2) &#123; return 2; &#125; else &#123; return RectCover1(target - 1) + RectCover1(target - 2); &#125; &#125;&#125; 二进制中1的个数1234567891011121314//输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。 //负数在计算机中是用补码表示，无论正负，都是求其中1的个数。任何一个数减1，其二进制从右往左看，//第一个1变成0，第一个1右边的所有0都变成1。让它和原来的数进行&amp;计算，可以达到逐个消除1的效果public class Solution3 &#123; public int NumberOf1(int n) &#123; int count = 0; while (n != 0) &#123; n = n &amp; (n - 1); count++; &#125; return count; &#125;&#125; 数值的整数次方123456789101112131415161718192021222324252627282930//给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。 //可以根据exponent的正负分类讨论public class Solution4 &#123; public double Power(double base, int exponent) &#123; double result = 1.0; for (int i = 0; i &lt; Math.abs(exponent); i++) &#123; result *= base; &#125; if (exponent &gt;= 0) &#123; return result; &#125; else &#123; return 1 / result; &#125; &#125; // 先求出次方为正数时的解，再分析次方为负数时的解 public double Power1(double base, int exponent) &#123; int n = Math.abs(exponent);// 次方数的绝对值 double r = 1.0;// 定义计算结果值 while (n != 0) &#123; // r=2^101=(4^50)*2=(8^25)*2=(64^12)*8*2=...规律如下 if ((n &amp; 1) == 1) r *= base;// 次方数为奇数时，结果值要乘上底数 base *= base;// 底数以2次方的形式增长 n &gt;&gt;= 1;// 次方数不断取其除以2的向下取整值 &#125; return exponent &lt; 0 ? 1 / r : r; &#125;&#125; 调整数组顺序使奇数位于偶数前面1234567891011121314151617181920212223242526272829303132333435363738//输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，//所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。 //使用list集合先添加所有奇数，后添加所有偶数，遍历list集合public class Solution5 &#123; public void reOrderArray(int[] array) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); for (int i = 0; i &lt; array.length; i++) &#123; if (array[i] % 2 == 1) list.add(array[i]); &#125; for (int i = 0; i &lt; array.length; i++) &#123; if (array[i] % 2 == 0) &#123; list.add(array[i]); &#125; &#125; for (int i = 0; i &lt; array.length; i++) &#123; array[i] = list.get(i); &#125; &#125; // 使用冒泡排序，分析思路： public void reOrderArray1(int[] array) &#123; // i值标记冒泡排序的趟数，数组索引不应该使用i。 for (int i = 0; i &lt; array.length - 1; i++) &#123; // j值标记比较的次数，也就是可以从头逐步两两比较的次数 for (int j = 0; j &lt; array.length - 1 - i; j++) &#123; if (array[j] % 2 == 0 &amp;&amp; array[j + 1] % 2 == 1) &#123; // 前偶后奇才交换，保证了奇数偶数的相对位置不变，内层循环完1次， //就可以确定，一个相对位置正确的偶数已经放在了相对最右边 int t = array[j]; array[j] = array[j + 1]; array[j + 1] = t; &#125; &#125; &#125; &#125;&#125; 链表中倒数第k个节点12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//输入一个链表，输出该链表中倒数第k个结点。 public class Solution6 &#123; // 节点代码示意 public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125; &#125; // 我的代码： public ListNode FindKthToTail(ListNode head, int k) &#123; ListNode tmp = head; if (tmp == null || k &lt; 0) &#123; return null; &#125; // 先统计总节点数，注意all从1开始，包括头结点 int all = 1; while (head.next != null) &#123; all++; head = head.next; &#125; if (k &gt; all) return null; // 倒数第k个节点的位置 int count = all - k; // 遍历寻找该节点 while (count != 0) &#123; tmp = tmp.next; count--; &#125; return tmp; &#125; // 分析思路 public ListNode FindKthToTail1(ListNode head, int k) &#123; if (head == null || k &lt;= 0) return null; ListNode nodePre = head; ListNode nodeLast = head; // 最后得到的nodePre节点是第k个节点，注意循环条件 for (int i = 1; i &lt; k; i++) &#123; if (nodePre.next != null) nodePre = nodePre.next; else return null;// k值超过总节点数的情况 &#125; // 最后求出的nodeLast为倒数第k个节点 while (nodePre.next != null) &#123; // nodePre往后还剩多少个节点，nodeLast就应该从头走多少个节点。 nodePre = nodePre.next; nodeLast = nodeLast.next; &#125; return nodeLast; &#125;&#125; 反转链表123456789101112131415161718192021222324252627//输入一个链表，反转链表后，输出链表的所有元素。 public class Solution7 &#123; public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125; &#125; //分析思路：所有节点的next指针反过来指向前一个节点，原head节点指向null public ListNode ReverseList(ListNode head) &#123; ListNode pre = null; ListNode next = null; if(head==null)&#123; return null; &#125; while(head!=null)&#123; next = head.next;//保存head的next节点，下行代码的操作会改变它 head.next = pre;//让当前节点的指针指向前一个节点 pre = head;//更新pre为当前head节点 head = next;//更新head节点为一开始保存的节点 &#125; return pre; &#125;&#125; 合并两个递增的链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990//输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 class ListNode &#123; int val; ListNode next; ListNode(int val) &#123; this.val = val; &#125;&#125; public class Solution1 &#123; // 思路：要确定两个链表的最小值，把它赋给一个新链表的头，在这个新链表的基础上进行添加 public ListNode Merge(ListNode list1, ListNode list2) &#123; if (list1 == null) &#123; return list2; &#125; if (list2 == null) &#123; return list1; &#125; // 定义一个头结点，头结点用于返回，不应该变化 ListNode head = null; // 此节点用于组装一条链表 ListNode current = null; while (list1 != null &amp;&amp; list2 != null) &#123; if (list1.val &lt;= list2.val) &#123; if (head == null) &#123;// head为null时current也为null head = current = list1; list1 = list1.next;// 这里容易忽视 &#125; else &#123;// else必须要加 // 下面两行代码决定了续航能力 current.next = list1; current = current.next; list1 = list1.next; &#125; &#125; else &#123; if (head == null) &#123; head = current = list2; list2 = list2.next; &#125; else &#123; current.next = list2; current = current.next; list2 = list2.next; &#125; &#125; &#125; // 单独讨论2种特殊情况 if (list1 == null) &#123; current.next = list2;// 注意，不能current=list2 &#125; else &#123; current.next = list1; &#125; return head; &#125; //递归写法，也是在一个新链表基础上操作 public ListNode Merge2(ListNode list1,ListNode list2) &#123; if(list1==null)&#123; return list2; &#125;else if(list2==null)&#123; return list1; &#125; ListNode pMergeHead = null; if(list1.val&lt;list2.val)&#123; pMergeHead = list1; pMergeHead.next = Merge(list1.next,list2); &#125;else&#123; pMergeHead = list2; pMergeHead.next = Merge(list1,list2.next); &#125; return pMergeHead; &#125; public static void main(String[] args) &#123; ListNode list1 = new ListNode(1); ListNode list2 = new ListNode(2); list1.next = new ListNode(3); list1.next.next = new ListNode(5); list2.next = new ListNode(4); list2.next.next = new ListNode(6); Solution1 ss = new Solution1(); ListNode tt = ss.Merge(list1, list2); while (tt.next != null) &#123; System.out.println(tt.val); tt = tt.next; &#125; &#125;&#125; 树的子结构1234567891011121314151617181920212223242526272829303132333435363738//输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构） public class Solution2 &#123; class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125; &#125; // 解答思路： // 首先，我需要一个（根据树的两个根节点）能够判断b树绝对是a树子树的方法 // b上从根节点往下和a树重合，但a树的深度一定大于等于b树 public boolean isSubTree(TreeNode node1, TreeNode node2) &#123; if (node2 == null) return true;// b树遍历到底，包括b树所有叶子节点都对应a树 if (node1 == null) return false;// b树还没遍历到叶子节点，a树却遍历到叶子节点 // 如果节点内容不对应相等，也不符合要求 if (node1.val == node2.val) &#123; return isSubTree(node1.left, node2.left) &amp;&amp; isSubTree(node1.right, node2.right); &#125; else &#123; return false; &#125; &#125; // 运算符左边为真，右边不执行 public boolean HasSubtree(TreeNode root1, TreeNode root2) &#123; if (root1 == null || root2 == null) return false; return isSubTree(root1, root2) || HasSubtree(root1.left, root2) || HasSubtree(root1.right, root2); &#125;&#125; 二叉树的镜像1234567891011121314151617181920212223242526272829303132333435363738//操作给定的二叉树，将其变换为源二叉树的镜像。 // 源二叉树 // 8// / \\// 6 10// / \\ / \\// 5 7 9 11// 镜像二叉树// 8// / \\// 10 6// / \\ / \\// 11 9 7 5 //从上往下交换二叉树的左右孩子节点即可public class Solution3 &#123; class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125; &#125; public void Mirror(TreeNode root) &#123; if(root==null||(root.left ==null &amp;&amp; root.right==null)) return; //包含的左右孩子为空时的交换 TreeNode left = root.left; root.left = root.right; root.right = left; Mirror(root.left); Mirror(root.right); &#125;&#125; 从上往下打印二叉树12345678910111213141516171819202122232425262728293031import java.util.ArrayList; //从上往下打印出二叉树的每个节点，同层节点从左至右打印 public class Solution4 &#123; class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125; &#125; //思路：使用ArrayList模拟队列，类似树的广度搜索 public ArrayList&lt;Integer&gt; PrintFromTopToBottom(TreeNode root) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); ArrayList&lt;TreeNode&gt; queue = new ArrayList&lt;TreeNode&gt;(); if(root!=null) queue.add(root); while(!queue.isEmpty())&#123;//注：这里不能用queue!=null TreeNode pop = queue.remove(0); list.add(pop.val); if(pop.left!=null) queue.add(pop.left); if(pop.right!=null) queue.add(pop.right); &#125; return list; &#125;&#125; 数组中出现次数超过一半的数字1234567891011121314151617181920//数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组//&#123;1,2,3,2,2,2,5,4,2&#125;,由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2,不存在则输出0 public class Solution5 &#123; //解法思想：先排序，若存在此数，则必在数组中央 public int MoreThanHalfNum_Solution(int [] array) &#123; Arrays.sort(array); int num = array[array.length/2]; int count = 0; for(int i=0;i&lt;array.length;i++)&#123; if(num==array[i])&#123; count++; &#125; &#125; if(count&gt;array.length/2)&#123; return num; &#125; return 0; &#125;&#125; 最小k个数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import java.util.ArrayList; //输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4 public class Solution6 &#123; public static ArrayList&lt;Integer&gt; GetLeastNumbers_Solution(int[] input, int k) &#123; ArrayList&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(); if(input==null||input.length==0||input.length&lt;k||k==0)&#123; return result; &#125; int []data =new int[k];//新建一个长度为k的数组，存放堆排序内容 for(int i=0;i&lt;k;i++)&#123; data[i]=input[i]; &#125; heapSort(data); for(int i=k;i&lt;input.length;i++)&#123; if(data[k-1]&gt;input[i])&#123; data[k-1]=input[i]; heapSort(data); &#125; &#125; for(int i=0;i&lt;k;i++)&#123; result.add(data[i]); &#125; return result; &#125; //之前博客已总结过堆排序 public static void heapSort(int[] data) &#123; for (int i = 0; i &lt; data.length - 1; i++) &#123; buildMaxHeap(data, data.length - 1 - i); swap(data, 0, data.length - 1 - i); &#125; &#125; private static void buildMaxHeap(int[] data, int lastIndex) &#123; for (int i = (lastIndex - 1) / 2; i &gt;= 0; i--) &#123; int k = i; if (2 * k + 1 == lastIndex) &#123; if (data[k] &lt; data[lastIndex]) &#123; swap(data, k, lastIndex); &#125; &#125; else &#123; int tmp = data[2 * k + 1] &gt; data[2 * k + 2] ? (2 * k + 1) : (2 * k + 2); if (data[k] &lt; data[tmp]) &#123; swap(data, k, tmp); &#125; &#125; &#125; &#125; private static void swap(int[] data, int i, int j) &#123; int tmp = data[i]; data[i] = data[j]; data[j] = tmp; &#125; public static void main(String[] args) &#123; int[] input =&#123;4,5,1,6,2,7,3,8&#125;; int k=4; ArrayList&lt;Integer&gt; list = GetLeastNumbers_Solution(input,k); for(int i=0;i&lt;k;i++)&#123; System.out.println(list.get(i)); &#125; &#125;&#125; 丑数12345678910111213141516171819202122232425262728//把只包含因子2、3和5的数称作丑数（UglyNumber）例如6、8都是丑数，但14不是，因为它包含因子7//习惯上我们把1当做是第一个丑数，求按从小到大的顺序的第N个丑数 //思路：p是丑数，那么p=2^x * 3^y * 5^z，只要赋予x,y,z不同的值就能得到不同的丑数。public class Solution7 &#123; //分析思路： public int GetUglyNumber_Solution1(int index) &#123; if(index&lt;7)return index; int[] res = new int[index];//用于从小到大记录丑数 res[0] = 1; //res[t2],res[t3],res[t5]分别记录最近一次乘2,3,5的结果值 int t2 = 0, t3 = 0, t5 = 0; for (int i = 1; i &lt; index; i++)&#123; //t2,t3,t5,一定小于或等于i，但不会小得超过1 //例如当res[t3]最小时，t3自增1，下次比较时相当于未自增前的res[t3+1]*3和 //res[t2]*2,res[t5]*5比，一定比它们大，实现了res从小到大记录丑数的目的 res[i] = Math.min(res[t2] * 2, Math.min(res[t3] * 3, res[t5] * 5)); if (res[i] == res[t2] * 2)t2++; if (res[i] == res[t3] * 3)t3++; if (res[i] == res[t5] * 5)t5++; &#125; return res[index - 1]; &#125;&#125;","categories":[],"tags":[{"name":"博客重构","slug":"博客重构","permalink":"http://yoursite.com/tags/博客重构/"},{"name":"牛客网","slug":"牛客网","permalink":"http://yoursite.com/tags/牛客网/"},{"name":"简单算法","slug":"简单算法","permalink":"http://yoursite.com/tags/简单算法/"}]},{"title":"Java实现简单树","slug":"Java实现简单树","date":"2017-03-18T16:17:51.000Z","updated":"2018-03-04T03:01:58.000Z","comments":true,"path":"2017/03/19/Java实现简单树/","link":"","permalink":"http://yoursite.com/2017/03/19/Java实现简单树/","excerpt":"一颗数只能有一个根节点，如果有了多个根节点，它就称为森林 树的定义12345N个有父子关系的节点的有限集合，满足：- 当N=0，称为空树。- 任意非空树，有且仅有一个根（root）节点。- 当N&gt;1时，除根节点以外的其余节点可分为M个集合，每个集合又是一棵树，称为根的子树(subtree).- 树的任一节点可以有0或多个子节点，但只能有一个父节点，根节点没有父节点（唯一特例）","text":"一颗数只能有一个根节点，如果有了多个根节点，它就称为森林 树的定义12345N个有父子关系的节点的有限集合，满足：- 当N=0，称为空树。- 任意非空树，有且仅有一个根（root）节点。- 当N&gt;1时，除根节点以外的其余节点可分为M个集合，每个集合又是一棵树，称为根的子树(subtree).- 树的任一节点可以有0或多个子节点，但只能有一个父节点，根节点没有父节点（唯一特例） 节点的分类1231.普通节点：包含子节点，具有唯一父节点的节点。2.叶子节点：没有子节点的节点。3.根节点：没有父节点的节点。 二叉树二叉树的定义 每个节点最多只能有两个子树的有序树，左边的子树称左子树，右边的子树称右子树 一棵深度为k的二叉树，包含了2^k-1个节点，称为满二叉树 一棵二叉树除最后一层外，其余层的所有节点都是满的，称为完全二叉树，满二叉树是特殊的完全二叉树 二叉树第i层的节点数至多为2^(i-1)(i&gt;=1) 多叉树向二叉树转换1231.加虚线：同一个父节点的相邻兄弟节点之间加虚线。2.抹实线：每节点只保留它与最左子节点的连线。3.虚改实：虚线改为实线。 二叉树的顺序存储 对于普通二叉树，空出的节点对应的数组元素留空就可以了。 对于完全二叉树，没有任何空间浪费。 代码：ArrayBinTree.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class ArrayBinTree&lt;T&gt; &#123; //数组记录数的所有节点 private Object[] datas; private int DEFAULT_DEEP = 8; private int deep; private int arraySize; //以默认的深度创建二叉树 public ArrayBinTree()&#123; this.deep = DEFAULT_DEEP; this.arraySize = (int)Math.pow(2, deep)-1;//满二叉树所需节点数 datas = new Object[arraySize]; &#125; //以指定深度创建二叉树 public ArrayBinTree(int deep)&#123; this.deep = deep; this.arraySize = (int)Math.pow(2, deep)-1; datas = new Object[arraySize]; &#125; //以指定深度，指定节点创建二叉树 public ArrayBinTree(int deep,T data)&#123; this.deep = deep; this.arraySize = (int)Math.pow(2, deep)-1; datas = new Object[arraySize]; datas[0] = data; &#125; /** * 为指定节点添加子节点 * @param index 需要添加子节点的父节点索引 * @param data 新子节点的数据 * @param left 是否为左节点 */ public void add(int index,T data, boolean left)&#123; if(datas[index]==null)&#123; throw new RuntimeException(index+\"处节点为空，无法添加\"); &#125; if(2*index +1&gt;=arraySize)&#123; throw new RuntimeException(\"树底层的数组已满，树越界异常\"); &#125; //添加左节点 if(left)&#123; datas[2*index+1]=data; &#125;else&#123; datas[2*index+2]=data; &#125; &#125; public boolean isEmpty()&#123; return datas[0]==null; &#125; //返回根节点 public T root()&#123; return (T)datas[0]; &#125; //返回指定节点的父节点 public T parent(int index)&#123; return (T)datas[(index-1)/2]; &#125; //返回指定节点的左子节点，当左子节点不存在时返回null public T left(int index)&#123; if(2*index+1&gt;=arraySize)&#123; throw new RuntimeException(\"该节点为叶子节点，无子节点\"); &#125; return (T)datas[2*index+1]; &#125; //返回指定节点的右子节点，当右子节点不存在时返回null public T right(int index)&#123; if(2*index+1&gt;=arraySize)&#123; throw new RuntimeException(\"该节点为叶子节点，无子节点\"); &#125; return (T)datas[2*index+2]; &#125; //返回二叉树的深度 public int deep(int index)&#123; return deep; &#125; //返回指定节点的位置 public int pos(T data)&#123; for(int i =0;i&lt;arraySize;i++)&#123; if(datas[i].equals(data))&#123; return i; &#125; &#125; return -1; &#125; public String toString()&#123; return Arrays.toString(datas); &#125; public static void main(String[] args) &#123; ArrayBinTree&lt;String&gt; binTree = new ArrayBinTree&lt;String&gt;(4,\"根\"); binTree.add(0, \"第二层右子节点\", false); binTree.add(2, \"第三层右子节点\", false); binTree.add(6, \"第四层右子节点\", false); System.out.println(binTree); //输出：//[根, null, 第二层右子节点, null, null, null, 第三层右子节点, //null, null, null, null, null, null, null, 第四层右子节点] &#125;&#125; 二叉树的二叉链表存储 每个节点记住他的左、右子节点，代码：TwoLinkBinTree.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public class TwoLinkBinTree&lt;E&gt; &#123; public static class TreeNode&#123; Object data; TreeNode left; TreeNode right; public TreeNode()&#123; &#125; public TreeNode(Object data)&#123; this.data = data; &#125; public TreeNode(Object data,TreeNode left,TreeNode right)&#123; this.data = data; this.left = left; this.right = right; &#125; &#125; private TreeNode root; public TwoLinkBinTree()&#123; this.root = new TreeNode(); &#125; //指定根元素创建二叉树 public TwoLinkBinTree(E data)&#123; this.root = new TreeNode(data); &#125; /** * 对指定父节点添加子节点 * @param parent 指定的父节点 * @param data 新子节点的数据 * @param isLeft 是否为左节点 * @return 新增的节点 */ public TreeNode addNode(TreeNode parent,E data,boolean isLeft)&#123; if(parent == null)&#123; throw new RuntimeException(parent+\"节点为null\"); &#125; if(isLeft &amp;&amp; parent.left!=null)&#123; throw new RuntimeException(parent+\"节点已有左子节点\"); &#125; if(!isLeft &amp;&amp; parent.right!=null)&#123; throw new RuntimeException(parent+\"节点已有右子节点\"); &#125; TreeNode newNode = new TreeNode(data); if(isLeft)&#123; parent.left = newNode; &#125;else&#123; parent.right = newNode; &#125; return newNode; &#125; public boolean isEmpty()&#123; return root.data == null; &#125; //返回根节点 public TreeNode root()&#123; if(isEmpty())&#123; throw new RuntimeException(\"树为空，无法访问根节点\"); &#125; return root; &#125; //返回指定节点的左子节点，当左子节点不存在时返回null public E leftChild(TreeNode parent)&#123; if(parent==null)&#123; throw new RuntimeException(parent+\"节点为null\"); &#125; return parent.left == null?null:(E)parent.left.data; &#125; //返回指定节点的右子节点，当右子节点不存在时返回null public E rightChild(TreeNode parent)&#123; if(parent ==null)&#123; throw new RuntimeException(parent+\"节点为null\"); &#125; return parent.right == null?null:(E)parent.right.data; &#125; //返回二叉树的深度 public int deep()&#123; return deep(root); &#125; private int deep(TreeNode node) &#123; if(node==null)&#123; return 0; &#125; if(node.left == null &amp;&amp; node.right ==null)&#123; return 1; &#125;else&#123; int leftDeep = deep(node.left); int rightDeep = deep(node.right); int max = leftDeep&gt;rightDeep?leftDeep:rightDeep; return max + 1;//max是左或右子树的深度，要加1 &#125; &#125;&#125; 二叉树的三叉链表存储 让每个节点不仅记住他的左、右子节点，还记住它的父节点，代码：ThreeLinkBinTree.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117import java.util.ArrayDeque;import java.util.ArrayList;import java.util.List;import java.util.Queue; public class ThreeLinkBinTree&lt;E&gt; &#123; public static class TreeNode&#123; Object data; TreeNode left; TreeNode right; TreeNode parent; public TreeNode()&#123; &#125; public TreeNode(Object data)&#123; this.data = data; &#125; public TreeNode(Object data,TreeNode left,TreeNode right, TreeNode parent)&#123; this.data = data; this.left = left; this.right = right; this.parent = parent; &#125; &#125; private TreeNode root; public ThreeLinkBinTree()&#123; this.root = new TreeNode(); &#125; public ThreeLinkBinTree(E data)&#123; this.root = new TreeNode(data); &#125; /** * 为指定节点添加子节点 * @param parent 需要添加子节点的父节点 * @param data 新子节点的数据 * @param isLeft 是否为左节点 * @return 新增的节点 */ public TreeNode addNode(TreeNode parent,E data,boolean isLeft)&#123; if(parent==null)&#123; throw new RuntimeException(parent+\"节点为null\"); &#125; if(isLeft &amp;&amp; parent.left != null)&#123; throw new RuntimeException(parent+\"节点已有左子节点\"); &#125; if(!isLeft &amp;&amp; parent.right != null)&#123; throw new RuntimeException(parent+\"节点已有右子节点\"); &#125; TreeNode newNode = new TreeNode(data); if(isLeft)&#123; parent.left = newNode; &#125;else&#123; parent.right = newNode; &#125; //让新节点的parent引用到parent节点 newNode.parent = parent; return newNode; &#125; public boolean isEmpty()&#123; return root.data == null; &#125; //返回根节点 public TreeNode root()&#123; if(isEmpty())&#123; throw new RuntimeException(\"树为空，无法访问根节点\"); &#125; return root; &#125; //返回指定节点的父节点 public E parent(TreeNode node)&#123; if(node == null)&#123; throw new RuntimeException(node+\"节点为null\"); &#125; return (E)node.parent.data; &#125; //返回指定节点的左子节点 public E leftChild(TreeNode parent)&#123; if(parent == null)&#123; throw new RuntimeException(parent+\"节点为null\"); &#125; return parent.left == null?null:(E)parent.left.data; &#125; //返回指定节点的右子节点 public E rightChild(TreeNode parent)&#123; if(parent == null)&#123; throw new RuntimeException(parent+\"节点为null\"); &#125; return parent.right == null?null:(E)parent.right.data; &#125; //返回二叉树的深度 public int deep()&#123; return deep(root); &#125; private int deep(TreeNode node) &#123; if(node == null)&#123; return 0; &#125; if(node.left ==null &amp;&amp; node.right == null)&#123; return 1; &#125;else&#123; int leftDeep = deep(node.left); int rightDeep = deep(node.right); int max = leftDeep&gt;rightDeep?leftDeep:rightDeep; return max+1; &#125; &#125; 深度优先搜索（接上面代码）1根据处理根节点的时机，来判断是什么遍历。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960 //实现先序遍历public List&lt;TreeNode&gt; preIterator()&#123; return preIterator(root);&#125; private List&lt;TreeNode&gt; preIterator(TreeNode node) &#123; ArrayList&lt;TreeNode&gt; list = new ArrayList&lt;TreeNode&gt;(); list.add(node);//先处理根节点 //递归处理左子树 if(node.left!=null)&#123; list.addAll(preIterator(node.left)); &#125; //递归处理右子树 if(node.right!=null)&#123; list.addAll(preIterator(node.right)); &#125; return list;&#125; //实现中序遍历public List&lt;TreeNode&gt; inIterator()&#123; return inTerator(root);&#125; private List&lt;TreeNode&gt; inTerator(TreeNode node) &#123; ArrayList&lt;TreeNode&gt; list = new ArrayList&lt;TreeNode&gt;(); //递归处理左子树 if(node.left!=null)&#123; list.addAll(inTerator(node.left)); &#125; //中间位置处理根节点 list.add(node); //递归处理右子树 if(node.right!=null)&#123; list.addAll(inTerator(node.right)); &#125; return list;&#125; //实现后序遍历public List&lt;TreeNode&gt; postIterator()&#123; return postIterator(root);&#125; private List&lt;TreeNode&gt; postIterator(TreeNode node) &#123; ArrayList&lt;TreeNode&gt; list = new ArrayList&lt;TreeNode&gt;(); //递归处理左子树 if(node.left!=null)&#123; list.addAll(postIterator(node.left)); &#125; //递归处理右子树 if(node.right!=null)&#123; list.addAll(postIterator(node.right)); &#125; //最后处理根节点 list.add(node); return list;&#125; 广度优先搜索（接上面代码）1231.建立一个队列，把树的根节点压入队列。2.从队列中弹出一个节点（第一次弹出的是根节点），分别把该节点的左、右节点压人队列3.重复2即可。当队列为空时，也就完成了遍历。 12345678910111213141516171819public List&lt;TreeNode&gt; breadthFirst()&#123; Queue&lt;TreeNode&gt; queue = new ArrayDeque&lt;TreeNode&gt;(); List&lt;TreeNode&gt; list = new ArrayList&lt;TreeNode&gt;(); if(root!=null)&#123; //将根元素加入队列 queue.offer(root); &#125; while(!queue.isEmpty())&#123; list.add(queue.peek()); TreeNode p = queue.poll();//弹队列 if(p.left!=null)&#123; queue.offer(p.left); &#125; if(p.right!=null)&#123; queue.offer(p.right); &#125; &#125; return list;&#125; 排序二叉树排序二叉树的定义1234要么是一棵空二叉树，要么具有以下性质：- 若它的左子树不空，则左子树上所有节点的值均小于它的根节点的值- 若它的右子树不空，则右子树上所有节点的值均大于它的根节点的值- 它的左、右子树也分别为排序二叉树 添加二叉树节点的步骤123451.以根节点为当前节点开始搜索2.拿新节点的值和当前节点的值比较： - 新节点的值更大，以当前节点的右子节点作为新的当前节点 - 新节点的值更小，以当前节点的左子节点作为新的当前节点3.重复2，直到找到合适的叶子节点，新节点更大，添加为右子节点，否则，添加为左子节点 删除一个节点后，要对排序二叉树进行维护123- 被删除的是叶子节点，直接删除即可- 被删除的只有左或只有右子树，只需把左、右子树添加成其父节点的左、右子树即可- 被删除的节点既有左子树又有右子树，让左子树最大值代替原来位置，右子树最大值在左子树基础上进行排序插入 代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209import java.util.ArrayDeque;import java.util.ArrayList;import java.util.List;import java.util.Queue; public class SortedBinTree&lt;T extends Comparable&gt; &#123; static class Node&#123; Object data; Node parent; Node left; Node right; public Node(Object data,Node parent,Node left,Node right)&#123; this.data = data; this.parent = parent; this.left = left; this.right = right; &#125; public String toString()&#123; return \"[data=\"+data+\"]\"; &#125; public boolean equals(Object obj)&#123; if(this==obj)&#123; return true; &#125; if(obj.getClass() == Node.class)&#123; Node target = (Node)obj; return data.equals(target.data) &amp;&amp; left == target.left &amp;&amp; right == target.right &amp;&amp; parent == target.parent; &#125; return false; &#125; &#125; private Node root; public SortedBinTree()&#123; root = null; &#125; public SortedBinTree(T o)&#123; root = new Node(o,null,null,null); &#125; public void add(T ele)&#123; if(root==null)&#123; root = new Node(ele,null,null,null); &#125;else&#123; Node current = root; Node parent = null; int cmp = 0; //找到合适的叶子节点，以该叶子节点为父节点添加新节点 do&#123; parent = current; cmp = ele.compareTo(current.data); //如果新节点的值大于当前节点 if(cmp&gt;0)&#123; //以右节点作为当前节点 current = current.right; &#125;else&#123; current = current.left; &#125; &#125;while(current!=null); Node newNode = new Node(ele,parent,null,null); //如果新节点的值大于父节点 if(cmp&gt;0)&#123; parent.right = newNode; &#125;else&#123; parent.left = newNode; &#125; &#125; &#125; public void remove(T ele)&#123; Node target = getNode(ele); if(target==null)&#123; return; &#125; //左右子树为空 if(target.left == null &amp;&amp; target.right == null)&#123; //被删除的是根节点 if(target == root)&#123; root = null; &#125;else&#123; //被删除的是父节点的左子节点 if(target == target.parent.left)&#123; target.parent.left = null; &#125;else&#123; target.parent.right = null; &#125; //释放被删除节点的父节点指针内存 target.parent = null; &#125; &#125; //左子树为空，右子树不为空 else if(target.left == null &amp;&amp; target.right !=null)&#123; if(target == root)&#123; root = target.right; &#125;else&#123; //被删除节点是父节点的左子节点 if(target == target.parent.left)&#123; target.parent.left = target.right; &#125;else&#123; target.parent.right = target.right; &#125; //让target的右子树的parent指向target的parent， //因为它现在还指向target target.right.parent = target.parent; target.parent = null; &#125; &#125; //左子树不为空，右子树为空 else if(target.left!=null &amp;&amp; target.right == null)&#123; if(target == root)&#123; root = target.left; &#125;else&#123; //被删除的节点是父节点的左子节点 if(target == target.parent.left)&#123; target.parent.left = target.left; &#125;else&#123; target.parent.right = target.left; &#125; target.left.parent = target.parent; target.parent = null; &#125; &#125; //左右子树都不为空 else&#123; //leftMaxNode用于保存target节点的左子树的最大的节点 Node leftMaxNode = target.left; while(leftMaxNode.right!=null)&#123; leftMaxNode = leftMaxNode.right; &#125; //删除原来子树的右子树 leftMaxNode.parent.right = null; //左子树最大值代替被删除节点的位置 leftMaxNode.parent = target.parent; //如果删除的是父节点的左子节点 if(target == target.parent.left)&#123; target.parent.left = leftMaxNode; &#125;else&#123; target.parent.right = leftMaxNode; &#125; //注意leftMaxNode是节点，不是子树 leftMaxNode.left = target.left; leftMaxNode.right = target.right; target.parent = target.left = target.right = null; &#125; &#125; //根据给定值搜索节点 private Node getNode(T ele) &#123; //从根节点开始 Node p = root; while (p!=null)&#123; int cmp = ele.compareTo(p.data); if(cmp&lt;0)&#123; p = p.left; &#125;else if(cmp&gt;0)&#123; p = p.right; &#125;else&#123; return p; &#125; &#125; return null; &#125; //广度优先遍历 public List&lt;Node&gt; breadthFirst()&#123; Queue&lt;Node&gt; queue = new ArrayDeque&lt;Node&gt;(); List&lt;Node&gt; list = new ArrayList&lt;Node&gt;(); if(root!=null)&#123; queue.offer(root); &#125; while(!queue.isEmpty())&#123; list.add(queue.peek()); Node p = queue.poll(); if(p.left!=null)&#123; queue.offer(p.left); &#125; if(p.right != null)&#123; queue.offer(p.right); &#125; &#125; return list; &#125; public static void main(String[] args) &#123; SortedBinTree&lt;Integer&gt; tree = new SortedBinTree&lt;Integer&gt;(); tree.add(5); tree.add(20); tree.add(10); tree.add(3); tree.add(8); tree.add(15); tree.add(30); System.out.println(tree.breadthFirst()); tree.remove(20); System.out.println(tree.breadthFirst()); //输出：// [[data=5], [data=3], [data=20], [data=10], [data=30], [data=8], [data=15]]// [[data=5], [data=3], [data=15], [data=10], [data=30], [data=8]] &#125;&#125; 红黑树简介123456781.排序二叉树虽然可以快速检索，但如果插入的数据本身就是有序的，它就会变成左斜线，或右斜线状的链表。2.红黑树是改进后的排序二叉树，又叫对称二叉B树3.红黑树在原有排序二叉树的基础上增加了如下要求： 1.每个节点要么是红色，要么是黑色 2.根节点永远是黑色的 3.所有的叶子节点都是空节点，并且是黑色的 4.每个红色节点的两个子节点都是黑色 5.从任一节点到其子树中的每个叶子节点的路径都包含相同数量的黑色节点 哈夫曼树简介1哈夫曼树又称最优二叉树，是一类带权路径最短的二叉树，在信息检索中很常用。","categories":[],"tags":[{"name":"博客重构","slug":"博客重构","permalink":"http://yoursite.com/tags/博客重构/"},{"name":"简单数据结构","slug":"简单数据结构","permalink":"http://yoursite.com/tags/简单数据结构/"}]},{"title":"Java实现简单栈和队列","slug":"Java实现简单栈和队列","date":"2017-03-18T10:05:34.000Z","updated":"2018-03-04T03:01:57.000Z","comments":true,"path":"2017/03/18/Java实现简单栈和队列/","link":"","permalink":"http://yoursite.com/2017/03/18/Java实现简单栈和队列/","excerpt":"栈定义： 只能在某一端进行插入、删除的特殊线性表。 通常在线性表尾端插入、删除。 允许插入、删除的一端称为栈顶，另一端称为栈底。 插入元素叫做压栈（push），删除元素叫做弹栈（pop）。","text":"栈定义： 只能在某一端进行插入、删除的特殊线性表。 通常在线性表尾端插入、删除。 允许插入、删除的一端称为栈顶，另一端称为栈底。 插入元素叫做压栈（push），删除元素叫做弹栈（pop）。 通常不应该提供如下方法： 获取指定索引的元素。 按元素查找元素索引。 向指定索引处插入元素。 向指定索引处删除元素。 栈的顺序存储结构及实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130import java.util.Arrays; public class SequenceStack&lt;T&gt; &#123; private int DEFAULT_SIZE = 10; //数组长度 private int capacity; //当底层数组容量不够时，程序每次增加的数组长度 private int increase = 10; //保存顺序栈中的元素 private Object[] data; //保存顺序栈中当前元素个数 private int size = 0; //以默认数组长度创建空顺序栈 public SequenceStack()&#123; capacity = DEFAULT_SIZE; data = new Object[capacity]; &#125; //以一个初始化元素创建顺序栈 public SequenceStack(T element)&#123; this(); data[0] = element; size++; &#125; //指定长度数组创建顺序栈 public SequenceStack(T element,int initSize)&#123; this.capacity = initSize; data = new Object[capacity]; data[0] = element; size++; &#125; //并且指定底层数组每次增加的长度 public SequenceStack(T element,int initSize,int increase)&#123; this.capacity = initSize; this.increase = increase; data = new Object[capacity]; data[0] = element; size++; &#125; //获取顺序栈的大小 public int length()&#123; return size; &#125; //入栈 public void push(T element)&#123; ensureCapacity(size+1); //上句方法复制了原来数据，这里只要考虑新压数据 data[size++]=element; &#125; private void ensureCapacity(int minCapacity) &#123; if(minCapacity&gt;capacity)&#123; if(increase&gt;0)&#123; while(capacity&lt;minCapacity)&#123; capacity+=increase; &#125; &#125;else&#123; while(capacity&lt;minCapacity)&#123; capacity&lt;&lt;=1; &#125; &#125; data = Arrays.copyOf(data, capacity); &#125; &#125; //出栈 public T pop()&#123; T oldValue = (T)data[size-1]; //入栈是按size判断的，这里让size-1，且释放栈顶元素，如果不释放， //栈顶元素将在下次压栈后才释放内存。 data[--size] = null; return oldValue; &#125; //返回栈顶元素，但不删除栈顶元素 public T peek()&#123; return (T)data[size-1];//不能用--size，因为size不能变 &#125; //判断顺序栈是否为空栈 public boolean isEmpty()&#123; return size==0; &#125; //清空顺序栈 public void clear()&#123; //释放内存 Arrays.fill(data, null); size = 0; &#125; public String toString()&#123; if(size==0)&#123; return \"[]\"; &#125;else&#123; StringBuffer sb = new StringBuffer(\"[\"); for(int i=size-1;i&gt;-1;i--)&#123; sb.append(data[i].toString()+\", \"); &#125; int len = sb.length(); return sb.delete(len-2, len).append(\"]\").toString(); &#125; &#125; public static void main(String[] args) &#123; SequenceStack&lt;String&gt; stack = new SequenceStack&lt;String&gt;(); stack.push(\"aaaa\"); stack.push(\"bbbb\"); stack.push(\"cccc\"); stack.push(\"dddd\"); System.out.println(stack); System.out.println(\"访问栈顶元素：\"+stack.peek()); System.out.println(\"第一次弹出栈顶元素：\"+stack.pop()); System.out.println(\"第二次弹出栈顶元素：\"+stack.pop()); System.out.println(\"两次pop之后的栈：\"+stack); //输出： [dddd, cccc, bbbb, aaaa]// 访问栈顶元素：dddd// 第一次弹出栈顶元素：dddd// 第二次弹出栈顶元素：cccc// 两次pop之后的栈：[bbbb, aaaa] &#125;&#125; 栈的链式存储结构及实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class LinkStack&lt;T&gt; &#123; private class Node&#123; private T data; private Node next; public Node(T data,Node next)&#123; this.data = data; this.next = next; &#125; &#125; private Node top;//栈顶元素 private int size; public LinkStack()&#123; top = null; &#125; public LinkStack(T element)&#123; top = new Node(element,null); size++; &#125; public int length()&#123; return size; &#125; //进栈 public void push(T element)&#123; top = new Node(element,top); size++; &#125; //出栈 public T pop()&#123; Node oldTop = top; top = top.next; //原来的栈顶元素的引用还未清除 oldTop.next = null; size--; return oldTop.data; &#125; //访问栈顶元素，但不删除 public T peek()&#123; return top.data; &#125; //判断是否为空栈 public boolean isEmpty()&#123; return size ==0; &#125; //清空链栈 public void clear()&#123; top = null; size = 0; &#125; public String toString()&#123; if(isEmpty())&#123; return \"[]\"; &#125;else&#123; StringBuffer sb = new StringBuffer(\"[\"); for(Node current = top;current !=null;current = current.next)&#123; sb.append(current.data.toString()+\", \"); &#125; int len = sb.length(); return sb.delete(len-2, len).append(\"]\").toString(); &#125; &#125; public static void main(String[] args) &#123; LinkStack&lt;String&gt; stack = new LinkStack&lt;String&gt;(); stack.push(\"aaaa\"); stack.push(\"bbbb\"); stack.push(\"cccc\"); stack.push(\"dddd\"); System.out.println(stack); System.out.println(\"访问栈顶元素：\"+stack.peek()); System.out.println(\"第一次弹出栈顶元素：\"+stack.pop()); System.out.println(\"第二次弹出栈顶元素：\"+stack.pop()); System.out.println(\"两次pop之后的栈：\"+stack); //输出： [dddd, cccc, bbbb, aaaa]// 访问栈顶元素：dddd// 第一次弹出栈顶元素：dddd// 第二次弹出栈顶元素：cccc// 两次pop之后的栈：[bbbb, aaaa] &#125;&#125; 队列定义： 只允许在表的前端（front）进行删除，只允许在表的后端（rear）进行插入操作。 进行插入的端称为队尾，进行删除操作的端称为队头。 通常不应该提供如下方法： 获取指定索引的元素。 按元素查找元素索引。 向指定索引处插入元素。 向指定索引处删除元素。 队列的顺序存储结构及实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105import java.util.Arrays; public class SequenceQueue&lt;T&gt; &#123; private int DEFAULT_SIZE = 10; //保存数组长度 private int capacity; //保存顺序队列的元素 private Object[] elementData; //保存顺序队列中元素的当前个数 private int front = 0; private int rear = 0; public SequenceQueue()&#123; capacity = DEFAULT_SIZE; elementData = new Object[capacity]; &#125; public SequenceQueue(T element)&#123; this(); elementData[0] = element; rear++; &#125; public SequenceQueue(T element,int initSize)&#123; this.capacity = initSize; elementData = new Object[capacity]; elementData[0] = element; rear++; &#125; public int length()&#123; return rear-front; &#125; public void add(T element)&#123; if(rear&gt;capacity-1)&#123; throw new IndexOutOfBoundsException(\"队列已满的异常\"); &#125; elementData[rear++] = element; &#125; public boolean isEmpty()&#123; return rear==front; &#125; public T remove()&#123; if(isEmpty())&#123; throw new IndexOutOfBoundsException(\"空队列异常\"); &#125; T oldValue = (T)elementData[front]; //释放队列的rear端元素 elementData[front++]=null; return oldValue; &#125; //返回队列顶元素，但不删除 public T element()&#123; if(isEmpty())&#123; throw new IndexOutOfBoundsException(\"空队列异常\"); &#125; return (T)elementData[front]; &#125; //清空顺序队列 public void clear()&#123; //释放内存 Arrays.fill(elementData, null); front = 0; rear = 0; &#125; public String toString()&#123; if(isEmpty())&#123; return \"[]\"; &#125;else&#123; StringBuffer sb = new StringBuffer(\"[\"); for(int i =front;i&lt;rear;i++)&#123; sb.append(elementData[i].toString()+\", \"); &#125; int len = sb.length(); return sb.delete(len-2, len).append(\"]\").toString(); &#125; &#125; public static void main(String[] args) &#123; SequenceQueue&lt;String&gt; queue = new SequenceQueue&lt;String&gt;(); queue.add(\"aaaa\"); queue.add(\"bbbb\"); queue.add(\"cccc\"); queue.add(\"dddd\"); System.out.println(queue); System.out.println(\"访问队列front端元素：\"+queue.element()); System.out.println(\"移除队列的front端元素：\"+queue.remove()); System.out.println(\"移除队列的front端元素：\"+queue.remove()); System.out.println(\"再次调用remove方法后的队列：\"+queue); //输出： [aaaa, bbbb, cccc, dddd]// 访问队列front端元素：aaaa// 移除队列的front端元素：aaaa// 移除队列的front端元素：bbbb// 再次调用remove方法后的队列：[cccc, dddd] &#125;&#125; 循环队列： 为了重新利用顺序队列底层数组中已删除元素所占空间，消除可能出现的“假满”现象。 当front、rear变量达到底层数组的capacity-1后，再向前进一位就自动变为0. 当front=rear时，如果底层数组elementData[front] == null表示队列为空，否则队列已满。 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124import java.util.Arrays; public class LoopQueue&lt;T&gt; &#123; private int DEFAULT_SIZE = 10; // 保存数组长度 private int capacity; private Object[] elementData; private int front = 0; private int rear = 0; public LoopQueue()&#123; capacity = DEFAULT_SIZE; elementData = new Object[capacity]; &#125; public LoopQueue(T element)&#123; this(); elementData[0] = element; rear++; &#125; public LoopQueue(T element,int initSize)&#123; this.capacity = initSize; elementData = new Object[capacity]; elementData[0] = element; rear++; &#125; public boolean isEmpty()&#123; return rear==front &amp;&amp; elementData[rear] == null; &#125; public int length()&#123; if(isEmpty())&#123; return 0; &#125; return rear&gt;front?rear-front : capacity - (front - rear); &#125; public void add(T element)&#123; if(rear == front &amp;&amp; elementData[front]!=null)&#123; throw new IndexOutOfBoundsException(\"队列已满的异常\"); &#125; elementData[rear++] = element; //如果rear已经到头，那就转头 rear = rear == capacity?0:rear; &#125; public T remove()&#123; if(isEmpty())&#123; throw new IndexOutOfBoundsException(\"空队列异常\"); &#125; T oldValue = (T)elementData[front]; //释放内存 elementData[front++] = null; //如果front已经到头，那就转头 front = front == capacity?0:front; return oldValue; &#125; //返回队列顶元素，但不删除 public T element()&#123; if(isEmpty())&#123; throw new IndexOutOfBoundsException(\"空队列异常\"); &#125; return (T)elementData[front]; &#125; //清空队列 public void clear()&#123; //释放内存 Arrays.fill(elementData, null); front = 0; rear = 0; &#125; public String toString()&#123; if(isEmpty())&#123; return \"[]\"; &#125;else&#123; if(front&lt;rear)&#123; //有效元素是front到rear之间的元素 StringBuffer sb = new StringBuffer(\"[\"); for(int i = front;i&lt;rear;i++)&#123; sb.append(elementData[i].toString()+\", \"); &#125; int len = sb.length(); return sb.delete(len-2, len).append(\"]\").toString(); &#125;else&#123; //有效元素为front到capacity，0到front的元素 StringBuffer sb = new StringBuffer(\"[\"); for(int i=front;i&lt;capacity;i++)&#123; sb.append(elementData[i].toString()+\", \"); &#125; for(int i=0;i&lt;rear;i++)&#123; sb.append(elementData[i].toString()+\", \"); &#125; int len = sb.length(); return sb.delete(len-2, len).append(\"]\").toString(); &#125; &#125; &#125; public static void main(String[] args) &#123; LoopQueue&lt;String&gt; queue = new LoopQueue&lt;String&gt;(\"aaaa\",3); queue.add(\"bbbb\"); queue.add(\"cccc\"); System.out.println(queue); queue.remove(); System.out.println(\"删除一个元素后的队列：\"+queue); queue.add(\"dddd\"); System.out.println(queue); System.out.println(\"队列满时的长度：\"+queue.length()); queue.remove(); queue.add(\"eeee\"); System.out.println(queue); //输出： [aaaa, bbbb, cccc]// 删除一个元素后的队列：[bbbb, cccc]// [bbbb, cccc, dddd]// 队列满时的长度：3// [cccc, dddd, eeee] &#125;&#125; 队列的链式存储结构及实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class LinkQueue&lt;T&gt; &#123; private class Node&#123; private T data; private Node next; public Node(T data,Node next)&#123; this.data = data; this.next = next; &#125; &#125; //链队列的头节点 private Node front; //链队列的尾节点 private Node rear; //链队列已包含的节点数 private int size; public LinkQueue()&#123; front = null; rear = null; &#125; public LinkQueue(T element)&#123; front = new Node(element,null); rear = front; size++; &#125; public int length()&#123; return size; &#125; public void add(T element)&#123; if(front == null)&#123; //该链队列是空链队列 front = new Node(element,null); rear = front; &#125;else&#123; Node newNode = new Node(element,null); rear.next = newNode; rear = newNode; size++; &#125; &#125; //删除队列front端元素 public T remove()&#123; Node oldFront = front; front = front.next; //释放内存 oldFront.next = null; size--; return oldFront.data; &#125; //访问链队列中最后一个元素 public T element()&#123; return rear.data; &#125; public boolean isEmpty()&#123; return size==0; &#125; //清空链队列 public void clear()&#123; front = null; rear = null; size = 0; &#125; public String toString()&#123; if(isEmpty())&#123; return \"[]\"; &#125;else&#123; StringBuffer sb = new StringBuffer(\"[\"); for(Node current = front;current!=null;current = current.next)&#123; sb.append(current.data.toString()+\", \"); &#125; int len = sb.length(); return sb.delete(len-2, len).append(\"]\").toString(); &#125; &#125; public static void main(String[] args) &#123; LinkQueue&lt;String&gt; queue = new LinkQueue&lt;String&gt;(\"aaaa\"); queue.add(\"bbbb\"); queue.add(\"cccc\"); System.out.println(queue); queue.remove(); System.out.println(\"删除一个元素后的队列：\"+queue); queue.add(\"dddd\"); System.out.println(queue); System.out.println(\"再添加元素后的队列\"+queue); queue.remove(); queue.add(\"eeee\"); System.out.println(queue); //输出： [aaaa, bbbb, cccc]// 删除一个元素后的队列：[bbbb, cccc]// [bbbb, cccc, dddd]// 再添加元素后的队列[bbbb, cccc, dddd]// [cccc, dddd, eeee] &#125;&#125;","categories":[],"tags":[{"name":"博客重构","slug":"博客重构","permalink":"http://yoursite.com/tags/博客重构/"},{"name":"简单数据结构","slug":"简单数据结构","permalink":"http://yoursite.com/tags/简单数据结构/"}]},{"title":"Java实现简单线性表","slug":"Java实现简单线性表","date":"2017-03-18T07:36:03.000Z","updated":"2018-03-04T03:02:03.000Z","comments":true,"path":"2017/03/18/Java实现简单线性表/","link":"","permalink":"http://yoursite.com/2017/03/18/Java实现简单线性表/","excerpt":"线性表的顺序存储结构 顺序存储的线性表是一种随机存取的存储结构。顺序表中的每个元素都可随机存取 顺序表中相邻元素ai和ai+1对应的存储地址loc（ai）和loc（ai+1）也是相邻的，loc（a i）=loc（a0）+i*b，b代表每个元素的存储单元 程序获取线性表中每个元素的存储起始地址的时间相同，读取表中数据元素的时间也相同 但当试图向线性表的指定位置添加元素时，必须重新定义新数组，也可能为底层数组扩容","text":"线性表的顺序存储结构 顺序存储的线性表是一种随机存取的存储结构。顺序表中的每个元素都可随机存取 顺序表中相邻元素ai和ai+1对应的存储地址loc（ai）和loc（ai+1）也是相邻的，loc（a i）=loc（a0）+i*b，b代表每个元素的存储单元 程序获取线性表中每个元素的存储起始地址的时间相同，读取表中数据元素的时间也相同 但当试图向线性表的指定位置添加元素时，必须重新定义新数组，也可能为底层数组扩容 代码模拟： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140import java.util.Arrays; public class SequenceList&lt;T&gt; &#123; private final int DEFAULT_SIZE = 16;//默认构造中数组的大小 private int capacity;//实时的数组大小 private Object[] data;//用来保存顺序表中的元素 private int size=0;//实时的数组中的存在的元素的数量 //默认构造 public SequenceList()&#123; capacity = DEFAULT_SIZE; data=new Object[capacity]; &#125; //以一个初始化元素构建顺序表 public SequenceList(T element)&#123; this(); data[0] = element; size++; &#125; //以一个初始化元素，和指定数组长度构建顺序表 public SequenceList(T element,int initSize)&#123; capacity = 1; while(capacity&lt;initSize)&#123; capacity&lt;&lt;=1;//不直接赋值，而是使用效率很高的位运算 &#125; data = new Object[capacity]; data[0]=element;//要保证size的大小比数组索引最大值大1 size++; &#125; //获取顺序表中实际存在元素的数量 public int length()&#123; return size; &#125; //获取顺序表索引为i的元素 public T get(int i)&#123; if(i&lt;0||i&gt;size-1)&#123; throw new IndexOutOfBoundsException(\"线性表索引越界\"); &#125; return (T)data[i]; &#125; //查找顺序表中指定元素的索引 public int locate(T element)&#123; for(int i=0;i&lt;size;i++)&#123; if(data[i].equals(element))&#123; return i; &#125; &#125; return -1; &#125; //向顺序表的指定位置插入一个元素 public void insert(T element,int index)&#123; if(index&lt;0||index&gt;size)&#123; throw new IndexOutOfBoundsException(\"顺序表索引越界\"); &#125; //需要保证实时数组大小比size+1大，该方法已将data成员变量和capacity成员变量更新 ensureCapacity(size+1); //将某数组，从哪个索引，到哪个数组，从哪个索引，总共复制多长 System.arraycopy(data, index, data, index+1, size-index); //新的数组index索引处的值需要更新 data[index]=element; size++; &#125; //在顺序表最后添加一个元素 public void add(T element)&#123; insert(element,size); &#125; //扩容代码 private void ensureCapacity(int minCapacity) &#123; if(minCapacity&gt;capacity)&#123; while(capacity&lt;minCapacity)&#123; capacity&lt;&lt;=1; &#125; //参数1：从哪个数组完全复制，参数2：指定新数组的容量 //此方法相当于仅更新了data的容量，但性能很差，顺序表不适合插入的原因 data = Arrays.copyOf(data, capacity); &#125; &#125; //删除顺序表指定索引的元素 public T delete(int index)&#123; if(index&lt;0||index&gt;size-1)&#123; throw new IndexOutOfBoundsException(\"线性表索引越界\"); &#125; T oldValue =(T)data[index]; int numMoved = size - index -1;//要移动的数组某部分的长度 if(numMoved&gt;0)&#123; System.arraycopy(data, index+1, data, index, numMoved); &#125; //清空最后一个元素，size也自减一 data[--size] = null; return oldValue; &#125; //删除最后一个元素 public T remove()&#123; return delete(size-1); &#125; //判断顺序表中元素是否为空 public boolean isEmpty()&#123; return size ==0; &#125; //清空顺序表 public void clear()&#123; Arrays.fill(data, null); size=0; &#125; public String toString()&#123; if(size==0)&#123; return \"[]\"; &#125;else&#123; StringBuffer sb = new StringBuffer(\"[\"); for(int i=0;i&lt;size;i++)&#123; sb.append(data[i].toString()+\", \"); &#125; int len = sb.length(); return sb.delete(len-2, len).append(\"]\").toString(); &#125; &#125; //测试 public static void main(String[] args) &#123; SequenceList&lt;String&gt; list = new SequenceList&lt;String&gt;(); list.add(\"aaaaa\"); list.add(\"bbbbb\"); list.add(\"ccccc\"); list.insert(\"dddddd\", 1); System.out.println(list); list.delete(2); System.out.println(list); System.out.println(\"ccccc在顺序表中的位置：\"+list.locate(\"ccccc\")); // 输出： [aaaaa, dddddd, bbbbb, ccccc]// [aaaaa, dddddd, ccccc]// ccccc在顺序表中的位置：2 &#125;&#125; 线性表的链式存储结构 链表采用一组地址任意的存储单元存放线性表中的数据元素 由于不必须按顺序存储，链表在插入、删除数据元素时比顺序表快很多。但是查找一个特定编号节点比顺序表慢很多 不需预先知道数据大小，可以充分利用计算机内存空间。但增加了节点指针域，空间开销比较大 1.单链表： 建立单链表的过程就是不断添加节点的过程 头插法建表：从空表开始，不断创建新节点，将数据元素存入节点的data域，不断以新节点为头节点指向原有的头节点（生成链表的次序和输入相反） 尾插法建表：新节点插入当前链表的表尾上，需要为链表对象定义一个变量引用最后一个节点 代码模拟： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174public class LinkList&lt;T&gt; &#123; private class Node &#123; private T data;// 节点的数据 private Node next; public Node(T data, Node next) &#123; this.data = data; this.next = next; &#125; &#125; // 单链表只需要头节点就可遍历获取其他所有节点 private Node header; private Node tail; // 单链表中实时节点数量 private int size; public LinkList() &#123; size = 0; &#125; // 指定节点中的数据，创建只有一个节点的单链表 public LinkList(T data) &#123; header = new Node(data, null); tail = header; size++; &#125; public int length() &#123; return size; &#125; // 获取索引为index的节点的数据 public T get(int index) &#123; return getNodeByIndex(index).data; &#125; private Node getNodeByIndex(int index) &#123; if (index &lt; 0 || index &gt; size - 1) &#123; throw new IndexOutOfBoundsException(\"单链表索引越界\"); &#125; // 从头节点遍历单链表index+1次，才能得到该元素 Node current = header; for (int i=0;i&lt;size &amp;&amp; current!=null;i++,current=current.next) &#123; if (i==index) &#123; return current; &#125; &#125; return null; &#125; // 指出节点中的数据，查找它在单链表中的索引位置 public int locate(T data) &#123; Node current = header; for (int i=0;i&lt;size &amp;&amp; current!=null;i++,current=current.next) &#123; if (current.data.equals(data)) &#123; return i; &#125; &#125; return -1; &#125; // 头插法建表 private void addAtHeader(T data) &#123; header = new Node(data, header);// 将当前头节点替换为传入的值 if (tail == null) &#123; tail = header; &#125; size++; &#125; // 尾插法建表 private void add(T data) &#123; if (header == null) &#123; header = new Node(data, null); tail = header;// 容易忽视这一步 &#125; else &#123; Node newNode = new Node(data, null); tail.next = newNode; tail = newNode;// 更新tail &#125; size++; &#125; // 向链表指定位置插入一个元素 public void insert(T data, int index) &#123; if (index &lt; 0 || index &gt; size) &#123; throw new IndexOutOfBoundsException(\"单链表索引越界\"); &#125; if (header == null) &#123; add(data); &#125; else &#123; if (index == 0) &#123; addAtHeader(data); &#125; else &#123; // 获取index的前一个节点 Node pre = getNodeByIndex(index - 1); // 更新pre.next,让它指向当前元素，当前元素的next指向原先pre的next pre.next = new Node(data, pre.next); size++; &#125; &#125; &#125; // 删除链表指定索引的元素 public T delete(int index) &#123; if (index &lt; 0 || index &gt; size - 1) &#123; throw new IndexOutOfBoundsException(\"单链表索引越界\"); &#125; Node del = null;// 用于返回 if (index == 0) &#123; del = header; header = header.next; &#125; else &#123; // 让index的前一个节点指向index后一个节点即可 Node pre = getNodeByIndex(index - 1); del = pre.next; pre.next = del.next; del.next = null;// 释放空间，可以不做 &#125; size--; return del.data; &#125; // 删除最后一个元素 public T remove() &#123; return delete(size - 1); &#125; // 判断单链表是否为空 public boolean isEmpty() &#123; return size == 0; &#125; // 清空单链表 public void clear() &#123; header = null; tail = null; size = 0; &#125; public String toString() &#123; if (isEmpty()) &#123; return \"[]\"; &#125; else &#123; StringBuffer sb = new StringBuffer(\"[\"); for (Node current=header;current!=null;current=current.next) &#123; sb.append(current.data.toString() + \", \"); &#125; int len = sb.length(); return sb.delete(len - 2, len).append(\"]\").toString(); &#125; &#125; // 测试 public static void main(String[] args) &#123; LinkList&lt;String&gt; list = new LinkList&lt;String&gt;(); list.insert(\"aaaa\", 0); list.add(\"bbbb\"); list.add(\"cccc\"); list.insert(\"dddd\", 1); System.out.println(list); list.delete(2); System.out.println(list); System.out.println(\"cccc在链表中的位置\" + list.locate(\"cccc\")); System.out.println(\"链表中索引2处的元素\" + list.get(2)); //输出： [aaaa, dddd, bbbb, cccc]// [aaaa, dddd, cccc]// cccc在链表中的位置2// 链表中索引2处的元素cccc &#125;&#125; 2.循环链表： 将单链表的尾节点next指针改为引用单链表header节点，形成循环链表。 从链表的任一节点出发均可找到表中其他所有节点。 只要保证tail.next=header即可 3.双向链表： 每个节点保留两个引用prev和next，分别指向上一个和下一个节点。此时链表既可以向前也可以向后遍历 更方便地插入、删除数据元素。克服了单链表上指针单向性的缺点 代码模拟： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214public class DuLinkList&lt;T&gt; &#123; private class Node &#123; private T data;// 保存节点数据 private Node pre; private Node next; public Node(T data, Node pre, Node next) &#123; this.data = data; this.pre = pre; this.next = next; &#125; &#125; private Node header; private Node tail; private int size; // 创建空链表 public DuLinkList() &#123; header = null; tail = null; &#125; // 以指定元素创建链表，只有一个元素 public DuLinkList(T data) &#123; header = new Node(data, null, null); tail = header; size++; &#125; // 返回链表的长度 public int length() &#123; return size; &#125; // 获取索引为index处的元素 public T get(int index) &#123; return getNodeByIndex(index).data; &#125; private Node getNodeByIndex(int index) &#123; if (index &lt; 0 || index &gt; size - 1) &#123; throw new IndexOutOfBoundsException(\"双链表索引越界\"); &#125; if (index &lt;= size / 2) &#123; Node current = header; for (int i=0; i&lt;=size/2 &amp;&amp; current!=null;i++,current=current.next) &#123; if (i == index) &#123; return current; &#125; &#125; &#125; else &#123; Node current = tail; for (int i=size-1;i&gt;size/2 &amp;&amp; current!=null;i++, current=current.pre) &#123; if (i==index) &#123; return current; &#125; &#125; &#125; return null; &#125; // 查找指定元素的索引 public int locate(T data) &#123; // 这里从头开始搜索 Node current = header; for (int i=0; i&lt;size &amp;&amp; current!=null;i++,current=current.next) &#123; if (current.data.equals(data)) &#123; return i; &#125; &#125; return -1; &#125; // 向线性链表的指定位置插入一个元素 public void insert(T data, int index) &#123; if (index &lt; 0 || index &gt; size) &#123; throw new IndexOutOfBoundsException(\"双链表索引越界\"); &#125; if (header == null) &#123; add(data); &#125; else &#123; if (index == 0) &#123; addAtHeader(data); &#125; else &#123; Node pre = getNodeByIndex(index - 1); Node next = pre.next; Node newNode = new Node(data, pre, next); pre.next = newNode; next.pre = newNode; size++; &#125; &#125; &#125; // 头插法 private void addAtHeader(T data) &#123; header = new Node(data, null, header); if (tail == null) &#123; tail = header; &#125; size++; &#125; // 尾插法 private void add(T data) &#123; if (header == null) &#123; header = new Node(data, null, null); tail = header; &#125; else &#123; // 他将作为尾节点，next指向null Node newNode = new Node(data, tail, null); tail.next = newNode; tail = newNode; &#125; size++; &#125; // 删除链表指定索引处的元素 public T delete(int index) &#123; if (index &lt; 0 || index &gt; size - 1) &#123; throw new IndexOutOfBoundsException(\"双链表索引越界\"); &#125; Node del = null; if (index == 0) &#123; del = header; header = header.next; // 释放新header节点的pre引用 header.pre = null; &#125; else &#123; Node pre = getNodeByIndex(index - 1); del = pre.next; pre.next = del.next; // 被删除节点的下一个节点的pre指向pre节点 if (del.next != null) &#123; del.next.pre = pre; &#125; &#125; size--; return del.data; &#125; // 删除链表最后一个元素 public T remove() &#123; return delete(size - 1); &#125; // 判断链表是否为空链表 public boolean isEmpty() &#123; return size == 0; &#125; // 清空线性表 public void clear() &#123; header = null; tail = null; size = 0; &#125; public String toString() &#123; if (isEmpty()) &#123; return \"[]\"; &#125; else &#123; StringBuffer sb = new StringBuffer(\"[\"); for (Node current=header;current!=null;current=current.next) &#123; sb.append(current.data.toString() + \", \"); &#125; int len = sb.length(); return sb.delete(len - 2, len).append(\"]\").toString(); &#125; &#125; public String reverseToString() &#123; if (isEmpty()) &#123; return \"[]\"; &#125; else &#123; StringBuffer sb = new StringBuffer(\"[\"); for (Node current=tail;current!=null; current=current.pre) &#123; sb.append(current.data.toString() + \", \"); &#125; int len = sb.length(); return sb.delete(len - 2, len).append(\"]\").toString(); &#125; &#125; public static void main(String[] args) &#123; DuLinkList&lt;String&gt; list = new DuLinkList&lt;String&gt;(); list.insert(\"aaaa\", 0); list.add(\"bbbb\"); list.insert(\"cccc\", 0); list.insert(\"dddd\", 1); System.out.println(list); list.delete(2); System.out.println(list); System.out.println(list.reverseToString()); System.out.println(\"cccc在表中位置：\" + list.locate(\"cccc\")); System.out.println(\"链表中索引1处的元素：\" + list.get(1)); list.remove(); System.out.println(\"调用remove方法后的链表：\" + list); list.delete(0); System.out.println(\"调用delete（0）后的链表：\" + list); &#125;&#125; //输出： [cccc, dddd, aaaa, bbbb]// [cccc, dddd, bbbb]// [bbbb, dddd, cccc]// cccc在表中位置：0// 链表中索引1处的元素：dddd// 调用remove方法后的链表：[cccc, dddd]// 调用delete（0）后的链表：[dddd]","categories":[],"tags":[{"name":"博客重构","slug":"博客重构","permalink":"http://yoursite.com/tags/博客重构/"},{"name":"简单数据结构","slug":"简单数据结构","permalink":"http://yoursite.com/tags/简单数据结构/"}]},{"title":"【深入浅出MySQL】","slug":"【深入浅出MySQL】","date":"2017-03-12T09:21:31.000Z","updated":"2017-05-23T09:43:56.000Z","comments":true,"path":"2017/03/12/【深入浅出MySQL】/","link":"","permalink":"http://yoursite.com/2017/03/12/【深入浅出MySQL】/","excerpt":"SQL基础SQL分类1.DDL(Data Definition Languages)：数据库定义语言","text":"SQL基础SQL分类1.DDL(Data Definition Languages)：数据库定义语言 123456789101112131415161718192021222324251.创建数据库：create database test1;//不能创建已有的数据库 2.查看数据库：use test1; 3.查看所有表：show tables; 4.删除数据库：drop database test1; 5.创建表：create table emp(ename varchar(10),hiredate date,sal decimal(10,2),deptno int(2)); 6.查看表的定义：desc emp; 7.删除表：drop table emp; 8.修改表： - 修改字段定义：alter table emp modify ename varchar(20); - 增加表字段：alter table emp add column age int(3); - 删除表字段：alter table emp drop column age; - 字段改名：alter table emp change age age1 int(4); //change可以修改列名称，modify不能，change后面需要写两次列名 2.DML(Data Manipulation Language)数据操纵语句1234567891011121314151617181920212223242526272829303132- 插入记录：insert into emp(ename,hiredate,sal,deptno) values('zzx1','2000-01-01','2000',1); - 或不指定名称：insert into emp values('lisa','2003-02-01','3000',2); - 只对表中的ename和sal字段插入值：insert into emp (ename,sal) values('dony',1000); - 更新记录：update emp set sal=4000 where ename='lisa'; - 删除记录：delete from emp where ename = 'dony'; - 查询记录：select * from emp; - 查询不重复的记录：select distinct deptno from emp; - 条件查询：select * from emp where deptno=1 and sal&lt;3000; - 把emp表中的记录按照工资从低到高进行排序：select * from emp order by sal;(相同则无序) - 对于deptno相同的前两条记录，按照工资由高到低排序：select * from emp order by deptno,sal desc; - 对于排序后的记录，显示从第二条记录开始的3条记录：select * from emp order by sal limit 1,3; MySQL支持的数据类型1.数值类型12345678910111213141516171819202122232425- 整数类型： TINYINT，1字节 SMALLINT,2字节 MEDIUMINT，3字节 INT、INTEGER，4字节 BIGINT，8字节//对于整型数据，在类型名称后面的小括号内指定显示宽度，默认int（11），配合zerofill，//位数不够的空间用字符“0”填满 - 浮点数类型： FLOAT，4字节 DOUBLE，8字节 - 定点数类型 DEC（M,D） DECIMAL（M,D）//浮点数和定点数都可以用类型名称后加（M，D）（精度，标度）（一共显示多少位数字，小数点后面多少位）//浮点数如果不写精度和标度，则会按照精度值显示，如果有精度和标度，则会自动四舍五入后的结果插入，//系统不会报错,定点数如果不写精度和标度，则按照默认decimal（10,0），如果数据超越了精度和标度，//系统会报错 - 位类型 BIT（M）//位类型用SELECT命令将不会看到结果，可以用bin()(显示为二进制格式)，//或hex()(显示为十六进制格式)函数进行读取 2.日期时间类型123456789- DATE类型：4字节，表示年月日 - DATETIME类型：8字节，表示年月日时分秒 - TIMESTAMP类型：4字节，返回显示为YYYY-MM-DD HH:MM-DD:SS格式，显示宽度固定为19个字符 - TIME类型：3字节，只用来表示时分秒 - YEAR类型：1字节，只表示年份 3.字符串类型 CHAR和VARCHAR类型 1234567891.CHAR列的长度固定为创建表时声明的长度，0~2552.VARCHAR列中的值为可变长字符串，0~2553.在检索时，CHAR列删除了尾部的空格，VARCHAR保留这些空格 CREATE TABLE VC(v VARCHAR(4),c CHAR(4));INSERT INTO VC VALUES('ab ','ab ');select length(v),length(c) from vc; //结果，length(v):4,length(c):2 BINARY和VARBINARY类型 123451.类似上面 2.都包含二进制字符串而不包含非二进制字符串 3.对于一个BINARY(3)列，当插入“a”变为“a\\0\\0”(填充零字节0x00) ENUM类型 1234567891.忽略大小写，存储时都转换成大写 2.对于插入不在ENUM指定范围内的值时，没有返回警告，而是插入第一个值 create table t(gender enum('M','F'));INSERT INTO t VALUES('M'),('l'),('f'),(NULL);select * from t; //结果：M M F NULL SET类型 12345678910111.类似ENUM 2.SET类型一次可以选取多个成员，而ENUM只能选一个 create table t (col set('a','b','c','d'));insert int t values('a,b'),('a,d,a'),('a,b'),('a,c'),('a');select * from t; //结果 a,b a,d a,b a,c a 3.对于('a,d,a')这样包含重复成员的集合将只取一次，写入后的结果为\"a,d\" MySQL中的运算符1.算术运算符12345671.select 0.1+0.3333,0.1-0.3333,0.1*0.3333,1/2,1%2; //结果0.1+0.3333 0.1-0.3333 0.1*0.3333 1/2 1%2 0.4333 -0.2333 0.03333 0.5000 1 2.使用MOD(a,b)函数与a%b效果一样 2.比较运算符1234567891011121314151.比较结果为真，返回1，为假，返回0，比较结果不确定，返回NULL 2.NULL不能用于\"=\"、\"&lt;&gt;\"(和!=等价) 3.NULl可以用于\"&lt;=&gt;\"(类似\"=\")比较 4.\"BETWEEN\"运算符格式\"a BETWEEN min AND max\" 等价于 （a&gt;=min and a&lt;=max） 5.\"IN\"运算符格式\"a IN (value1,value2,...)\"当a的值存在于列表中时，则整个表达是返回1，否则返回0 6.\"IS NULL\"格式 \"a IS NULL\",a为NULL，返回1，否则返回0，\"IS NOT NULL\"类似 7.\"LIKE\"运算符格式\"a LIKE %123%\",a中含有字符串\"123\"时，返回1，否则返回0 8.\"REGEXP\"运算符格式\"str REGEXP str_pat\",当str字符串部分含有str_pat字符串时，返回1，否则返回0 3.逻辑运算符12345671.NOT或! 表示逻辑非，但NOT NULL 返回 NULL 2.AND或&amp;&amp;,操作数中有任何一个为NULL则返回NULL 3.OR或|| ,当一个操作数为NULL，另一个操作数非0，则返回1，否则返回NULL。两个都为NULL，返回NULL 4.XOR表示逻辑异或，任意一个操作数为NULL，返回NULL，如果两个操作数真假相异，返回1，否则返回0 4.位运算符略 5.运算符的优先级略 常用函数字符串函数12345678910111213141516171819202122232425262728293031321.CONCAT(S1,S2,...Sn)函数： 把传入的参数连接成为一个字符串任何字符串与NULL进行连接的结果都是NULL 2.INSERT(str,x,y,instr)函数： 将字符串str从第x位置开始，y个字符长的子串替换为字符串instr(第一个位置记x为1) 3.LOWER(str)和UPPER(str)函数： 把字符串全部转换为大写或者小写 4.LEFT(str,x)和RIGHT(str,x): 分别返回字符串最左边x个字符和最右边x个字符，如果第二个参数为NULL，不返回任何字符串 5.LPAD(str,n,pad)和RPAD(str,n,pad)函数： 用字符串pad对str最左边或最右边进行填充，直到总长度为n 6.LTRIM(str)和RTRIM(str)函数： 去掉字符串str左侧和右侧空格 7.REPEAT(str,x): 返回str重复x次的结果 8.REPLACE(str,a,b)函数： 用字符串b替换str中所有出现的字符串a 9.STRCMP(s1,s2)函数： 比较字符串s1和s2的ASCII码值的大小，相等返回0，s1大，返回1，s2大，返回-1，s2大，返回-1 10.TRIM(str)函数： 去掉目标字符串的开头和结尾的空格 11.SUBSTRING(str,x,y)函数： 返回str中第x位置起y个字符长度的子串(索引从1开始) 数值函数12345678910111213141.ABS(x)函数：返回x的绝对值 2.CEIL(x)函数：返回大于x的最小整数 3.FLOOR(x)函数：返回小于x的最大整数 4.MOD(x,y)函数：返回x/y的摸，和x%y的结果相同，任何一个数为NULL结果都为NULL 5.RAND()函数：返回0~1内的随机值, 产生0~100内的任意随机整数：select ceil(100*rand()) 6.ROUND(x,y)函数：返回参数x的四舍五入的有y为小数的值 7.TRUNCATE(x,y)函数：返回数字x截断为y为小数的结果，不进行四舍五入，类似ROUND(x,y) 日期和时间函数123456789101112131415161718192021221.CURDATE()函数：返回当前日期，只包含年月日 2.CURTIME()函数：返回当前时间，只包含时分秒 3.NOW()函数：返回当前的日期和时间，年月日时分秒全都包含 4.UNIX_TIMESTAMP(date)函数：返回日期date的UNIX时间戳(日期的12位数字表示) 5.FROM_UNIXTIME(unixtime)函数：返回UNIXTIME时间戳的日期值，和上面互为逆操作 6.WEEK(DATE)和YEAR(DATE)函数：前者返回所给日期是一年中的第几周，后者返回所给的日期是哪一年 7.HOUR(time)和MINUTE(time)函数：返回所给时间的小时部分，分钟部分 8.MONTHNAME(date)函数：返回date的英文月份名称 9.DATE_FORMAT(date,fmt)函数：按字符串fmt格式化日期date值，fmt表自行去查 10.DATE_ADD(date,INTERVAL expr type)函数：返回与所给日期date相差INTERVAL时间段的日期， 其中INTERVAL是间隔类型关键字，expr可以是一个表达式（匹配间隔类型表），type是间隔类型（自行查看） 11.DATEDIFF(date1,date2)函数：计算两个日期之间相差的天数 流程函数12345678910111213141.IF(value,t,f)函数： 月薪在2000以上，用“high”表示，2000以下，用“low”表示: select if(salary&gt;2000, 'high','low') from salary; 2.IFNULL(value1,value2)函数： 一般用来替换NULL值，value1代表字段: select ifnull(salary,0)from salary; 3.CASE WHEN[value1] THEN[result1]...ELSE[default]END函数： select case when salary&lt;=2000 then 'low' else 'high' end from salary; 4.CASE [expr] WHEN [value1] THEN[result1]...ELSE[default]END函数： 分多个档次: select case salary when 1000 then 'low' when 2000 then 'mid' else 'high' end from salary; 其他常用函数123456789101112131.DATABASE()函数：返回当前数据库名 2.VERSION()函数：返回当前数据库版本 3.USER()函数：返回当前登录用户名 4.INET_ATON(IP)函数：返回IP地址的网络字节序表示 5.INET_NTOA(num)函数：返回网络字节序代表的IP地址 6.PASSWORD(str)函数：返回字符串str的加密版本，一个41位长的字符串 7.MD5(str)函数：返回字符串str的MD5值，常用来对应用中的数据进行加密 存储过程和函数存储过程和函数简介 存储过程和函数是经过编译并存储在数据库中的一段SQL语句的集合 调用它们可以减少数据在数据库和应用服务器之间的传输，提高数据处理效率 函数必须有返回值，存储过程不必须有返回值 存储过程的参数可以是IN、OUT、INOUT类型，函数的参数只能是IN类型 存储过程和函数的相关操作0.在对存储过程和函数进行操作时，需要确定用户是否具有权限123创建需要：CREATE ROUTINE权限修改删除：ALTER ROUTINE权限执行需要：EXECUTE权限 1.创建、修改存储过程或者函数 MySQL的存储过程和函数中允许包含DDL语句，允许执行提交（Commit），或者回滚（Rollback） 存储过程和函数中可以调用其他的过程或者函数 下面创建了一个新的过程film_in_stock： 12345678910111213141516171819202122232425DELIMITER $$CREATE PROCEDURE film_in_stock(IN p_film_id INT,IN p_store_id INT,OUT p_film_count INT)READS SQL DATA //表示只包含读sql的语句BEGIN SELECT inventory_id FROM inventory WHERE film_id = p_film_id AND store_id = p_store_id AND inventory_in_stock(inventory_id); SELECT FOUND_ROWS() INTO p_film_count;END $$DELIMITER; 1.使用$$符号，在过程和函数中的分号就不会被MySQL解释成语句的结束而提示错误 2.存储过程或函数创建完毕，通过DELIMITER;命令再将结束符改回分号 3.手工执行：select inventory_id from inventory where film_id=2 and store_id = 2 and inventory_in_stock(inventory_id); 结果为：inventory_id 10 11 4.调用过程等同于手工执行的代码：CALL film_in_stock(2,2,@a); 5.select @a:显示：@a 2（2条结果，） 2.删除存储过程或者函数1DROP PROCEDURE film_in_stock; 3.查看存储过程或者函数12345678- 查看存储过程或者函数的状态： show procedure status like 'film_in_stock'\\G - 查看存储过程或者函数的定义： show create procedure film_in_stock \\G - 详细： select * from routines where ROUTINE_NAME = 'film_in_stock' \\G 4.变量的使用1234567891011- 变量的定义 1.通过DECLARE定义一个局部变量，作用范围只能在BEGIN...END块中 2.定义必须写在复合语句的开头，并且在任何其他语句的前面 3.可以使用DEFAULT赋默认值 4.例定义一个DATE类型变量：DECLARE last_month_start DATE; - 变量的赋值 1.直接使用SET赋值：SET var_name = expr [,var_name = expr]...,可以赋常量或者表达式 2.通过查询将结果赋值给变量：SELECT col_name[,...]INTO var_name[,...] from tavle_expr(var_name是被赋值的变量) 5.定义条件和处理1234567891011121314151617- 定义：DECLARE condition_name CONDITION FOR condition_value - 处理：DECLARE handler_type HANDLER FOR condition_value[,...] sp_statement 1.handler_type,支持CONTINUE和EXIT 2.condition_value，可以是通过DECLARE定义的condition_name,可以是SQLSTATE的值， 或mysql-error-code或SQLWARNING，NOT FOUND，SQLEXCEPTION - 例子： 1.捕获mysql-error-code DECLARE CONTINUE HANDLER FOR 1062 SET @x2 =1; 2.事先定义condition_name DECLARE DuplicateKey CONDITION FOR SQLSTATE '23000'; DECLARE CONTINUE HANDLER FOR DuplicateKey SET @x2 = 1; 3.捕获SQLEXCEPTION DECLARE CONTINUE HANDLER FOR SQLEXCEPTION SET @x2 = 1； 6.光标的使用 使用光标对结果集进行循环处理 声明光标：DECLARE cursor_name CURSOR FOR select_statement OPEN光标：OPEN cursor_name FETCH光标：FETCH cursor_name INTO var_name [,var_name]… CLOSE光标：CLOSE cursor_name 例：对payment表按照staff_id值的不同累加amount的值，结束条件：捕获NOT FOUNT 12345678910111213141516171819202122232425delimiter $$CREATE PROCEDURE payment_stat()BEGIN DECLARE i_staff_id int; DECLARE d_amount decimal(5,2); DECLARE cur_payment cursor for select staff_id,amount from payment; DECLARE EXIT HANDLER FOR NOT FOUND CLOSE cur_payment; set @x1 = 0; set @x2 = 0; OPEN cur_payment; REPEAT FETCH cur_payment INTO i_staff_id,d_amount; if i_staff_id = 2 then set @x1 = @x1 + d_amount; else set @x2 = @x2 + d_amount; end if; UNTIL 0 END REPEAT; CLOSE cur_payment;END;$$ 变量和条件必须在最前面声明，然后才能是光标的声明，最后才可以是处理程序的声明 7.流程控制 IF语句 1234IF search_condition THEN statement_list [ELSEIF search_condition THEN statement_list]... [ELSE statement_list]END IF CASE语句 1234567891011CASE case_value WHEN when_value THEN statement_list [WHEN when_value THEN statement_list]... [ELSE statement_list]END CASE//或者：CASE WHEN search_condition THEN statement_list [WHEN search_condition THEN statement_list]... [ELSE statement_list]END CASE LOOP语句 123[begin_label:]LOOP statement_list //如果不在这里增加退出循环的语句，会实现死循环END LOOP [end_lable] LEAVE语句 1234567891011121314151617//下面是使用LOOP和LEAVE的例子，循环100次向actor表插入记录，然后退出循环CREATE PROCEDURE actor_insert()BEGIN set @x = 0; ins:LOOP set @x = @x + 1; IF @x = 100 then leave ins; END IF; INSERT INTO actor(first_name,last_name) VALUES ('Test','201'); END LOOP ins;END;$$call actor_insert();select count(*) from actor where first_name='Test'; //结果显示：count(*) 100 ITERATE语句 12345678910111213141516171819//必须用在循环中，跳过当前循环剩下的语句，直接进入下一轮循环//例子：当@x变量是偶数的时候，不再执行循环中剩下的语句CREATE PROCEDURE actor_insert()BEGIN set @x = 0; ins: LOOP set @x=@x+1; IF @x = 10 then leave ins; ELSEIF mod(@x,2) = 0 then ITERATE ins; END IF; INSERT INTO actor(actor_id,first_name,last_name)VALUES(@x+200,'Test',@x); END LOOP ins;END;$$ call actor_insert();select actor_id,first_name,last_name from actor where first_name = 'Test'; REPEAT语句 12345//有条件的循环控制语句，当满足条件的时候退出循环[begin_label:]REPEAT statement_listUNTIL search_conditionEND REPEAT[end_label] WHILE语句 123456//有条件的循环控制语句，当满足条件是执行循环内容[begin_label:]WHILE search_condition DO statement_listEND WHILE[end_label] 注：WHILE在首次循环执行之前就判断条件，REPEAT是首次执行循环之后才判断条件，循环至少执行一次 8.事件调度器 可以将数据库按照自定义时间周期触发某种操作 下面通过一个完整的实例来熟悉事件调度器的使用： 123456789101112131415161718192021222324252627281.创建测试表test：create table test(id1 vachar(10),create_time datetime); 2.创建事件调度器，每隔5秒向test表插入一条记录 CREATE EVENT test_event_1 ON SCHEDULE EVERY 5 SECOND DO INSERT INTO test.test(id1,create_time) VALUES('test',now()) 3.查看调度器状态：show events \\G; 4.隔几秒后，查看test表，发现没有数据插入：select * from test; 5.查看事件调度器状态，发现默认是关闭的：show variables like '%scheduler%'; 6.打开调度器：SET GLOBAL event_scheduler = 1; show variables like '%scheduler%'; 7.查看后台进程，发现新增一个：show processlist \\G; 8.为防止表变大，创建新调度器，每隔1分钟清空一次test表： CREATE EVENT trunc_test ON SCHEDULE every 1 MINUTE DO TRUNCATE TABLE test; 9.禁用和删除 禁用event：alter event test_event_1 disable; 删除event：drop event test_event_1; 存储引擎和索引MySQL存储引擎概述 用户可以根据应用的需要选择如何存储和索引数据，是否使用事务等 InnoDB和BDB存储引擎提供事务安全表，其他存储引擎都是非事务安全表 MySQL5.5之后默认引擎为InnoDB 1234561.查看当前的默认存储引擎： show variables like 'table_type'; 2.查询当前数据库支持的存储引擎： show ENGINES \\G 或 show variables like 'have%'; 设置存储引擎 1234在创建新表的时候，可以通过增加ENGINE关键字设置新建表的存储引擎也可以使用ALTER TABLE语句，将一个已经存在的表修改成其他的存储引擎： alter table ai engine = innodb; show create table ai \\G 各种存储引擎的特性1.MyISAM1231.MySQL5.5之前的默认存储引擎，不支持事务，不支持外键，访问速度快 2.默认使用静态表，插入记录保留前面的空格，但后面的空格被去掉 2.InnoDB12345678910111213141516171819202122232425262728293031- 提供了具有提交、回滚和崩溃恢复能力的事务安全，写的处理效率差一些 - 自动增长列： 1.可以手工插入，但插入的值如果是空或者0，则实际插入的将是自动增长后的值 2.可以使用ALTER TABLE *** AUTO_INCREMENT = n;强制设置自动增长列的初始值（默认1开始）， 强制设置的值保留在内存中，重启数据库要重新设置 3.可以使用LAST_INSERT_ID()查询当前线程最后插入记录使用的值：select LAST_INSERT_ID(); - 外键约束： 1.只有InnoDB引擎支持外键 2.主键声明：PRIMARY KEY(主键名) 3.外键声明：(在子表，带外键的表中)CONSTRAINT '自定义一个名称' FOREIGN KEY(外键名) REFERENCES 父表名(父表主键) ON DELETE RESTRICT ON UPDATE CASCADE可以指定在删除、 更新父表时，对字表进行相应操作： 1.RESTRICT和NO ACTION:限制在子表有关联记录的情况下父表不能更新 2.CASCADE:父表在更新或者删除时，更新或删除子表对应记录 3.SET NULL：父表在更新或删除时，子表的对应字段被SET NULL 4.当某个表被其他表创建了外键参照，那么该表的对应索引或者主键禁止被删除 5.在导入多个表的数据时，如果需要忽略导入顺序，可以暂时关闭外键检查来加快处理速度 关闭：SET FOREIGN_KEY_CHECKS=0; 改回：SET FOREIGN_KEY_CHECKS=1; 6.对应InnoDB类型表，外键信息可以使用show create table 或 show table status命令 - 存储方式:略 索引概述 所有Mysql列类型都可以被索引，对相关列使用索引是提高SELECT操作性能的最佳途径 MyISAM和InnoDB存储引擎的表默认创建的都是BTREE索引 MySQL不支持函数索引，支持前缀索引（对索引字段的前N个字符创建索引） 索引在创建表的时候可以同时创建，也可以随时增加新的索引，创建新索引的语法： 1234CREATE [UNIQUE|FULLTEXT|SPATIAL]INDEX index_name ON tb_name(index_col_name...) 例：要为city表创建10个字节的前缀索引： create index cityname on city(city(10)); 删除索引： 1drop index cityname on city BTREE索引与HASH索引 MEMORY引擎可以选择使用BTREE索引或HASH索引 对于HASH索引： 121.只使用=或&lt;=&gt;操作符的等式比较2.只能使用整个关键字来搜索一行 对于BTREE索引： 1可以使用&gt;、 &lt;、 &gt;=、 &lt;=、 BETWEEN、 !=、 &lt;&gt;、 LIKE'pattern'(pattern不以通配符开始) 下列范围查询适用于BTREE索引和HASH索引： 1select * from t1 where key_col = 1 or key_col in (15,18,20) 下列范围查询只使用于BTREE索引： 123select * from t1 where key_col &gt; 1 and key_col &lt; 10; select * from t1 where key_col LIKE 'ab%' or key_col BETWEEN 'kisa' AND 'simon'; 如果不使用索引，MySQL必须从第一条记录开始然后读完整个表知道找出相关的行，表越大，花费的时间越多 SQL优化优化SQL语句的一般步骤1.通过show [session|global]status命令，默认session(当前连接)，global(自数据库上次启动至今)的统计结果1234567891011121314151617181920212223240.例：show status like 'Com_%'; 1.Com_XXX表示每个XXX语句执行的次数 Com_select:执行SELECT操作的次数，一次查询只累加1次 Com_insert:执行INSERT操作的次数，对于批量插入的INSERT操作，只累加1次 Com_update:执行UPDATE操作的次数 Com_delete:执行DELETE操作的次数 2.上述参数对所有存储引擎的表操作都会进行累计，下面参数只针对InnoDB引擎 Innodb_rows_read:SELECT查询返回的行数 Innodb_rows_inserted:执行INSERT操作插入的行数 Innodb_rows_updated:执行UPDATE操作更新的行数 Innodb_rows_deleted:执行DELETE操作删除的行数 3.通过上述参数，可以了解各种类型SQL大致执行比例，是以插入更新为主还是以查询操作为主 4.对于事务型应用： Com_commit 事务提交情况 Com_rollback 事务回滚情况 5.其他基本情况 Connections:试图连接MySQL服务器的次数 Uptime：服务器工作时间 Slow_queries:慢查询次数 2.定位执行效率较低的SQL语句123- 通过慢查询日志定位那些执行效率较低的SQL语句（日志管理） - 使用show processlist命令查看当前MySQL在进行的线程 3.通过EXPLAIN分析低效SQL的执行计划0.可以通过EXPLAIN或者DESC命令获取MySQL如何执行SELECT语句的信息 1.例：统计某个email账号为租电影所支付的总金额，需要关联客户表customer和付款表payment，并对付款金额amount字段做求和操作12explain select sum(amount) from customer a,payment b where 1=1 and a.customer_id = b.customer_id and email = 'JANE.BENNETT@sakilacustomer.org'\\G 2.上例显示结果列： 123456789101112131415161718192021222324252627282930313233- select_type:表示SELECT类型，有SIMPLE(简单表，不使用表连接或子查询)、PRIMARY(主查询，外层的查询)、 UNION(UNION中的第二个或后面的查询语句)、SUBQUERY(子查询的第一个SELECT) - table：输出结果集的表 - type：表示MySQL在表中找到所需行的方式(访问类型)，越往下，性能越好 1.type=ALL,全表扫描，遍历全表找到匹配的内容行 2.type=index，索引全扫描，遍历整个索引来查询匹配的行 3.type=range，索引范围扫描，常用&lt;，&lt;=，&gt;，&gt;=，between等操作符 4.type=ref，使用非唯一索引或唯一索引前缀扫描， 5.type=eq_ref,同上，但使用唯一索引(多表连接使用primary key或unique index) 6.type=const/system,单表最多有一个匹配行，这个匹配行中的其他列的值可以被优化器在当前查询中 当作常量处理，例： explain select * from (select * from customer where email='') a \\G 7.type=null,不用访问表或者索引，例： explain select 1 from dual where 1 /G - possible_keys:查询时可能使用的索引 - key:实际使用的索引 - key_len:使用到索引字段的长度 - rows：扫描行的数量 - Extra:执行情况 3.使用explain extended命令，之后再用show warnings可以看到SQL真正被执行前优化亲做了哪些改写：比如去除1=1恒等条件 4.通过show profile分析SQL1234567891.select @@have_profiling;命令，查看是否支持profile 2.默认profiling是关闭的，select @@profiling;,结果为0，set profiling=1; 在Session级别开启profiling 3.在innodb引擎执行COUNT(*)查询：select count(*) from payment;- 通过show profiles；可以看到SQL的Query ID为4- 通过show profile for query 4；能够看到执行过程中线程每个状态的消耗时间- InnoDB执行COUNT(*)比MyISAM慢，因为没有元数据缓存 5.确定问题并优化123确定对客户表customer的全表扫描效率不理想，对客户表customer的email字段创建索引： create index idx_email on customer(email)； 索引问题1.索引的存储分类1234567- B-Tree索引：大部分引擎都支持，适用于范围查找 - HASH索引：只有Memory/Heap引擎支持，适用于Key-Value查询，不适用范围查找 - R-Tree索引：主要用于地理空间数据类型 - Full-text:全文索引 2.使用索引 例，重命名rental表上的索引rental_date为idx_rental_date 123alter table rental drop index rental_date; alter table rental add index idx_rental_date (rental_date,inventory_id,customer_id); 能够使用索引的典型场景 123456789101112131415161718192021222324252627282930313233343536373839404142434445461.匹配全值： 上例通过指定出租日期rental_date,库存编号inventory_id,客户编号customer_id的组合条件进行查询 explain select * from rental where rental_date='2005-05-25 17:22:10' and inventory_id =373 and customer_id=343\\G 输出结果为type为const，表示常量，key为idx_rental_date,表示优化器选择索引idx_rental_date进行扫描 2.匹配值的范围查询： explain select * from rental where customer_id&gt;=373 and customer_id&lt;400\\G 输出结果：type为range，说明优化器选择范围查询，key为idx_fk_customer_id 3.匹配最左前缀： alter table payment add index idx_payment_date(payment_date,amount,last_update); explain select * from payment where payment_date = '2006-02-14 15:16:03' and last_update='2006-02-15 22:12:32'\\G 但如果选择复合索引idx_payment_date的第二列和第三列amount,last_update执行计划不会利用 索引idx_payment_date explain select * from payment where amount = 3.98 and last_update ='2006-02-15 22:12:32'\\G 4.仅仅对索引进行查询： explain select last_update from payment where payment_date='2006-02-14 15:16:03' and amount = 3.98\\G 输出结果，Extra部分变成了Using index，只访问必须访问的数据，不需要通过索引回表 5.匹配列前缀（只使用索引的第一列）： create index idx_title_desc_part on film_text(title(10),description(20)); explain select title from film_text where title like 'AFRICAN%'\\G 输出结果：Extra为Using where 表示优化器需要通过索引回表查询数据 6.能够实现索引匹配部分精确而其他部分进行范围匹配： explain select inventory_id from rental where rental_date='2006-02-14 15:16:03' and customer_id&gt;=300 and customer_id &lt;= 400\\G 输出结果：type：range，key：idx_rental_date,Extra:Using indx 7.如果列名是索引，使用column_name is null就会使用索引： explain select * from payment where rental_id is null\\G 存在索引但不能使用的典型场景 12345678910111213141516171819201.以%开头的LIKE查询不能利用B-Tree索引 explain select * from actor where last_name like '%NI%'\\G 2.数据类型出现隐式转换的时候也不会使用索引 explain select * from actor where last_name = 1\\G 这样会全表扫描，应改为 explain select * from actor where last_name='1'\\G 3.复合索引的情况下，查询条件不包含索引列最左边部分，不满足最左原则，不会使用复合索引 explain select * from payment where amount = 3.98 and last_update= '2006-02-15 22:12:32'\\G 4.如果MySQL估计使用索引比全表扫描更慢，则不使用索引 update film_text set title = concat('S',title); explain select * from film_text where title like 'S%'\\G 更换查询的值为一个选择率更高的值，发现优化器更倾向于选择索引扫描 explain select * from film_text where title like 'SW%'\\G 5.用or分割开的条件，如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到 explain select * from payment where customer_id = 203 or amount = 3.96\\G 常用SQL的优化1.大批量插入数据12345678910111213141516171.对于MyISAM存储引擎表，通过- ALTER TABLE tb1_name DISABLE KEYS; loading the data... - ALTER TABLE tb1_name ENABLE KEYS; 打开或关闭MyISAM表非唯一索引的更新 在非空的MyISAM表中导入大量数据，通过设置这两个命令，提高导入效率 在空MyISAM表中导入大量数据，默认是先导入再创建索引 2.对于InnoDB表，是按照主键的顺序保存的，- 将导入的数据按照主键的顺序排列，可以提高导入效率 - 导入数据前执行SET UNIQUE_CHECKS=0,关闭唯一性校验，导入结束后执行SET UNIQUE_CHECKS=1, 恢复唯一性校验，可以提高导入效率 - 如果应用使用自动提交方式，在导入前执行SET AUTOCOMMIT=0,关闭自动提交，导入之后再开启， 可以提高导入效率 2.优化INSERT语句123如果同时从同一客户端插入很多行，应尽量使用多个值表的INSERT语句，比单个INSERT语句块： 例：insert into test values(1,2),(1,3),(1,4)... 3.优化ORDER BY语句123456789101.MySQL有两种排序方式， 第一种，通过有序索引顺序扫描直接返回有序数据，在explain分析显示为Using Index，不需要额外排序 第二种，对返回数据进行排序，Filesort排序 2.优化目标：- 尽量减少额外的排序，通过索引直接返回有序数据 - WHERE条件和ORDER BY使用相同的索引，ORDER BY的顺序和索引顺序相同，ORDER BY 的字段 都是升序或降序（否则出现Filesort排序）","categories":[],"tags":[{"name":"博客重构","slug":"博客重构","permalink":"http://yoursite.com/tags/博客重构/"},{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/tags/读书笔记/"}]},{"title":"【Java高并发程序设计】","slug":"【Java高并发程序设计】","date":"2017-03-12T07:09:03.000Z","updated":"2018-03-04T03:02:21.000Z","comments":true,"path":"2017/03/12/【Java高并发程序设计】/","link":"","permalink":"http://yoursite.com/2017/03/12/【Java高并发程序设计】/","excerpt":"java并行基础走进并行世界1.同步（Synchronous）和异步（Asynchronous）123451.同步和异步通常用来形容一次方法调用2.同步方法调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为。3.异步方法调用一旦开始，方法调用就会立即返回，调用者可以继续后续的操作。4.如果异步调用需要返回结果，当异步调用真实完成时，则会通知调用者。5.同步可比作去商场购物，异步比作网购，网购支付完成在等送货上门时，可以做任何事情。","text":"java并行基础走进并行世界1.同步（Synchronous）和异步（Asynchronous）123451.同步和异步通常用来形容一次方法调用2.同步方法调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为。3.异步方法调用一旦开始，方法调用就会立即返回，调用者可以继续后续的操作。4.如果异步调用需要返回结果，当异步调用真实完成时，则会通知调用者。5.同步可比作去商场购物，异步比作网购，网购支付完成在等送货上门时，可以做任何事情。 2.并发（Concurrency）和并行（Parallelism）121.并发偏重于多个任务交替执行，而多个任务之间有可能还是串行的。2.并行是真正意义上的“同时执行”。 3.临界区1用来表示一种公共资源或者共享数据，可以被多个线程使用，但每一次，只能有一个线程使用它。 4.阻塞（Blocking）和非阻塞（Non-Blocking）1234561.形容多线程建的相互影响，如果一个线程占用了临界区资源，其他所有需要这个资源的线程就必须在这个临界区中进行等待 2.等待会导致线程挂起，这种情况就是阻塞。 3.如果占用资源的线程一直不愿意释放资源，其他所有阻塞在这个临界区上的线程都不能工作 5.死锁（Deadlock）、饥饿（Starvation）和活锁（Livelock）1234561.都属于多线程的活跃性问题，如果出现上述几种情况，线程可能不再活跃 2.饥饿，比如它的线程优先级可能太低，高优先级的线程不断抢占它需要的资源，导致其无法工作，可能在未来一段时间内解决（高优先级线程已经完成任务） 3.活锁，资源不断在两个线程中跳动，没有一个线程可以同时拿到所有资源而正常执行 6.并发级别12345670.分为：阻塞、无饥饿、无障碍、无锁、无等待 1.阻塞：一个线程是阻塞的，那么在其他线程释放资源之前，当前线程无法继续执行2.无饥饿：如果锁是公平的，满足先来后到，那么饥饿就不会产生3.无障碍：线程可以同时访问临界区，为确保数据安全，如果有数据竞争，立即对修改数据进行回滚4.无锁：无所的并行总能保证有一个线程在有限步是可以胜出的。5.无等待：要求所有线程必须在有限步内完成。 有关并行的两个重要定律12341.Amdahl定律：加速比定义，加速比=优化前系统耗时/优化后系统耗时，取决于CPU数量增加和串行化程序的减少 2.Gustafson定律：如果串行化比例很小，加速比就是处理器的个数（加速比定义都一样） java的内存模型（JMM）123451.原子性：一个操作是不可中断的 2.可见性：当一个线程修改了某一个共享变量的值，其他线程是否能够立即知道这个修改 3.有序性：在并发时，程序的执行可能就会出现乱序 Java并行程序基础1.线程的基本操作 新建线程： 1231.Thread子类重写run方法，调用Thread子类对象的start方法 2.创建Thread类带Runnable接口参数的构造器对象，参数对象重写了run方法，调用Thread类对象的start方法 终止线程： 1stop方法，太暴力，已过时，可能引起数据不一致的问题 线程中断： 12345671.Thread.interrupt()它通知目标线程中断 2.Thread.isInterrupted()方法判断当前线程是否有被中断（通过检查中断标志位） 3.静态方法Thread.interrupted()判断当前线程的中断状态（同时清除当前线程的中断标志位状态） 4.通过判断线程是否被中断了，如果是，手动退出循环体（break;），否则中断后的线程还可以继续执行。 等待（wait）和通知（notify） 1234567891.这两个方法在Object类，任何对象都可以调用者两个方法 2.如果一个线程调用了wait，它就会进入等待队列，在这个等待队列中，可能有多个等待线程 3.当调用notify，它就会从等待队列中，随机选择一个线程，并将其唤醒 4.notifyAll方法唤醒等待队列中的所有等待线程 5.wait方法必须包含在对应的synchronized语句中 挂起(suspend)和继续执行(resume) 1231.已过时2.suspend在导致线程暂停的同时，并不会去释放任何锁资源3.如果resume操作意外地在suspend前执行，可能导致整个系统工作不正常 等待线程结束(join)和谦让(yield) 1231.join不带参数，表示无限等待，一直阻塞调用者（当前线程），直到目标线程执行完毕2.join带参数，表示最大等待时间，如果指定时间目标线程还在执行，当前线程往下执行3.yield是静态方法，使当前线程让出CPU，但还会进行CPU资源的争夺 2.volatile与Java内存模型(JMM)121.为了在适当的场合，确保线程间的有序性、可见性、原子性，java提供了volatile关键字2.如果不使用volatile申明变量，这个变量被修改后，其他线程可能不会被通知 3.线程组1234561.Thread t1 = new Thread(new ThreadGroup(),new ThreadGroupName(),&quot;T1&quot;) 2.第一个参数，线程组对象（jdk自带），多个线程可共用一个线程组对象3.第二个参数，自定义实现Runnable接口的线程类4.第三个参数，线程组中某个线程的自定义名称5.调用线程组对象的list方法，可以打印这个线程组中所有线程信息，stop方法，立刻关闭线程组所有线程 4.守护线程（Daemon）123451.守护线程必须在start()之前设置，setDaemon(true) 2.守护线程在用户线程中设置（如main用户线程），如果用户线程全部结束，守护线程要守护的对象已经不存在了 3.在一个Java应用中，只有守护线程时，Java虚拟机就会自然退出 5.线程优先级121.数字越大优先级越高（1-10）2.setPriority（Thread.MAX_PRIORITY） 6.线程安全的概念与synchronized12341.volatile并不能真正保证线程安全，它只能确保一个线程修改了数据后，其他线程能够看到这个改动2.synchronized代码块，要指定锁对象3.synchronized作用于实例方法，锁对象是当前类的对象4.synchronized作用于静态方法，锁对象是当前类的字节码对象 7.隐蔽的错误 并发下的ArrayList 123456t1和t2两个线程同时向一个ArrayList容器中添加元素: 1.第一种结果，程序正常结束，大小正好为添加的元素2.程序抛出异常，ArrayList在扩容过程中，内部一致性被破坏，另外一个线程访问到了不一致的内部状态，出现越界问题3.打印的大小小于添加的元素，两个线程同时对ArrayList中的同一个位置进行赋值导致的 并发下的HashMap 1234567t1和t2线程同时对HashMap进行put操作: 1.第一种情况，程序正常，大小正常2.第二种情况，程序正常，大小偏小3.第三种情况，程序永远无法结束，hashMap元素结构是链表，链表结构在多线程环境下变成环（key1、key2的next指针互相指向对方），迭代条件是&#123;当前元素不为null，当前元素的next赋给当前元素&#125;&#123;这条件可以保证put方法一直从尾部添加元素&#125; 错误的加锁 1锁对象应该是不变的 JDK并发包synchronized的功能扩展：重入锁1.重入锁,使用java.util.concurrent.lock.ReentrantLock类来实现1231.public static ReentrantLock lock = new ReentrantLock();2.lock.lock();和lock.unlock();保护临界区资源3.允许迭代 2.中断响应1234561.对锁的请求，统一使用lockInterruptibly() 2.线程1先请求锁1，后请求锁2，线程2先请求锁2，后请求锁1，很容易形成线程的相互等待 3.线程2调用interrupt(),放弃对锁1的申请，同时释放已获得的锁2，这个操作可以使线程1顺利得到锁2而继续执行 3.锁申请等待限时1234561.为避免死锁，给定一个等待时间，让线程自动放弃，使用tryLock() 2.lock.tryLock(5,TimeUnit.SECONDS),参数1表示等待时长，参数2表示计时单位，得到锁返回true，否则false 3.不带参数直接运行，申请成功，立即返回true，锁被其他线程占用，立即返回false 4.公平锁123451.不会产生饥饿现象，按照时间的先后顺序（使用synchronized控制锁，是非公平的） 2.重入锁有构造：public ReentrantLock(boolean fair),当fair为true，表示锁是公平的 3.性能低，可以交替执行线程 重入锁的Condition条件1.Condition接口提供方法1234561.await()方法使当前线程等待，同时释放当前锁，其他线程使用signal()或signalAll()方法时，有机会获得锁继续执行。当前线程被中断，能跳出等待。 2.awaitUninterruptibly()不会再等待过程中响应中断 3.signal()唤醒一个等待中的线程 2.代码12public static ReentrantLock lock = new ReentrantLock();public static Condition condition = lock.newCondition(); 允许多个线程同时访问：信号量（Semaphore）1.构造信号量对象时，必须指定信号量的准入数，可以指定是否公平12public Semaphore(int permits)public Semaphore(int permits, boolean fair) 2.主要逻辑方法123456789public void acquire()尝试获得一个准入的许可，否则线程会等待，直到有线程释放一个许可或者当前线程被中断 public void acquireUninterruptibly() 不响应中断 public boolean tryAcquire()public boolean tryAcquire(long timeout,TimeUnit unit)尝试获得一个许可，成功返回true，否则返回false public void release()用于线程访问资源结束后，释放一个许可，以使其他等待许可的线程可以进行资源访问 3.信号量的泄露1如果发生了信号量的泄露（申请了但没有释放），那么可以进入临界区的线程数量越来越少，直到所有线程均不可访问 ReadWriteLock读写锁 读-读之间不互斥，不阻塞，不对数据的完整性造成破坏，可以并行操作 如果在系统中，读操作次数远远大于写操作，则读写锁就可以发挥最大功效 代码（当前类由线程类加载）123456789101112131415//成员private static Lock lock = new ReentrantLock();private static ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();private static Lock readLock = readWriteLock.readLock();private static Lock writeLock = readWriteLock.writeLock(); //模拟读操作public Object handleRead(Lock lock) throws InterruptedException&#123; try&#123; lock.lock();//传入读锁 Thread.sleep(1000);//模拟耗时的操作，读操作线程越多，读写锁优势越明显 &#125;finally&#123; lock.unlock(); &#125;&#125; 倒计时器CountDownLatch1这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行 循环栅栏：CyclicBarrier1功能比CountDownLatch更复杂 线程阻塞工具类：LockSupport121.可以在线程内任意位置让线程阻塞2.LockSupport的静态方法park()可以阻塞当前线程... 线程复用：线程池1.Executor框架1234567891011121314151617181920212223//各种类型的线程池，主要有以下工厂方法public static ExecutorService newFixedThreadPool(int nThreads),返回一个固定线程数量的线程池，新任务提交时线程池若无空闲线程，暂存在任务队列 public static ExecutorService newSingleThreadExecutor(),返回只有一个线程的线程池 public static ExecutorService newCachedThreadPool(),返回一个可根据实际情况调整线程数量的线程池 public static ScheduledExecutorService newSingleThreadScheduledExecutor()，返回一个扩展了ExecutorService接口的接口对象，扩展了给定时间执行某任务的功能，如，延时执行，周期执行 public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize)同上，可指定线程池线程数量（线程池大小为1） //内部实现：均使用了ThreadPoolExecutor实现(传入不同参数)1.corePoolSize:指定线程池中的线程数量2.maximumPoolSize:指定了线程池中的最大线程数量3.keepAliveTime:超过corePoolSize的空闲线程，多久会被销毁4.unit：keepAliveTime的单位5.workQueue：任务队列，被提交但尚未执行的任务6.threadFactory:线程工厂，一般用默认7.handler:拒绝策略,当任务太多来不及处理，如何拒绝任务（有界队列达到了上限，或使用了SynchronousQueue会将任务直接提交给线程池，提交失败，执行拒绝策略） 2.拒绝策略123451.AbortPolicy策略：直接抛出异常，阻止系统正常工作2.CallerRunsPolicy策略：该策略直接在调用者线程中，运行当前被丢弃的任务3.DiscardOledestPolicy策略：丢弃最老的一个请求，尝试再次提交当前任务4.DiscardPolicy策略：不处理5.自己扩展RejectedExecutionHandler接口 自定义线程创建：ThreadFactory1第6个参数，可以跟踪线程池何时创建、线程名称、组、优先级等 扩展线程池12ThreadPoolExecutor提供了beforeExecute()、afterExecute()、terminated()三个接口对线程池进行控制，在创建ThreadPoolExecutor类对象时重写这些方法 JDK并发容器1.并发集合简介12345ConcurrentHashMap:线程安全的HashMapCopyOnWriteArrayList:适用在读多写少的场合ConcurrentLinkedQueue:适用链表实现，可以看做线程安全的LnkedListBlockingQueue:表示阻塞队列，适用于数据共享的通道ConcurrentSkipListMap：跳表的实现，使用跳表的数据结构进行快速查找，跳表遍历输出是有序的 2.线程安全的HashMap123public static Map m = Collections.synchronizedMap(new HashMap()),在多线程环境中性能表现不算好 java.util.concurrent.ConcurrentHashMap,专为并发进行了性能优化，更适用多线程的场合 3.线程安全的List1234561.ArrayList和Vector都使用数组做为其内部实现，Vector是线程安全的，ArrayList不是 2.LinkedList使用链表的数据结构实现，并不是线程安全的 3.包装成线程安全的List:public static List&lt;String&gt; list = Collections.synchronizedList(new LinkedList&lt;String&gt;()); 4.高效读写队列1ConcurrentLinkedQueue:链表作为其数据结构 锁优化与并行模式有助于提高”锁”性能的几点建议1.减少锁持有时间1234567891011121314public synchronized void syncMethod()&#123; othercode1(); mutextMethod(); othercode2();&#125; //假设只有mutextMethod()方法是有同步需要的，可改为：public void syncMethod2()&#123; othercode1(); synchronized(this)&#123; mutextMethod(); &#125; othercode2();&#125; 2.减少锁粒度123456789典型使用场景：ConcurrentHashMap类的实现 对于HashMap，最重要的就是get和put方法，对整个HashMap加锁，加锁粒度太大它内部细分了若干个小的HashMap，称为段，默认细分为16个段只要被加入的（哈希）表项不存放在同一个段中，则线程间可以做到并行 但：当系统需要取得全局锁时，要获取所有子段的锁，消耗资源比较多 例：size方法会先使用无锁方式求和，失败后会尝试加锁方法求和，性能差与同步的HashMap 3.使用读写锁替换独占锁，之前介绍过，不再重复4.锁分离12345LinkedBlockingQueue实现中，take函数和put函数分别实现了从队列中取得数据和往队列中增加数据，分别作用于队列的前端和尾端，理论上不冲突 JDK定义了takeLock和putLock，这样take和put函数相互独立，只需要在take和take间、put和put间分别对相应的锁进行竞争 5.锁粗化12345678910111213141516171.为了保证有效并发，要求每个线程持有锁的时间尽量短，应尽快释放锁，但多次请求、同步和释放，其本身也会消耗资源，不利于优化 2.把所有锁的操作整合成对锁的一次请求，减少对锁的请求同步次数，这个操作叫做锁的粗化 3.例for(int i=0;i&lt;CIRCLE;i++)&#123; synchronized(lock)&#123; &#125;&#125;//每次循环都有申请锁和释放锁的操作，应改写为：synchronized(lock)&#123; for(int i=0;i&lt;CIRCLE;i++)&#123; &#125;&#125; Java虚拟机对锁优化所做的努力1.锁偏向12如果一个线程获得了锁，那么锁就进入偏向模式，当这个线程再次请求锁是，无须再做任何同步操作，但对于锁竞争比较激烈的场合，效果不佳 2.轻量级锁12如果偏向锁失败，它还会将对象头作为指针，指向持有锁定的线程堆栈内部，判断其是否持有锁，如果获取失败，就会膨胀为重量级锁，成功，进入临界区 3.自旋锁1膨胀后的锁会经历若干次循环，如果还得不到锁，才会真实地将线程在操作系统层面挂起 4.锁消除1在没有用锁的地方使用锁，即使Vector，会使用逃逸分析技术观察某一个变量是否会逃出某一作用域 ThreadLocal 一个容器，保证容器对象只被当前线程访问 set方法相当于把数据存放在一个map中，map的key为当前线程 get方法先获得当前线程名，作为key获得其value ThreadLocal变量，手动设置为null，其所有线程的局部变量都有可能被回收 无锁0.说明：123对于并发控制，锁是一种悲观策略，它总是假设每次临界区操作会产生冲突，必须每次操作都小心翼翼。无锁是一种乐观策略，遇到冲突采用比较交换技术（CAS Compare And Swap）来鉴别线程冲突，一旦检测冲突发生，就重试当前操作直到没有冲突为止 1.并发策略：比较交换（CAS）1当多个线程同时使用CAS操作一个变量时，只有一个会胜出，失败的线程不会被挂起，并且允许再次尝试 2.无锁的线程安全整数：Atomiclnteger12345678910111213141516171.JDK并发包中有一个atomic包，最常用的类是AtomicInteger 2.incrementAndGet()方法使用CAS操作将自己加1，同时返回当前值内部实现：public final int incrementAndGet()&#123; for(;;)&#123; //使用死循环，CAS操作不成功的情况，就要进行不断尝试 int current = get(); int next = current + 1; if(compareAndSet(current,next)) //该方法将新值next写入，使得期望值等于新值， //否则前两行代码被其他线程修改过了 return next; &#125;&#125; public final int get()&#123; return value;&#125; 3.无锁的对象引用：AtomicReferencece12340.和AtomicInteger类似，是对普通对象的引用 1.无法解决反复修改，但最终值相同的情况2.解决上述情况，使用AtomicStampedReference 4.带有时间戳的对象引用：AtomicStampedReference1230.当对应数值被修改时，除了更新数据本身，还必须更新时间戳 1.设置对象值时，对象值以及时间戳都必须满足期望值，才可写入成功 5.无锁的数组：AtomicIntegerArray6.普通变量的原子操作12分为int、long、普通对象的CAS修改：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater 7.等待队列SynchronousQueue的实现1将put()和take()两个功能抽象为一个共通的方法Transferer.transfer() 死锁 两个或多个线程，相互占用对方需要的资源，都不进行释放。 代码模拟 12345678910111213//多人就餐问题，必须得到fork1，fork2两根筷子才能吃饭if(tool == fork1)&#123; synchronized(fork1)&#123; try&#123; Thread.sleep(500); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; synchronized(fork2)&#123; System.out.println(\"A程序在执行。。。\"); &#125; &#125;&#125; cmd/jps命令得到java进程的进程ID，接着使用jstack命令得到线程的线程堆栈、 单例模式1.包含静态成员的单例：123456789101112131415public class Singleton&#123; public static int STATUS = 1; private Singleton()&#123; System.out.println(\"Singleton is create\"); &#125; private static Singleton instance = new Singleton(); public static Singleton getInstance()&#123; return instance; &#125;&#125; 在相同任何地方引用这个STATUS都会导致instance实例被创建（类第一次初始化时创建静态成员instance） 例：System.out.println(Singleton.STATUS);会打印：Singleton is create \\n 1 2.支持延迟加载的策略12345678910111213public class LazySingleton&#123; private LazySingleton&#123; System.out.println(\"LazySingleton is create\"); &#125; private static LazySingleton instance = null; public static synchronized LazySingleton getInstance()&#123; if(instance==null) instance = new LazySingleton(); return instance; &#125;&#125; 当getInstance()方法被第一次调用时，创建单例对象 3.无锁123456789101112131415public class StaticSingleton&#123; private StaticSingleton()&#123; System.out.println(&quot;StaticSingleton is create&quot;); &#125; private static class SingletonHolder&#123; private static StaticSingleton instance = new StaticSingleton(); &#125; public static StaticSingleton getInstance()&#123; return SingletonHolder.instance; &#125;&#125; 只有在getInstance方法被第一次调用时，StaticSingleton的实例才会被创建 内部类声明为private，不能在外部访问并初始化它，利用虚拟机的类初始化机制创建单例 不变模式1.说明12一个对象一旦被创建，它的内部状态将永远不会发生改变，没有一个线程可以修改其内部状态和数据，内部状态也不会自行改变，不需要同步控制 2.只需注意12341.去除setter方法以及所有修改自身属性的方法2.将所有属性设置为私有，并用final标记3.确保没有子类可以修改它的行为4.有一个可以创建完整对象的构造函数","categories":[],"tags":[{"name":"博客重构","slug":"博客重构","permalink":"http://yoursite.com/tags/博客重构/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/tags/读书笔记/"},{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"Java简单IO流操作","slug":"Java简单IO流操作","date":"2017-03-11T07:40:47.000Z","updated":"2018-03-04T03:02:06.000Z","comments":true,"path":"2017/03/11/Java简单IO流操作/","link":"","permalink":"http://yoursite.com/2017/03/11/Java简单IO流操作/","excerpt":"File类构造方法：123File(String pathname)：根据一个路径得到File对象File(String parent, String child):根据一个目录和一个子文件/目录得到File对象File(File parent, String child):根据一个父File对象和一个子文件/目录得到File对象","text":"File类构造方法：123File(String pathname)：根据一个路径得到File对象File(String parent, String child):根据一个目录和一个子文件/目录得到File对象File(File parent, String child):根据一个父File对象和一个子文件/目录得到File对象 创建功能：12345public boolean createNewFile():创建文件 如果存在就不创建public boolean mkdir():创建文件夹 如果存在就不创建//注：要想在某个目录下创建内容，该目录必须存在public boolean mkdirs():创建文件夹,如果父文件夹不存在，会帮你创建出来 删除功能：12345public boolean delete() //如果你创建文件或者文件夹不写盘符路径，默认在项目路径下//Java中的删除不走回收站//要删除一个文件夹，该文件夹内不能包含文件或者文件夹 重命名功能：1234public boolean renameTo(File dest) //如果路径名相同，就是改名//如果路径名不同，就是改名并剪切 判断功能：123456public boolean isDirectory():判断是否是目录public boolean isFile():判断是否是文件public boolean exists():判断是否存在public boolean canRead():判断是否可读public boolean canWrite():判断是否可写public boolean isHidden():判断是否隐藏 获取功能：12345public String getAbsolutePath()：获取绝对路径public String getPath():获取相对路径public String getName():获取名称public long length():获取长度。字节数public long lastModified():获取最后一次的修改时间，毫秒值 高级获取功能1：12public String[] list():获取指定目录下的所有文件或者文件夹的名称数组public File[] listFiles():获取指定目录下的所有文件或者文件夹的File数组 高级获取功能2：(参数为文件名称过滤器)1234567891011public String[] list(FilenameFilter filter)public File[] listFiles(FilenameFilter filter) //示例File file = new File(\"e:\\\\\");String[] strArray = file.list(new FilenameFilter() &#123; @Override public boolean accept(File dir, String name) &#123; return new File(dir, name).isFile() &amp;&amp; name.endsWith(\".jpg\"); &#125;&#125;); 递归删除带内容的目录：12345678910111213141516private static void deleteFolder(File srcFolder) &#123;// 获取该目录下的所有文件或者文件夹的File数组 File[] fileArray = srcFolder.listFiles(); if (fileArray != null) &#123; // 遍历该File数组，得到每一个File对象 for (File file : fileArray) &#123; // 判断该File对象是否是文件夹 if (file.isDirectory()) &#123; deleteFolder(file); &#125; else &#123; System.out.println(file.getName() + \"#########\" + file.delete()); &#125; &#125; System.out.println(srcFolder.getName() + \"#########\" + srcFolder.delete()); &#125;&#125; 字节流FileOutputStream的构造方法：1234567891011FileOutputStream(File file) FileOutputStream(String name) //下面创建字节输出流对象做了几件事情： FileOutputStream fos = new FileOutputStream(\"fos.txt\"); //1.调用系统功能去创建文件 //2.创建fos对象 //3.把fos对象指向这个文件 //数据的追加写入：构造方法带第二个参数是true FileOutputStream fos = new FileOutputStream(\"fos3.txt\", true); 字节输出流操作步骤：1. 创建字节输出流对象 2. 调用write()方法 3. 释放资源 123public void write(int b):写一个字节public void write(byte[] b):写一个字节数组public void write(byte[] b,int off,int len):写一个字节数组的一部分 FileOutputStream写数据：123FileOutputStream fos = new FileOutputStream(\"fos.txt\");fos.write(\"hello\".getBytes());fos.close(); FileInputStream读数据：1234567891011121314FileInputStream fis = new FileInputStream(\"fos.txt\");//方式1int by = 0;while((by=fis.read())!=###1) &#123; System.out.print((char)by);//中文无法实现&#125; //方式2byte[] bys = new byte[1024];int len = 0;while((len=fis.read(bys))!=###1) &#123; System.out.print(new String(bys,0,len));&#125;fis.close(); 缓冲区类(高效类)：12345//写数据：BufferedOutputStream//读数据：BufferedInputStreamBufferedOutputStream bos = new BufferedOutputStream( new FileOutputStream(\"bos.txt\")); 字节流四种方式复制文件:123456789101112//（高效）字节流一次读写一个字节数组：byte[] bys = new byte[1024];int len = 0;while ((len = bis.read(bys)) != ###1) &#123; bos.write(bys, 0, len); &#125; //（高效）字节流一次读写一个字节：int by = 0;while ((by = bis.read()) != ###1) &#123; bos.write(by);&#125; 字符流编码和解码：12345678910//编码:把看得懂的变成看不懂的：（String ###### byte[]）byte[] getBytes(String charsetName):使用指定的字符集合把字符串编码为字节数组 //解码:把看不懂的变成看得懂的：（byte[] ###### String）String(byte[] bytes, String charsetName):通过指定的字符集解码字节数组 InputStreamReader(InputStream is):用默认的编码读取数据InputStreamReader(InputStream is,String charsetName):用指定的编码读取数据OutputStreamWriter(OutputStream out):根据默认编码把字节流的数据转换为字符流OutputStreamWriter(OutputStream out,String charsetName):根据指定编码把字节流数据转换为 InputStreamReader的方法：123int read():一次读取一个字符int read(char[] chs):一次读取一个字符数组 OutputStreamWriter的方法：123456public void write(int c):写一个字符public void write(char[] cbuf):写一个字符数组public void write(char[] cbuf,int off,int len):写一个字符数组的一部分public void write(String str):写一个字符串public void write(String str,int off,int len):写一个字符串的一部分 字符流（转换流）为了高效读写，提供了对应的字符缓冲流：1234567891011121314BufferedWriter: public void newLine():根据系统来决定换行符BufferedReader: public String readLine()：一次读取一行数据包含该行内容的字符串， 不包含任何行终止符，如果已到达流末尾，则返回 null //读写代码：BufferedReader br = new BufferedReader(new FileReader(\"a.txt\"));BufferedWriter bw = new BufferedWriter(new FileWriter(\"b.txt\"));String line = null;while ((line = br.readLine()) != null) &#123; bw.write(line); bw.newLine(); bw.flush();&#125; close()和flush()的区别: close()关闭流对象，但是先刷新一次缓冲区，关闭之后，流对象不可以继续使用 flush()仅仅刷新缓冲区,刷新之后，流对象还可以继续使用 练习一：复制指定目录下的指定文件，并修改后缀名（.java–.jad） 1234567891011121314151617181920212223242526272829303132333435363738394041public static void main(String[] args) throws IOException &#123; File srcFolder = new File(\"e:\\\\java\"); File destFolder = new File(\"e:\\\\jad\"); if (!destFolder.exists()) &#123; destFolder.mkdir(); &#125; File[] fileArray = srcFolder.listFiles(new FilenameFilter() &#123; @Override public boolean accept(File dir, String name) &#123; return new File(dir, name).isFile() &amp;&amp; name.endsWith(\".java\"); &#125; &#125;); for (File file : fileArray) &#123; String name = file.getName(); File newFile = new File(destFolder, name); copyFile(file, newFile); &#125; // 在目的地目录下改名 File[] destFileArray = destFolder.listFiles(); for (File destFile : destFileArray) &#123; String name =destFile.getName(); //DataTypeDemo.java String newName = name.replace(\".java\", \".jad\");//DataTypeDemo.jad File newFile = new File(destFolder,newName); destFile.renameTo(newFile); &#125;&#125;private static void copyFile(File file, File newFile) throws IOException &#123; BufferedInputStream bis = new BufferedInputStream(new FileInputStream( file)); BufferedOutputStream bos = new BufferedOutputStream( new FileOutputStream(newFile)); byte[] bys = new byte[1024]; int len = 0; while ((len = bis.read(bys)) != ###1) &#123; bos.write(bys, 0, len); &#125; bos.close(); bis.close();&#125; 练习二：复制多极文件夹 123456789101112131415161718192021222324252627282930private static void copyFolder(File srcFile, File destFile) throws IOException &#123; if (srcFile.isDirectory()) &#123; File newFolder = new File(destFile, srcFile.getName()); newFolder.mkdir(); File[] fileArray = srcFile.listFiles(); for (File file : fileArray) &#123; copyFolder(file, newFolder); &#125; &#125; else &#123; File newFile = new File(destFile, srcFile.getName()); copyFile(srcFile, newFile); &#125;&#125;private static void copyFile(File srcFile, File newFile) throws IOException &#123; BufferedInputStream bis = new BufferedInputStream(new FileInputStream( srcFile)); BufferedOutputStream bos = new BufferedOutputStream( new FileOutputStream(newFile)); byte[] bys = new byte[1024]; int len = 0; while ((len = bis.read(bys)) != ###1) &#123; bos.write(bys, 0, len); &#125; bos.close(); bis.close();&#125; 练习三：用Reader模拟BufferedReader的readLine()功能 123456789101112131415161718192021222324252627282930313233343536//readLine():一次读取一行，根据换行符判断是否结束，只返回内容，不返回换行符//测试MyBufferedReader时，当作BufferedReader一样使用 public class MyBufferedReader &#123; private Reader r; public MyBufferedReader(Reader r) &#123; this.r = r; &#125; public String readLine() throws IOException &#123; StringBuilder sb = new StringBuilder(); int ch = 0; while ((ch = r.read()) != ###1) &#123; if (ch == '\\r') &#123; continue; &#125; if (ch == '\\n') &#123; return sb.toString(); &#125; else &#123; sb.append((char)ch); &#125; &#125; // 为了防止最后一行数据丢失 if (sb.length() &gt; 0) &#123; return sb.toString(); &#125; return null; &#125; public void close() throws IOException &#123; this.r.close(); &#125;&#125; 练习四：模拟BufferedReader的子类LineNumberReader的方法：（该类可继承第3题的自定义类） 1234567891011121314151617181920public class MyLineNumberReader extends MyBufferedReader &#123; private Reader r; private int lineNumber = 0; public MyLineNumberReader2(Reader r) &#123; super(r); &#125; public int getLineNumber() &#123; return lineNumber; &#125; public void setLineNumber(int lineNumber) &#123; this.lineNumber = lineNumber; &#125; @Override public String readLine() throws IOException &#123; lineNumber++; return super.readLine(); &#125;&#125; 其他流基本数据类型操作流：12DataInputStream(InputStream in)DataOutputStream(OutputStream out) 内存操作流：（用于处理临时存储信息，程序结束，数据就从内存中消失）123字节数组：ByteArrayInputStream(ByteArrayOutputStream)字符数组：CharArrayReader(CharArrayWriter)字符串： StringReader(StringWriter) 打印流：12345678字节流打印流：PrintStream字符打印流：PrintWriter 打印流的特点： 1.只有写数据的方法，没有读取数据的方法 2.可以操作任意类型的数据 3.如果启动了自动刷新，能够自动刷新 4.该流是可以直接操作文本文件的(一般情况下，构造方法同时有File和String类型参数) 标准输入输出流：12345678910111213141516171819//System类中的两个成员变量：public static final InputStream in “标准”输入流public static final PrintStream out “标准”输出流 InputStream is = System.in; //System.in标准输入流，从键盘获取数据 BufferedReader br = new BufferedReader(new InputStreamReader(System.in));//通过字符缓冲流包装标准输入流 PrintStream ps = System.out; // ps.print();这个方法不存在 // print()、println()可以操作任意类型的数据//启动自动刷新： PrintWriter pw = new PrintWriter(new FileWriter(\"pw2.txt\"), true);//再调用println()方法时，不仅仅自动刷新了，还实现了数据的换行,这时println()等价于： bw.write(); bw.newLine(); bw.flush(); 随机访问流：12341.RandomAccessFile类，不属于流，是Object类的子类，融合了InputStream和OutputStream的功能 2.public RandomAccessFile(String name,String mode)：第一个参数是文件路径，第二个参数是操作文件的模式,模式有四种，最常用\"rw\",这种方式表示既可以写数据，也可以读取数据 序列化流/反序列化流：1234567891011121.序列化流把对象按照流一样的方式存入文本文件或者在网络中传输(对象###流数据ObjectOutputStream) 2.反序列化流把文本文件中的流对象数据或者网络中的流对象数据还原成对象(流数据###对象ObjectInputStream) NotSerializableException:未序列化异常类通过实现 java.io.Serializable 接口以启用其序列化功能，未实现此接口的类将无法使其任何状态序列化或反序列化，该接口没有任何方法，被称为标记接口 一个类中可能有很多的成员变量，有些不想进行序列化：使用transient关键字声明不需要序列化的成员变量 类实现了序列化接口的时候，要想解决黄色警告线问题，就可以自动产生一个序列化id值而且产生这个值以后，我们对类进行任何改动，它读取以前的数据是没有问题的 Properties:属性集合类：(可以和IO流相结合使用的集合类)1234567891011//1.Properties 可保存在流中或从流中加载，属性列表中每个键及其对应值都是一个字符串是Hashtable//的子类，说明是一个Map集合 //2.功能 public Object setProperty(String key,String value)：添加元素public String getProperty(String key):获取元素public Set&lt;String&gt; stringPropertyNames():获取所有的键的集合 //下面方法必须Properties集合对象调用：public void load(Reader reader):把文件中的数据读取到集合对象中public void store(Writer writer,String comments):把集合对象中的数据存储到文件","categories":[],"tags":[{"name":"博客重构","slug":"博客重构","permalink":"http://yoursite.com/tags/博客重构/"},{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"Java常见对象","slug":"Java常用对象","date":"2017-03-09T14:51:13.000Z","updated":"2018-03-04T03:02:05.000Z","comments":true,"path":"2017/03/09/Java常用对象/","link":"","permalink":"http://yoursite.com/2017/03/09/Java常用对象/","excerpt":"Math类1234567891011121314151617181920//成员变量：public static final double PIpublic static final double E //成员方法：public static int abs(int a)：绝对值public static double ceil(double a):向上取整public static double floor(double a):向下取整public static int max(int a,int b):最大值 (min类似)public static double pow(double a,double b):a的b次幂public static double random():随机数 [0.0,1.0)public static int round(float a) 四舍五入(参数为double的类似)public static double sqrt(double a):正平方根 //设计一个方法，可以实现获取任意范围内的随机数：public static int getRandom(int start, int end) &#123; int number = (int) (Math.random() * (end - start + 1)) + start; return number;&#125;","text":"Math类1234567891011121314151617181920//成员变量：public static final double PIpublic static final double E //成员方法：public static int abs(int a)：绝对值public static double ceil(double a):向上取整public static double floor(double a):向下取整public static int max(int a,int b):最大值 (min类似)public static double pow(double a,double b):a的b次幂public static double random():随机数 [0.0,1.0)public static int round(float a) 四舍五入(参数为double的类似)public static double sqrt(double a):正平方根 //设计一个方法，可以实现获取任意范围内的随机数：public static int getRandom(int start, int end) &#123; int number = (int) (Math.random() * (end - start + 1)) + start; return number;&#125; Random类1234567//构造方法：public Random():没有给种子，用的是默认种子，是当前时间的毫秒值public Random(long seed):给定种子后，每次得到的随机数是相同的 //成员方法：public int nextInt()：返回的是int范围内的随机数public int nextInt(int n):返回的是[0,n)范围的内随机数 System类1234567891011//运行垃圾回收器，类中重写finalize()方法，在重写方法里调用父类的super.finalize();public static void gc() //终止当前正在运行的 Java 虚拟机，参数用作状态码，根据惯例，非0的状态码表示异常终止 public static void exit(int status) //返回以毫秒为单位的当前时间，可以用来统计程序运行时间public static long currentTimeMillis() //从指定源数组中复制一个数组，复制从指定的位置开始，到目标数组的指定位置结束public static void arraycopy(Object src,int srcPos,Object dest,int destPos,int length) BigInteger和BigDecimal类123456789101112131415161718//构造方法：BigInteger(String val)public BigDecimal(String val) //成员方法：public BigInteger add(BigInteger val):加public BigInteger subtract(BigInteger val):减public BigInteger multiply(BigInteger val):乘public BigInteger divide(BigInteger val):除public BigInteger[] divideAndRemainder(BigInteger val):返回商和余数的数组 public BigDecimal add(BigDecimal augend) 加public BigDecimal subtract(BigDecimal subtrahend) 减public BigDecimal multiply(BigDecimal multiplicand) 乘public BigDecimal divide(BigDecimal divisor) 除 //参数分别为：商，几位小数，如何舍取（见API）public BigDecimal divide(BigDecimal divisor,int scale,int roundingMode) Date和DateFormat类12345678910111213141516171819202122232425262728//Date类Date():根据当前的默认毫秒值创建日期对象Date(long date)：根据给定的毫秒值创建日期对象public long getTime():获取时间，以毫秒为单位public void setTime(long time): 以毫秒为单位设置时间 //和String互转public final String format(Date date)public Date parse(String source) //DateForamt是抽象类，使用子类SimpleDateFormatSimpleDateFormat():默认模式SimpleDateFormat(String pattern):给定的模式（年y月M日d时H分m秒s） //格式化和解析代码Date d = new Date(); //给定模式创建格式化对象SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy年MM月dd日 HH:mm:ss\");String s = sdf.format(d); // public final String format(Date date)System.out.println(s);// 2014年12月12日 12:12:12String str = \"2008-08-08 12:12:12\"; //在把一个字符串解析为日期的时候，请注意格式必须和给定的字符串格式匹配SimpleDateFormat sdf2 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");Date dd = sdf2.parse(str);System.out.println(dd);// Fri Aug 08 12:12:12 CST 2008 Calendar类（抽象类）123456789101112131415161718192021222324252627282930//返回给定日历字段的值,日历类中的每个日历字段都是静态的成员变量，并且是int类型public int get(int field) //根据给定的日历字段和对应的时间，来对当前的日历进行操作public void add(int field,int amount) //设置当前日历的年月日public final void set(int year,int month,int date)//示意代码 //其日历字段已由当前日期和时间初始化，右边的方法返回左边的子类对象 Calendar rightNow = Calendar.getInstance(); int year = rightNow.get(Calendar.YEAR); int month = rightNow.get(Calendar.MONTH); int date = rightNow.get(Calendar.DATE); System.out.println(year + \"年\" + (month + 1) + \"月\" + date + \"日\");//注意月索引 // 5年后的10天前 c.add(Calendar.YEAR, 5); c.add(Calendar.DATE, -10); //获取任意一年的二月有多少天 Scanner sc = new Scanner(System.in); System.out.println(\"请输入年份：\"); int year = sc.nextInt(); Calendar c = Calendar.getInstance(); c.set(year, 2, 1); // 这是这一年的3月1日 // 把时间往前推一天，就是2月的最后一天 c.add(Calendar.DATE, -1); System.out.println(c.get(Calendar.DATE));","categories":[],"tags":[{"name":"博客重构","slug":"博客重构","permalink":"http://yoursite.com/tags/博客重构/"},{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"Java基本概念","slug":"Java基本概念","date":"2017-03-09T14:07:16.000Z","updated":"2018-03-04T03:01:52.000Z","comments":true,"path":"2017/03/09/Java基本概念/","link":"","permalink":"http://yoursite.com/2017/03/09/Java基本概念/","excerpt":"Dos窗口 使用windows+R输入cmd打开该窗口 d:切换到D盘，dir列出当前目录的文件和文件夹 md aaa创建aaa文件夹，rd aaa移除空的aaa目录，rd /s aaa可以移除非空的aaa目录 cd ..单级回退，cd a/b/c多级进入，cd /回到根目录 del a.txt删除a.txt，del *.txt删除所有.txt`文件 cls清屏，exit退出 使用windows+R或者在Dos窗口下输入calc调用计算器，输入notepad调用记事本 使用windows+R或者在Dos窗口下输入shutdown /s /t 10系统会提示10秒后关机，shutdown /a系统会提示取消关机","text":"Dos窗口 使用windows+R输入cmd打开该窗口 d:切换到D盘，dir列出当前目录的文件和文件夹 md aaa创建aaa文件夹，rd aaa移除空的aaa目录，rd /s aaa可以移除非空的aaa目录 cd ..单级回退，cd a/b/c多级进入，cd /回到根目录 del a.txt删除a.txt，del *.txt删除所有.txt`文件 cls清屏，exit退出 使用windows+R或者在Dos窗口下输入calc调用计算器，输入notepad调用记事本 使用windows+R或者在Dos窗口下输入shutdown /s /t 10系统会提示10秒后关机，shutdown /a系统会提示取消关机 JDK,JRE,JVM的作用及关系1231.JRE只是java程序的运行环境，包含JVM及核心类库 2.JDK是java开发工具，不仅提供了java程序运行所需的JRE，还提供了一系列的编译、运行等工具，如javac、java等 环境变量CLASSPATH的作用1CLASSPATH环境变量保存的是一些目录和jar文件地址，这些路径是为java程序在编译和运行时搜索类而用 垃圾回收机制12345678910111.Java.lang.Object中有个finalize()方法，它会在垃圾回收器认为这个对象是垃圾之后，真正回收之前被调用 2.Java.lang.System中有个gc()方法，通过显示调用它可以请求垃圾回收器线程，但线程是否开始还是由JVM的算法决定 3.Java.lang.Runtime中的gc()方法和System的作用一样，只不过Runtime是一个单例模式的类，需要用getRuntime()获得它的实例，然后才能调用gc()方法 System.gc();Runtime.getRuntime().gc(); Java基础数据类型及其包装类123456789101.byte1字节-Byte，short2字节-Short，int4字节-Integer，float4字节-Float，double8字节-Double,char2字节-Character，boolean1字节-Boolean 2.数据类型转换默认`从小到大`，byte,short,char之间不相互转换，直接转成int类型参与运算 3.`从大到小`进行强转，可能有精度损失，目标数据类型 变量名 = (目标数据类型) (被转换的数据) byte b1=3,b2=4,b;b=b1+b2;//错，b1、b2要转成int做加法，赋给byte要强转b=3+4;//正确，常量相加，首先做加法，然后看结果是否在赋值的数据类型范围内 进制123456789101112131.二进制-0b开头、八进制-0开头、十六进制-0x开头2.其他进制到十进制：(用乘推导)3.十进制到其他进制：(用除推导) //其他进制到十进制十进制12345=1*10^4 + 2*10^3 + 3*10^2 + 4*10^1 + 5*10^0 = 12345二进制0b100=1*2^2 + 0*2^1 + 0*2^0 = 4八进制0100=1*8^2 + 0*8^1 + 0*8^0 = 64十六进制100=1*16^2 + 0*16^1 + 0*16^0 = 256 //十进制到其他进制十进制12345（到十进制）：不断除以10，记余数，直到0，余数反转，为12345十进制20（到二进制）： 不断除以2，记余数，直到0，余数反转，为0b10100 原码、反码、补码123456789101112原码：正数的原码最高位是0，负数的原码最高位是1，其他是数值位 +7 0 0000111 -7 1 0000111 反码：正数的反码与原码相同，负数的反码与原码符号位相同，数值位取反 +7 0 0000111 -7 1 1111000 补码：正数的补码与原码相同，负数的补码是在反码的基础上加1 +7 0 0000111 -7 1 1111001 运算符12345671.相除想得到小数，至少一个为float类型，可在输出时*1.0把int变为float 2.++,--运算符：放前放后，都使操作数变1，放前作为整体，变，放后面作为整体，不变 3.扩展赋值运算符隐含强换，s += 1;等价于s = (s的数据类型)(s + 1); 4.&amp;&amp;具有短路效果，左边是false，右边不执行,&amp;两边都一定执行 static关键字123451.随着类加载而加载，优先于对象存在，被类的所有对象共享 2.一个对象赋值或修改静态成员变量，其他的和再创建的对象都改变 3.静态方法中没有this关键字，静态方法只能访问静态的成员变量和方法 继承、this、super123451.子类只能继承父类所有非私有的成员 2.子类所有构造方法默认访问父类空参构造方法，子类不能继承父类的含参构造方法，可以通过super关键字访问 3.调用成员变量`this.成员变量`，调用构造方法`this(数据类型)`，调用成员方法`this.成员方法` 重写、重载12345方法重载：本类中出现的方法名一样，参数列表不同的方法，与返回值无关 方法重写：子类出现了和父类中方法声明一样的方法访问权限不能更低，私有方法不能继承，更不能重写 注意：静态方法不存在重写，但子类若存在同名方法，也要加静态 final关键字123修饰类，该类不能被继承，修饰方法，该方法不能被重写，修饰变量，该变量不能重新赋值 修饰引用类型变量，地址值不能改变，但内容可以改变 多态123前提：继承或实现关系、方法重写、父类引用指向子类对象 多态中的对象只能访问父类有的成员，不能使用子类特有功能 抽象类和接口12345671.都只能通过多态实例化 2.接口成员变量默认`public static final`修饰，无构造方法，只有抽象方法，默认`public abstract` 3.抽象类成员变量可以是变量，也可以是常量，有构造方法，成员方法至少一个是抽象的 4.抽象类被继承是`is a`的关系，体现共性，接口被实现是`like a`的关系，体现拓展 权限修饰符12345private只有本类内部可以访问 默认情况只在同一个包下自由访问 protected同一个包下，或不同包下的子类可以访问 内部类12345671.内部类可以访问外部类的成员，`包括私有`，外部类要访问内部类的成员，必须创建对象 2.访问非静态内部类：`Outer.Inner oi = new Outer().new Inner();`（外部类对象.内部类对象） 3.访问静态内部类：`Outer.Inner oi = new Outer.Inner();` 4.局部内部类访问的局部变量必须用`final`修饰 ==和equals123==比较基本类型是比较值，比较引用类型是比较地址 equals方法只能比较引用类型，默认调用==比较地址，String类重写了该方法，比较的是字符串内容 String12345678910111.String s = new String(“hello”);创建2个对象，堆内存一个，常量池一个 2.String s = “hello”;创建1个对象，在常量池 3.字符串变量相加，先开空间，再拼接，常量相加，编译后相当与一个整体 String s1 = \"hello\";String s2 = \"world\";String s3 = \"helloworld\";System.out.println(s3 == s1 + s2);// falseSystem.out.println(s3 == \"hello\" + \"world\");// true（若s3是new的，则false） 4.常用方法： 1234567891011boolean startsWith(String str):以某个指定的字符串开头，区分大小写boolean endsWith(String str):以某个指定的字符串结尾，区分大小写boolean isEmpty():内容是否为空char charAt(int index):获取指定索引位置的字符int indexOf(int ch):返回指定字符第一次出现的索引（形参传入'a'和97都代表'a'）String substring(int start):从指定位置开始截取字符串,默认到末尾包含start这个索引String substring(int start,int end):截取字符串包括start，不包括endbyte[] getBytes():把字符串转换为字节数组char[] toCharArray():把字符串转换为字符数组static String valueOf(char[] chs): valueOf方法可以把任意类型的数据转成字符串String concat(String str):字符串拼接 Stirng、StringBuffer、StringBuilder1231.String是内容不可变的，而StringBuffer，StringBuilder都是内容可变的 2.StringBuffer是同步的，安全，效率低、StringBuilder是不同步的，不安全，效率高 Arrays工具类1234public static String toString(int[] a)：把数组转成字符串public static void sort(int[] a)：对数组进行排序(底层是快排)public static int binarySearch(int[] a,int key)：二分查找 用LinkedList模拟栈数据结构12345678910111213141516public class MyStack &#123; private LinkedList link; public MyStack() &#123; link = new LinkedList(); &#125; public void add(Object obj) &#123; link.addFirst(obj); &#125; public Object get() &#123; // return link.getFirst();//这样会导致无法弹栈 return link.removeFirst(); &#125; public boolean isEmpty() &#123; return link.isEmpty(); &#125;&#125; 集合1234567891011121314Collection： List：有序，可重复 ArrayList：数据结构是数组，适合查询，线程不安全 Vector：同ArrayList，但线程安全 LinkedList：数据结构是链表，适合做增删，线程不安全 Set：无序，唯一 HashSet：数据结构是哈希表，依赖hashCode和equals方法 LinkedHashSet：链表保证有序，哈希表保证唯一 TreeSet：数据结构是红黑树Map：数据结构只针对键有效 HashMap：数据结构是哈希表，线程不安全，允许null键和null值 LinkedHashMap：数据结构是链表和哈希表 Hashtable：数据结构是哈希表，线程安全，不允许null键和null值 TreeMap：数据结构是红黑树 TreeSet集合保证元素排序12345678910111213自然排序(元素具备比较性)，让元素类实现自然排序接口Comparable TreeSet&lt;Student&gt; ts = new TreeSet&lt;Student&gt;(); 比较器排序(集合具备比较性)，使用一个带参构造方法TreeSet&lt;Student&gt; ts = new TreeSet&lt;Student&gt;(new MyComparator()); 都重写方法：public int compare(Student s1, Student s2) &#123; int num = s1.getName().length() - s2.getName().length(); int num2 = num == 0 ? s1.getName().compareTo(s2.getName()) : num; int num3 = num2 == 0 ? s1.getAge() - s2.getAge() : num2; return num3;&#125; Collections类12345public static &lt;T&gt; void sort(List&lt;T&gt; list)：默认情况下是自然顺序。public static &lt;T&gt; int binarySearch(List&lt;?&gt; list,T key)：二分查找public static &lt;T&gt; T max(Collection&lt;?&gt; coll)：最大值public static void reverse(List&lt;?&gt; list)：反转public static void shuffle(List&lt;?&gt; list)：随机置换 throw和throws123throws用在方法声明后，跟的是异常类名，可以多个，表示出现异常的可能性 throw用在方法中，跟的是异常对象名，表示抛出了异常 final,finally和finalize12345final：修饰类，类不能被继承，修饰变量，变量是常量，修饰方法，方法不能被重写 finally：是异常处理的一部分，用于释放资源 finalize：是Object类的一个方法，用于垃圾回收 异常分类1.Error 我们不处理。这种问题一般都是很严重的，比如说内存溢出 2.非RuntimeException的异常，不处理，编译就不能通过 3.RuntimeException，一般不处理，原因是代码不够严谨，需要修正代码 处理方式1.jvm默认的处理：把异常的名称，原因及出现的问题等信息输出在控制台，同时会结束程序 2.第一种处理格式 1234567try &#123; 可能出现问题的代码;&#125;catch(异常名 变量) &#123; 针对问题的处理;&#125;finally &#123; 释放资源;&#125;// 注：被finally控制的语句体一定会执行，除非执行到finally之前jvm退出了 3.第二种处理格式： 1throws 异常类名（必须跟在方法的括号后面） 4.多个异常的处理123456789try&#123; ...&#125;catch(异常类名 变量名) &#123; ...&#125;catch(异常类名 变量名) &#123; ...&#125;//平级关系的异常谁前谁后无所谓，子父关系的异常，父必须在后面//一旦try出现异常，就会抛出，和catch匹配，结束整个try...catch 5.JDK7出现了一个新的异常处理方案123456try&#123; ...&#125;catch(异常名1 | 异常名2 | ... 变量 ) &#123; ...&#125;//多个异常必须是平级关系 异常方法123public String getMessage():异常的消息字符串 public String toString():返回异常的简单信息描述void printStackTrace(): 获取异常类名和异常信息，位置 问题：catch里有return语句，finally还会执行吗？123456789101112131415161718public static void main(String[] args) &#123; System.out.println(getInt());&#125;public static int getInt() &#123; int a = 10; try &#123; System.out.println(a / 0); a = 20; &#125; catch (ArithmeticException e) &#123; a = 30; return a;//这里不是return a，而是return 30这个返回路径 //继续执行finally的内容，a=40，再次回到以前的返回路径，继续走return 30; &#125; finally &#123; a = 40; //return a;//如果这样结果就是40了（这里和下面的return a;只能出现一个） &#125; return a;&#125; 自定义异常类：继承Exception或继承RuntimeException12345678public class MyException extends Exception &#123; public MyException() &#123; &#125; public MyException(String message) &#123; super(message); &#125;&#125; 异常注意事项 子类重写父类方法时，子类的方法必须抛出相同的异常或父类异常的子类 如果父类抛出了多个异常,子类重写父类时,只能抛出相同的异常或者是它们的子集 子类不能抛出父类没有的异常 如果被重写的方法没有异常抛出,那么子类的方法绝不可以抛出异常,这时子类方法若有异常发生,子类只能try,不能throws 进程和线程 进程：正在运行的程序，是系统进行资源分配和调用的独立单位，每一个进程都有它自己的内存空间和系统资源 线程：是进程中的单个顺序控制流，是一条执行路径，一个进程如果只有一条执行路径，则称为单线程程序，否则称为多线程程序 并行：是逻辑上同时发生，指在某一个时间内同时运行多个程序，并发是物理上同时发生，指在某一个时间点同时运行多个程序 Java程序的运行原理：由java命令启动JVM，JVM启动就相当于启动了一个进程，接着有该进程创建了一个主线程去调用main方法 实现多线程的程序原理 1234561. 线程是依赖进程而存在的，所以我们应该先创建一个进程2. 而进程是由系统创建的，所以我们应该去调用系统功能3. Java是不能直接调用系统功能来创建进程的，所以，我们没有办法直接实现多线程程序，4.但是Java可以去调用C/C++写好的程序来实现多线程程序，由C/C++去调用系统功能创建进程 Java提供的类是：Thread 方式一 12341.自定义类MyThread继承Thread类2.MyThread类里面重写run方法3.创建对象 MyThread my = new MyThread();4.启动线程 my.start(); 方式二1231.自定义类MyRunnable实现Runnable接口2.重写run()方法3.创建MyRunnable类的对象 线程操作12345678910111213141516public final String getName():获取线程的名称public final void setName(String name):设置线程的名称public static Thread currentThread():获取线程对象名称：Thread.currentThread().getName() //该方法必须在启动线程前调用，随着Jvm的退出而退出public final void setDaemon(boolean on):将该线程标记为守护线程或用户线程public final int getPriority():返回线程对象的优先级 //线程默认优先级是5，线程优先级的范围是：1-10public final void setPriority(int newPriority)：更改线程的优先级。 public final void join():等待该线程终止public static void yield():暂停当前正在执行的线程对象，并执行其他线程public static void sleep(long millis):线程休眠public final void stop():让线程停止，已过时public void interrupt():中断线程，把线程的状态终止，并抛出一个InterruptedException run()和start()的区别：123run():仅仅是封装被线程执行的代码，直接调用是普通方法start():首先启动了线程，然后再由jvm去调用该线程的run()方法start():不能被同一个线程对象多次调用,否则IllegalThreadStateException:非法的线程状态异常 判断一个程序是否会有线程安全问题的标准：1231.是否是多线程环境2.是否有共享数据3.是否有多条语句操作共享数据 锁对象问题 1231.同步代码块的锁对象可以是任意对象2.关键字synchronized加在方法上，锁对象是this3.静态方法锁对象是类的字节码文件对象 线程安全的类或集合： 12345678StringBuffer sb = new StringBuffer();Vector&lt;String&gt; v = new Vector&lt;String&gt;();Hashtable&lt;String, String&gt; h = new Hashtable&lt;String, String&gt;(); //替代Vector集合的集合： public static &lt;T&gt; List&lt;T&gt; synchronizedList(List&lt;T&gt; list)List&lt;String&gt; list1 = new ArrayList&lt;String&gt;();// 线程不安全List&lt;String&gt; list2 = Collections.synchronizedList(new ArrayList&lt;String&gt;()); // 线程安全 锁对象Lock 123456//为了更清晰的表达如何加锁和释放锁,JDK5以后提供了一个新的锁对象Lock：void lock():获取锁void unlock():释放锁 //ReentrantLock是Lock的实现类：private Lock lock = new ReentrantLock(); 死锁 12345678910111213141516171819202122232425262728293031323334353637383940414243//使用了锁嵌套，两个或两个以上的线程在争夺资源的过程中，发生的一种相互等待的现象public class DieLock extends Thread &#123; private boolean flag; public DieLock(boolean flag) &#123; this.flag = flag; &#125; @Override public void run() &#123; if (flag) &#123; synchronized (MyLock.objA) &#123; System.out.println(\"if objA\"); synchronized (MyLock.objB) &#123; System.out.println(\"if objB\"); &#125; &#125; &#125; else &#123; synchronized (MyLock.objB) &#123; System.out.println(\"else objB\"); synchronized (MyLock.objA) &#123; System.out.println(\"else objA\"); &#125; &#125; &#125; &#125;&#125; public class DieLockDemo &#123; public static void main(String[] args) &#123; DieLock dl1 = new DieLock(true); DieLock dl2 = new DieLock(false); dl1.start(); dl2.start(); &#125;&#125; public class MyLock &#123; // 创建两把锁对象 public static final Object objA = new Object(); public static final Object objB = new Object();&#125; 生产者消费者模型1234567Object类中提供了三个方法： wait():等待 notify():唤醒单个线程 notifyAll():唤醒所有线程 为什么这些方法不定义在Thread类中呢? 因为这些方法的调用必须通过锁对象调用，锁对象可以是任意锁对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class Student &#123; private String name; private int age; private boolean flag; // 默认情况是没有数据，如果是true，说明有数据 public synchronized void set(String name, int age) &#123; // 如果有数据，就等待 if (this.flag) &#123; try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // 设置数据 this.name = name; this.age = age; // 修改标记 this.flag = true; this.notify();//唤醒其他锁线程，但必须抢到CPU的执行权才能执行 &#125; public synchronized void get() &#123; // 如果没有数据，就等待 if (!this.flag) &#123; try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // 获取数据 System.out.println(this.name + \"---\" + this.age); // 修改标记 this.flag = false; this.notify(); &#125;&#125;public class SetThread implements Runnable &#123; private Student s; private int x = 0; public SetThread(Student s) &#123; this.s = s; &#125; @Override public void run() &#123; while (true) &#123; if (x % 2 == 0) &#123; s.set(\"学生一\", 27); &#125; else &#123; s.set(\"学生二\", 30); &#125; x++; &#125; &#125;&#125;public class GetThread implements Runnable &#123; private Student s; public GetThread(Student s) &#123; this.s = s; &#125; @Override public void run() &#123; while (true) &#123; s.get(); &#125; &#125;&#125;public class StudentDemo &#123; public static void main(String[] args) &#123; //创建资源 Student s = new Student(); SetThread st = new SetThread(s); GetThread gt = new GetThread(s); Thread t1 = new Thread(st); Thread t2 = new Thread(gt); t1.start(); t2.start(); &#125;&#125; 线程池 使用步骤： 12345678910111213//创建一个线程池对象，控制要创建几个线程对象 public static ExecutorService newFixedThreadPool(int nThreads) ExecutorService pool = Executors.newFixedThreadPool(2);//可以执行Runnable对象或者Callable对象代表的线程 //调用如下方法开启线程：//Future&lt;?&gt; submit(Runnable task)//&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) pool.submit(new MyRunnable());//结束线程 pool.shutdown(); 线程求和案例 12345678910111213141516//Callable是带泛型的接口（泛型指call()方法的返回值类型）public class MyCallable implements Callable&lt;Integer&gt; &#123;private int number;public MyCallable(int number) &#123; this.number = number;&#125;@Overridepublic Integer call() throws Exception &#123; int sum = 0; for (int x = 1; x &lt;= number; x++) &#123; sum += x; &#125; return sum;&#125;&#125; 匿名内部类格式开启线程 123456789101112131415161718192021222324252627282930313233343536373839404142public class ThreadDemo &#123;public static void main(String[] args) &#123; // 继承Thread类来实现多线程 new Thread() &#123; public void run() &#123; for (int x = 0; x &lt; 100; x++) &#123; System.out.println(Thread.currentThread().getName() + \":\" + x); &#125; &#125; &#125;.start();// 实现Runnable接口来实现多线程new Thread(new Runnable() &#123; @Override public void run() &#123; for (int x = 0; x &lt; 100; x++) &#123; System.out.println(Thread.currentThread().getName() + \":\" + x); &#125; &#125;&#125;) &#123;&#125;.start(); //下面代码run方法被重写了2次，而start方法是通知Jvm调用run方法，根据多态原理， //最终执行下面的run方法，上面的run方法必须重写，但是不执行 new Thread(new Runnable() &#123; @Override public void run() &#123; for (int x = 0; x &lt; 100; x++) &#123; System.out.println(\"hello\" + \":\" + x); &#125; &#125; &#125;) &#123; public void run() &#123; for (int x = 0; x &lt; 100; x++) &#123; System.out.println(\"world\" + \":\" + x); &#125; &#125; &#125;.start();&#125;&#125; 定时器 12345678910//依赖Timer和TimerTask这两个类： //Timer: public Timer() public void schedule(TimerTask task,long delay) public void schedule(TimerTask task,long delay,long period) public void cancel()//TimerTask: //继承该类就变成了线程类，要重写run方法 //继承类对象传入到timer类对象的方法中","categories":[],"tags":[{"name":"博客重构","slug":"博客重构","permalink":"http://yoursite.com/tags/博客重构/"},{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]}]}